<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: April 21, 2023 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.242b882c3b0c00ae28b251add3931eef.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><script async src="https://www.googletagmanager.com/gtag/js?id=G-NNZHY5233M"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}function trackOutboundLink(e,t){gtag("event","click",{event_category:"outbound",event_label:e,transport_type:"beacon",event_callback:function(){t!=="_blank"&&(document.location=e)}}),console.debug("Outbound link clicked: "+e)}function onClickCallback(e){if(e.target.tagName!=="A"||e.target.host===window.location.host)return;trackOutboundLink(e.target,e.target.getAttribute("target"))}gtag("js",new Date),gtag("config","G-NNZHY5233M",{}),gtag("set",{cookie_flags:"SameSite=None;Secure"}),document.addEventListener("click",onClickCallback,!1)</script><meta name=author content="Giovanni Pecoraro"><meta name=description content="A tutorial on how to train a 3D Convolutional Neural Network (3D CNN) to detect the presence of brain stroke from Computer Tomography (CT) scans."><link rel=alternate hreflang=en-us href=https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/><link rel=canonical href=https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#3f51b5"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@Peco602"><meta property="twitter:creator" content="@Peco602"><meta property="twitter:image" content="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/featured.png"><meta property="og:site_name" content="Giovanni Pecoraro"><meta property="og:url" content="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/"><meta property="og:title" content="Brain stroke detection from CT scans via 3D Convolutional Neural Network | Giovanni Pecoraro"><meta property="og:description" content="A tutorial on how to train a 3D Convolutional Neural Network (3D CNN) to detect the presence of brain stroke from Computer Tomography (CT) scans."><meta property="og:image" content="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/featured.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2023-04-21T00:00:00+00:00"><meta property="article:modified_time" content="2023-04-21T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/"},"headline":"Brain stroke detection from CT scans via 3D Convolutional Neural Network","image":["https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/featured.png"],"datePublished":"2023-04-21T00:00:00Z","dateModified":"2023-04-21T00:00:00Z","author":{"@type":"Person","name":"Giovanni Pecoraro"},"publisher":{"@type":"Organization","name":"Giovanni Pecoraro","logo":{"@type":"ImageObject","url":"https://www.peco602.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_3.png"}},"description":"A tutorial on how to train a 3D Convolutional Neural Network (3D CNN) to detect the presence of brain stroke from Computer Tomography (CT) scans."}</script><title>Brain stroke detection from CT scans via 3D Convolutional Neural Network | Giovanni Pecoraro</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=789bb3424cd0565bbf26a31ec277fa04><script src=/js/wowchemy-init.min.7532de8e15162845d694f17af8b46a99.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Giovanni Pecoraro</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Giovanni Pecoraro</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#posts><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/#talks><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=/#featured><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item d-none d-lg-inline-flex"><a class=nav-link href=https://twitter.com/Peco602 data-toggle=tooltip data-placement=bottom title="Follow me on Twitter" target=_blank rel=noopener aria-label="Follow me on Twitter"><i class="fab fa-twitter" aria-hidden=true></i></a></li><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><article class=article><div class="article-container pt-3"><h1>Brain stroke detection from CT scans via 3D Convolutional Neural Network</h1><p class=page-subtitle>A tutorial on how to train a 3D Convolutional Neural Network (3D CNN) to detect the presence of brain stroke from Computer Tomography (CT) scans.</p><div class=article-metadata><div><span class=author-highlighted>Giovanni Pecoraro</span></div><span class=article-date>Apr 21, 2023</span>
<span class=middot-divider></span>
<span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/deep-learning/>Deep Learning</a>, <a href=/category/medical/>Medical</a>, <a href=/category/python/>Python</a></span></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:207px><div style=position:relative><img src=/post/0100-brain-stroke-detection-3d-cnn/featured_huf6a37d4a6ead960cadcc6717609e4865_287423_720x2500_fit_q75_h2_lanczos_3.webp width=720 height=207 alt class=featured-image>
<span class=article-header-caption>Image credit: <a href=https://unsplash.com/photos/CpkOjOcXdUY target=_blank rel=noopener><strong>Giovanni Pecoraro</strong></a></span></div></div><div class=article-container><div class=article-style><!-- CSS for scrollable code output --><style>.scrollable-output .highlight .chroma{max-height:1000px;overflow-y:auto;background-color:#23252f!important;border-color:#23252f!important}</style><h2 id=introduction>Introduction</h2><p>The <a href=https://www.kaggle.com/datasets/afridirahman/brain-stroke-ct-image-dataset target=_blank rel=noopener>Brain Stroke CT Image Dataset</a> from Kaggle provides normal and stroke brain Computer Tomography (CT) scans. The dataset presents very low activity even though it has been uploaded more than 2 years ago. It may be probably due to its quite low usability (3.13). The challenge is to get some interesting result, i.e., to try to perform brain stroke detection, even from this low-quality CT scans dataset. The followed approach is based on the usage of a 3D Convolutional Neural Network (CNN) in place of a standard 2D one. 2D CNNs are commonly used to process both grayscale (1 channel) and RGB images (3 channels), while a 3D CNN represents the 3D equivalent since it takes as input a 3D volume or a sequence of 2D frames, e.g. slices in a CT scan.
The provided example takes inspiration from the great work <a href=https://keras.io/examples/vision/3D_image_classification/ target=_blank rel=noopener>3D image classification from CT scans</a> done by <a href=https://twitter.com/hasibzunair target=_blank rel=noopener>Hasib Zunair</a> who clearly demonstrated how to use a 3D CNN to predict the presence of viral pneumonia from CT scans.</p><h2 id=dataset-exploration>Dataset exploration</h2><p>The CT scans dataset is public available on Kaggle, but for the sake of simplicy it has been made available also on my Github profile so it can be easily downloaded without the need of an API key and additional Python packages.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>zipfile</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>tensorflow</span> <span class=k>as</span> <span class=nn>tf</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Download dataset from Github</span>
</span></span><span class=line><span class=cl><span class=n>url</span> <span class=o>=</span> <span class=s2>&#34;https://github.com/Peco602/brain-stroke-detection-3d-cnn/releases/download/v0.0.1/brain_ct_data.zip&#34;</span>
</span></span><span class=line><span class=cl><span class=n>filename</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>getcwd</span><span class=p>(),</span> <span class=s2>&#34;brain_ct_data.zip&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>get_file</span><span class=p>(</span><span class=n>filename</span><span class=p>,</span> <span class=n>url</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Unzip dataset</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>zipfile</span><span class=o>.</span><span class=n>ZipFile</span><span class=p>(</span><span class=s2>&#34;brain_ct_data.zip&#34;</span><span class=p>,</span> <span class=s2>&#34;r&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>z_fp</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>z_fp</span><span class=o>.</span><span class=n>extractall</span><span class=p>(</span><span class=s2>&#34;.&#34;</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>Downloading data from https://github.com/Peco602/brain-stroke-detection-3d-cnn/releases/download/v0.0.1/brain_ct_data.zip
63160014/63160014 [==============================] - 1s 0us/step
</code></pre><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=err>!</span><span class=n>ls</span> <span class=o>-</span><span class=n>al</span> <span class=n>brain_ct_data</span>
</span></span></code></pre></div><pre><code>total 92
drwxr-xr-x 4 root root  4096 Apr 21 07:03 .
drwxr-xr-x 1 root root  4096 Apr 21 07:03 ..
drwxr-xr-x 2 root root 49152 Apr 21 07:03 Normal
drwxr-xr-x 2 root root 32768 Apr 21 07:03 Stroke
</code></pre><p>The dataset contains both normal and stroke images respectively in the <code>Normal</code> and <code>Stroke</code> folders.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=err>!</span><span class=n>ls</span> <span class=n>brain_ct_data</span><span class=o>/</span><span class=n>Normal</span> <span class=o>|</span> <span class=n>head</span>
</span></span></code></pre></div><pre><code>100 (10).jpg
100 (11).jpg
100 (12).jpg
100 (13).jpg
100 (14).jpg
100 (15).jpg
100 (16).jpg
100 (17).jpg
100 (18).jpg
100 (19).jpg
</code></pre><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=err>!</span><span class=n>ls</span> <span class=n>brain_ct_data</span><span class=o>/</span><span class=n>Stroke</span> <span class=o>|</span> <span class=n>head</span>
</span></span></code></pre></div><pre><code>58 (10).jpg
58 (11).jpg
58 (12).jpg
58 (13).jpg
58 (15).jpg
58 (17).jpg
58 (18).jpg
58 (19).jpg
58 (1).jpg
58 (20).jpg
</code></pre><p>It is important to clarify the dataset does not contain CT scans, which are usually provided as DICOM or NIfTI files, but the CT scan slices in JPEG format (most probably extracted from DICOM or NIfTI files). A previous <a href=https://www.peco602.com/post/0090-python-dicom/ target=_blank rel=noopener>post</a> clearly explains how to extract slice images from a DICOM file. Giving a further look to the slice images it is easy to understand the naming convention <code>PATIENT_ID (SLICE_ID).jpg</code>, e.g. <code>49 (1).jpg</code>, <code>49 (2).jpg</code> and for each patient ID several slices are available. The following function is able to plot up to 40 slices (if available) for a specific patient ID.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>imageio.v2</span> <span class=k>as</span> <span class=nn>imageio</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>plot_scan_from_path</span><span class=p>(</span><span class=n>slices_path</span><span class=p>,</span> <span class=n>patient_id</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Plot 40 slices for a patient ID&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>num_rows</span> <span class=o>=</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl>    <span class=n>num_columns</span> <span class=o>=</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl>    <span class=n>factor</span> <span class=o>=</span> <span class=mf>1.2</span>
</span></span><span class=line><span class=cl>    <span class=n>f</span><span class=p>,</span> <span class=n>axarr</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>num_rows</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>num_columns</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=n>num_columns</span><span class=o>*</span><span class=n>factor</span><span class=p>,</span> <span class=n>num_rows</span><span class=o>*</span><span class=n>factor</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>f</span><span class=o>.</span><span class=n>suptitle</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Patient </span><span class=si>{</span><span class=n>patient_id</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=mf>1.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>image_id</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_rows</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_columns</span><span class=p>):</span>
</span></span><span class=line><span class=cl>          <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>img</span> <span class=o>=</span> <span class=n>imageio</span><span class=o>.</span><span class=n>imread</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>slices_path</span><span class=si>}</span><span class=s1>/</span><span class=si>{</span><span class=n>patient_id</span><span class=si>}</span><span class=s1> (</span><span class=si>{</span><span class=n>image_id</span><span class=si>}</span><span class=s1>).jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>          <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=n>e</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>img</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=mi>2</span><span class=p>,</span><span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl>          <span class=k>finally</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>axarr</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>]</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>img</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;gray&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>axarr</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>]</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>image_id</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>subplots_adjust</span><span class=p>(</span><span class=n>wspace</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>hspace</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>left</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>right</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>bottom</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>top</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><p>Let&rsquo;s start with patient 49:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>plot_scan_from_path</span><span class=p>(</span><span class=n>slices_path</span><span class=o>=</span><span class=s1>&#39;brain_ct_data/Normal&#39;</span><span class=p>,</span> <span class=n>patient_id</span><span class=o>=</span><span class=mi>49</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>No such file: '/content/brain_ct_data/Normal/49 (34).jpg'
No such file: '/content/brain_ct_data/Normal/49 (35).jpg'
No such file: '/content/brain_ct_data/Normal/49 (36).jpg'
No such file: '/content/brain_ct_data/Normal/49 (37).jpg'
No such file: '/content/brain_ct_data/Normal/49 (38).jpg'
No such file: '/content/brain_ct_data/Normal/49 (39).jpg'
No such file: '/content/brain_ct_data/Normal/49 (40).jpg'
</code></pre><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_12_1_huc963a19fa5ec2ba52755c9d2ef9de032_461685_3f7106727f0c2778f8e21b0eb6afd6c0.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_12_1_huc963a19fa5ec2ba52755c9d2ef9de032_461685_c6fe155206152789e6d5ee9ddd210bf8.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_12_1_huc963a19fa5ec2ba52755c9d2ef9de032_461685_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_12_1_huc963a19fa5ec2ba52755c9d2ef9de032_461685_3f7106727f0c2778f8e21b0eb6afd6c0.webp width=760 height=341 loading=lazy data-zoomable></div></div></figure></p><p>Patient 49 has 33 slices, but it is fundamental to underline the slices are not correctly sorted. It seems the slices go from the middle of the head to the top, but then they suddenly start back from the bottom. This may be among the reasons the dataset usability is low. This may not be an issue for a 2D CNN since it takes single images as input, but is a big obstacle for a 3D CNN where the volumetric representation of the brain is needed.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>plot_scan_from_path</span><span class=p>(</span><span class=n>slices_path</span><span class=o>=</span><span class=s1>&#39;brain_ct_data/Normal&#39;</span><span class=p>,</span> <span class=n>patient_id</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>No such file: '/content/brain_ct_data/Normal/50 (13).jpg'
No such file: '/content/brain_ct_data/Normal/50 (15).jpg'
No such file: '/content/brain_ct_data/Normal/50 (17).jpg'
No such file: '/content/brain_ct_data/Normal/50 (19).jpg'
No such file: '/content/brain_ct_data/Normal/50 (21).jpg'
No such file: '/content/brain_ct_data/Normal/50 (23).jpg'
No such file: '/content/brain_ct_data/Normal/50 (25).jpg'
No such file: '/content/brain_ct_data/Normal/50 (27).jpg'
No such file: '/content/brain_ct_data/Normal/50 (29).jpg'
No such file: '/content/brain_ct_data/Normal/50 (31).jpg'
No such file: '/content/brain_ct_data/Normal/50 (33).jpg'
No such file: '/content/brain_ct_data/Normal/50 (35).jpg'
No such file: '/content/brain_ct_data/Normal/50 (39).jpg'
No such file: '/content/brain_ct_data/Normal/50 (40).jpg'
</code></pre><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_14_1_hua93f85e75ba7dbad122c7ea96b652984_280958_dc1ecbaf713a0954b5fb12763c9fdae4.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_14_1_hua93f85e75ba7dbad122c7ea96b652984_280958_ac03d8b9be67e9f5a82fdc76eab4ebfd.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_14_1_hua93f85e75ba7dbad122c7ea96b652984_280958_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_14_1_hua93f85e75ba7dbad122c7ea96b652984_280958_dc1ecbaf713a0954b5fb12763c9fdae4.webp width=760 height=341 loading=lazy data-zoomable></div></div></figure></p><p>For patient 50 the situation is even worse: there are holes in slice sequence, which makes dataset importing even more difficult.</p><h2 id=dataset-fixing>Dataset fixing</h2><p>Before going deeper into modeling it is necessary to try to fix the dataset otherwise it is quite difficult to expect good results. If you are not interested in this section you can skip it and directly jump to the next one since the fixed dataset is also already available on my Github profile.</p><p>The fixing consists of correctly sorting the slices and removing the existing holes. The idea is to create a dictionary where each key represents a patient ID, while the value is the list of correctly sorted images. The creation of such a dictionary was quite demanding since it required to visually analyze the entire dataset to try to determine the correct sequence for each patient.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>INPUT_PATH</span><span class=o>=</span><span class=s1>&#39;brain_ct_data&#39;</span>
</span></span><span class=line><span class=cl><span class=n>OUTPUT_PATH</span><span class=o>=</span><span class=s1>&#39;brain_ct_data_fixed&#39;</span>
</span></span><span class=line><span class=cl><span class=n>NORMAL_INPUT_PATH</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>INPUT_PATH</span><span class=si>}</span><span class=s1>/Normal&#39;</span>
</span></span><span class=line><span class=cl><span class=n>NORMAL_OUTPUT_PATH</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>OUTPUT_PATH</span><span class=si>}</span><span class=s1>/Normal&#39;</span>
</span></span><span class=line><span class=cl><span class=n>STROKE_INPUT_PATH</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>INPUT_PATH</span><span class=si>}</span><span class=s1>/Stroke&#39;</span>
</span></span><span class=line><span class=cl><span class=n>STROKE_OUTPUT_PATH</span><span class=o>=</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>OUTPUT_PATH</span><span class=si>}</span><span class=s1>/Stroke&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>NORMAL_SORTING_CONFIG</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=mi>49</span><span class=p>:</span>  <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>50</span><span class=p>:</span>  <span class=p>[</span><span class=mi>36</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>34</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>51</span><span class=p>:</span>  <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>40</span><span class=p>,</span> <span class=mi>42</span><span class=p>,</span> <span class=mi>44</span><span class=p>,</span> <span class=mi>46</span><span class=p>,</span> <span class=mi>48</span><span class=p>,</span> <span class=mi>50</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>52</span><span class=p>:</span>  <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>39</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>53</span><span class=p>:</span>  <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>39</span><span class=p>,</span> <span class=mi>41</span><span class=p>,</span> <span class=mi>43</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>54</span><span class=p>:</span>  <span class=p>[</span><span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>55</span><span class=p>:</span>  <span class=p>[</span><span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>56</span><span class=p>:</span>  <span class=p>[</span><span class=mi>33</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>57</span><span class=p>:</span>  <span class=p>[</span><span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>59</span><span class=p>:</span>  <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>60</span><span class=p>:</span>  <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>61</span><span class=p>:</span>  <span class=p>[</span><span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>62</span><span class=p>:</span>  <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>63</span><span class=p>:</span>  <span class=p>[</span><span class=mi>33</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>64</span><span class=p>:</span>  <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>65</span><span class=p>:</span>  <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>95</span><span class=p>:</span>  <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>96</span><span class=p>:</span>  <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>98</span><span class=p>:</span>  <span class=p>[</span><span class=mi>29</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>99</span><span class=p>:</span>  <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>100</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>101</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>102</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>103</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>104</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>105</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>106</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>107</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>108</span><span class=p>:</span> <span class=p>[</span><span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>109</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>110</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>111</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>112</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>113</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>114</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>115</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>116</span><span class=p>:</span> <span class=p>[</span><span class=mi>31</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>117</span><span class=p>:</span> <span class=p>[</span><span class=mi>29</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>118</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>119</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>120</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>121</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>122</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>123</span><span class=p>:</span> <span class=p>[</span><span class=mi>39</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>38</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>124</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>125</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>39</span><span class=p>,</span> <span class=mi>40</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>126</span><span class=p>:</span> <span class=p>[</span><span class=mi>30</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>127</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>128</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>129</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>130</span><span class=p>:</span> <span class=p>[</span><span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>],</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>STROKE_SORTING_CONFIG</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=mi>58</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>66</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>39</span><span class=p>,</span> <span class=mi>40</span><span class=p>,</span> <span class=mi>41</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>67</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>68</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>69</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>70</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>39</span><span class=p>,</span> <span class=mi>41</span><span class=p>,</span> <span class=mi>42</span><span class=p>,</span> <span class=mi>43</span><span class=p>,</span> <span class=mi>44</span><span class=p>,</span> <span class=mi>45</span><span class=p>,</span> <span class=mi>46</span><span class=p>,</span> <span class=mi>47</span><span class=p>,</span> <span class=mi>48</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>71</span><span class=p>:</span> <span class=p>[</span><span class=mi>48</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>40</span><span class=p>,</span> <span class=mi>42</span><span class=p>,</span> <span class=mi>44</span><span class=p>,</span> <span class=mi>46</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>72</span><span class=p>:</span> <span class=p>[</span><span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>73</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>39</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>74</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>39</span><span class=p>,</span> <span class=mi>40</span><span class=p>,</span> <span class=mi>41</span><span class=p>,</span> <span class=mi>42</span><span class=p>,</span> <span class=mi>43</span><span class=p>,</span> <span class=mi>44</span><span class=p>,</span> <span class=mi>45</span><span class=p>,</span> <span class=mi>46</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>75</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>40</span><span class=p>,</span> <span class=mi>42</span><span class=p>,</span> <span class=mi>44</span><span class=p>,</span> <span class=mi>46</span><span class=p>,</span> <span class=mi>48</span><span class=p>,</span> <span class=mi>49</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>76</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>39</span><span class=p>,</span> <span class=mi>40</span><span class=p>,</span> <span class=mi>41</span><span class=p>,</span> <span class=mi>42</span><span class=p>,</span> <span class=mi>43</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>77</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>39</span><span class=p>,</span> <span class=mi>40</span><span class=p>,</span> <span class=mi>41</span><span class=p>,</span> <span class=mi>42</span><span class=p>,</span> <span class=mi>43</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>78</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>39</span><span class=p>,</span> <span class=mi>40</span><span class=p>,</span> <span class=mi>41</span><span class=p>,</span> <span class=mi>42</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>79</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>80</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>39</span><span class=p>,</span> <span class=mi>40</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>81</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>39</span><span class=p>,</span> <span class=mi>41</span><span class=p>,</span> <span class=mi>43</span><span class=p>,</span> <span class=mi>44</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>82</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>83</span><span class=p>:</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>84</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>39</span><span class=p>,</span> <span class=mi>40</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>85</span><span class=p>:</span> <span class=p>[</span><span class=mi>21</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>86</span><span class=p>:</span> <span class=p>[</span><span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>87</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>39</span><span class=p>,</span> <span class=mi>40</span><span class=p>,</span> <span class=mi>41</span><span class=p>,</span> <span class=mi>42</span><span class=p>,</span> <span class=mi>43</span><span class=p>,</span> <span class=mi>44</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>88</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>37</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>89</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>39</span><span class=p>,</span> <span class=mi>40</span><span class=p>,</span> <span class=mi>41</span><span class=p>,</span> <span class=mi>42</span><span class=p>,</span> <span class=mi>43</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>90</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>91</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>39</span><span class=p>,</span> <span class=mi>40</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>92</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>40</span><span class=p>,</span> <span class=mi>42</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>93</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>94</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>17</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>19</span><span class=p>,</span> <span class=mi>21</span><span class=p>,</span> <span class=mi>23</span><span class=p>,</span> <span class=mi>25</span><span class=p>,</span> <span class=mi>27</span><span class=p>,</span> <span class=mi>29</span><span class=p>,</span> <span class=mi>31</span><span class=p>,</span> <span class=mi>33</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>39</span><span class=p>,</span> <span class=mi>41</span><span class=p>,</span> <span class=mi>43</span><span class=p>,</span> <span class=mi>44</span><span class=p>,</span> <span class=mi>45</span><span class=p>,</span> <span class=mi>46</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=mi>97</span><span class=p>:</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>11</span><span class=p>,</span> <span class=mi>12</span><span class=p>,</span> <span class=mi>13</span><span class=p>,</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>18</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>22</span><span class=p>,</span> <span class=mi>24</span><span class=p>,</span> <span class=mi>26</span><span class=p>,</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>30</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>34</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>36</span><span class=p>,</span> <span class=mi>37</span><span class=p>,</span> <span class=mi>38</span><span class=p>,</span> <span class=mi>39</span><span class=p>,</span> <span class=mi>40</span><span class=p>],</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Given both the <code>NORMAL_SORTING_CONFIG</code> and <code>STROKE_SORTING_CONFIG</code> it is just a matter of copying all the slices in the correct order to a different path, i.e., <code>brain_ct_data_fixed</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>shutil</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>sort_slices</span><span class=p>(</span><span class=n>input_path</span><span class=p>,</span> <span class=n>output_path</span><span class=p>,</span> <span class=n>patient_id</span><span class=p>,</span> <span class=n>order</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;Copy the slices in the correct order&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=c1># Create output folder for sorted images (if it does not exist)</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>output_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=n>output_path</span><span class=p>,</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># Move the image to the output path with a name based on the correct sorting order</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>new_id</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>order</span><span class=p>)</span><span class=o>+</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>old_id</span> <span class=o>=</span> <span class=n>order</span><span class=p>[</span><span class=n>new_id</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>shutil</span><span class=o>.</span><span class=n>copyfile</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>input_path</span><span class=si>}{</span><span class=n>os</span><span class=o>.</span><span class=n>sep</span><span class=si>}{</span><span class=n>patient_id</span><span class=si>}</span><span class=s1> (</span><span class=si>{</span><span class=n>old_id</span><span class=si>}</span><span class=s1>).jpg&#39;</span><span class=p>,</span> <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>output_path</span><span class=si>}{</span><span class=n>os</span><span class=o>.</span><span class=n>sep</span><span class=si>}{</span><span class=n>patient_id</span><span class=si>}</span><span class=s1> (</span><span class=si>{</span><span class=n>new_id</span><span class=si>}</span><span class=s1>).jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Normal slices sorting</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>patient_id</span><span class=p>,</span> <span class=n>order</span> <span class=ow>in</span> <span class=n>NORMAL_SORTING_CONFIG</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>sort_slices</span><span class=p>(</span>
</span></span><span class=line><span class=cl>      <span class=n>input_path</span><span class=o>=</span><span class=n>NORMAL_INPUT_PATH</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=n>output_path</span><span class=o>=</span><span class=n>NORMAL_OUTPUT_PATH</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=n>patient_id</span><span class=o>=</span><span class=n>patient_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=n>order</span><span class=o>=</span><span class=n>order</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Stroke slices sorting</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>patient_id</span><span class=p>,</span> <span class=n>order</span> <span class=ow>in</span> <span class=n>STROKE_SORTING_CONFIG</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>sort_slices</span><span class=p>(</span>
</span></span><span class=line><span class=cl>      <span class=n>input_path</span><span class=o>=</span><span class=n>STROKE_INPUT_PATH</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=n>output_path</span><span class=o>=</span><span class=n>STROKE_OUTPUT_PATH</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=n>patient_id</span><span class=o>=</span><span class=n>patient_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=n>order</span><span class=o>=</span><span class=n>order</span><span class=p>)</span>
</span></span></code></pre></div><p>Let&rsquo;s try to plot again CT slices for both patients 49 and 50:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>plot_scan_from_path</span><span class=p>(</span><span class=n>slices_path</span><span class=o>=</span><span class=n>NORMAL_OUTPUT_PATH</span><span class=p>,</span> <span class=n>patient_id</span><span class=o>=</span><span class=mi>49</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>No such file: '/content/brain_ct_data_fixed/Normal/49 (34).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/49 (35).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/49 (36).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/49 (37).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/49 (38).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/49 (39).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/49 (40).jpg'
</code></pre><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_23_1_hue7baffb15e2b06ed500a09d7e814e006_457306_5a1a31fd2f83adb87428afa381a425b6.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_23_1_hue7baffb15e2b06ed500a09d7e814e006_457306_85195e1f0bc019970566c46c7cac0ce1.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_23_1_hue7baffb15e2b06ed500a09d7e814e006_457306_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_23_1_hue7baffb15e2b06ed500a09d7e814e006_457306_5a1a31fd2f83adb87428afa381a425b6.webp width=760 height=341 loading=lazy data-zoomable></div></div></figure></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>plot_scan_from_path</span><span class=p>(</span><span class=n>slices_path</span><span class=o>=</span><span class=n>NORMAL_OUTPUT_PATH</span><span class=p>,</span> <span class=n>patient_id</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>No such file: '/content/brain_ct_data_fixed/Normal/50 (27).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (28).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (29).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (30).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (31).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (32).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (33).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (34).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (35).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (36).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (37).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (38).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (39).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (40).jpg'
</code></pre><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_24_1_hud597068fbe2ffaf25f9d80b7e7f9023e_269313_89af5f95a5d6c36dbb15e8dcfc680651.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_24_1_hud597068fbe2ffaf25f9d80b7e7f9023e_269313_cfc8367cabdca8aa5d123000be5426a9.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_24_1_hud597068fbe2ffaf25f9d80b7e7f9023e_269313_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_24_1_hud597068fbe2ffaf25f9d80b7e7f9023e_269313_89af5f95a5d6c36dbb15e8dcfc680651.webp width=760 height=341 loading=lazy data-zoomable></div></div></figure></p><p>Hopefully, the dataset should be fixed now. The fixed dataset is publicly available <a href=https://github.com/Peco602/brain-stroke-detection-3d-cnn/releases/download/v0.0.1/brain_ct_data_fixed.zip target=_blank rel=noopener>here</a>.</p><h2 id=dataset-loading-and-preprocessing>Dataset loading and preprocessing</h2><p>In case the previous section has been skipped, it is possible to directly download the fixed dataset:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>zipfile</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>tensorflow</span> <span class=k>as</span> <span class=nn>tf</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Download dataset from Github</span>
</span></span><span class=line><span class=cl><span class=n>url</span> <span class=o>=</span> <span class=s2>&#34;https://github.com/Peco602/brain-stroke-detection-3d-cnn/releases/download/v0.0.1/brain_ct_data_fixed.zip&#34;</span>
</span></span><span class=line><span class=cl><span class=n>filename</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>getcwd</span><span class=p>(),</span> <span class=s2>&#34;brain_ct_data_fixed.zip&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>get_file</span><span class=p>(</span><span class=n>filename</span><span class=p>,</span> <span class=n>url</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Unzip dataset</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>zipfile</span><span class=o>.</span><span class=n>ZipFile</span><span class=p>(</span><span class=s2>&#34;brain_ct_data_fixed.zip&#34;</span><span class=p>,</span> <span class=s2>&#34;r&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>z_fp</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>z_fp</span><span class=o>.</span><span class=n>extractall</span><span class=p>(</span><span class=s2>&#34;.&#34;</span><span class=p>)</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>NORMAL_PATH</span> <span class=o>=</span> <span class=s1>&#39;/content/brain_ct_data_fixed/Normal&#39;</span>
</span></span><span class=line><span class=cl><span class=n>STROKE_PATH</span> <span class=o>=</span> <span class=s1>&#39;/content/brain_ct_data_fixed/Stroke&#39;</span>
</span></span></code></pre></div><p>Before going deeper into data loading it can be interesting to give a look to a single CT slice.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>imageio.v2</span> <span class=k>as</span> <span class=nn>imageio</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>imageio</span><span class=o>.</span><span class=n>imread</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>STROKE_PATH</span><span class=si>}</span><span class=s1>/67 (15).jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s2>&#34;gray&#34;</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>&lt;matplotlib.image.AxesImage at 0x7fa302346580&gt;
</code></pre><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_33_1_hu6da8c0fe3b25fbfa39434b0c715dccc7_68014_f27d4e0683adc9b564964c00c667f76d.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_33_1_hu6da8c0fe3b25fbfa39434b0c715dccc7_68014_af54b659c6ed639b0bd7ff80c03d2d53.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_33_1_hu6da8c0fe3b25fbfa39434b0c715dccc7_68014_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_33_1_hu6da8c0fe3b25fbfa39434b0c715dccc7_68014_f27d4e0683adc9b564964c00c667f76d.webp width=425 height=418 loading=lazy data-zoomable></div></div></figure></p><p>As it is possible to see, the image presents some artifacts that may hinder the CNN training process. <a href=https://vincentblog.xyz/posts/medical-images-in-python-computed-tomography target=_blank rel=noopener>Vicente Rodrguez</a> provided a nice example of CT image denoising that lead to the creation of the following <code>remove_noise</code> function:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scipy</span> <span class=kn>import</span> <span class=n>ndimage</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>skimage</span> <span class=kn>import</span> <span class=n>morphology</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>remove_noise</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>display</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;Remove slice noise&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=c1># morphology.dilation creates a segmentation of the image</span>
</span></span><span class=line><span class=cl>  <span class=c1># If one pixel is between the origin and the edge of a square of size</span>
</span></span><span class=line><span class=cl>  <span class=c1># 3x3, the pixel belongs to the same class</span>
</span></span><span class=line><span class=cl>  <span class=n>segmentation</span> <span class=o>=</span> <span class=n>morphology</span><span class=o>.</span><span class=n>dilation</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>ones</span><span class=p>((</span><span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>  <span class=n>segmentation</span><span class=p>[</span><span class=n>segmentation</span> <span class=o>&lt;</span> <span class=mi>25</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>  <span class=n>segmentation</span><span class=p>[</span><span class=n>segmentation</span> <span class=o>&gt;</span> <span class=mi>25</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>  <span class=n>labels</span><span class=p>,</span> <span class=n>label_nb</span> <span class=o>=</span> <span class=n>ndimage</span><span class=o>.</span><span class=n>label</span><span class=p>(</span><span class=n>segmentation</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>label_count</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>bincount</span><span class=p>(</span><span class=n>labels</span><span class=o>.</span><span class=n>ravel</span><span class=p>()</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>int</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># The size of label_count is the number of classes/segmentations found.</span>
</span></span><span class=line><span class=cl>  <span class=c1># The first class is not used since it&#39;s the background.</span>
</span></span><span class=line><span class=cl>  <span class=n>label_count</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># A mask with the class with more pixels is created</span>
</span></span><span class=line><span class=cl>  <span class=c1># since it should represent the brain</span>
</span></span><span class=line><span class=cl>  <span class=n>mask</span> <span class=o>=</span> <span class=n>labels</span> <span class=o>==</span> <span class=n>label_count</span><span class=o>.</span><span class=n>argmax</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># Improve the brain mask</span>
</span></span><span class=line><span class=cl>  <span class=n>mask</span> <span class=o>=</span> <span class=n>morphology</span><span class=o>.</span><span class=n>dilation</span><span class=p>(</span><span class=n>mask</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>ones</span><span class=p>((</span><span class=mi>5</span><span class=p>,</span> <span class=mi>5</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>  <span class=n>mask</span> <span class=o>=</span> <span class=n>ndimage</span><span class=o>.</span><span class=n>binary_fill_holes</span><span class=p>(</span><span class=n>mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>mask</span> <span class=o>=</span> <span class=n>morphology</span><span class=o>.</span><span class=n>dilation</span><span class=p>(</span><span class=n>mask</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>ones</span><span class=p>((</span><span class=mi>3</span><span class=p>,</span> <span class=mi>3</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># Since the pixels in the mask are zeros and ones,</span>
</span></span><span class=line><span class=cl>  <span class=c1># it is possible to multiple the original image to only keep the brain region</span>
</span></span><span class=line><span class=cl>  <span class=n>masked_image</span> <span class=o>=</span> <span class=n>mask</span> <span class=o>*</span> <span class=n>image</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=n>display</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mf>2.5</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>141</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=n>plt</span><span class=o>.</span><span class=n>cm</span><span class=o>.</span><span class=n>bone</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Original Image&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>142</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>mask</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=n>plt</span><span class=o>.</span><span class=n>cm</span><span class=o>.</span><span class=n>bone</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Mask&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>143</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>masked_image</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=n>plt</span><span class=o>.</span><span class=n>cm</span><span class=o>.</span><span class=n>bone</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Clean Image&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>masked_image</span>
</span></span></code></pre></div><p>So, let&rsquo;s try to remove the background artifacts from the image:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>denoised_image</span> <span class=o>=</span> <span class=n>remove_noise</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>display</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_37_0_hu71a993d8bd84808ac3773613cf8720b6_33679_a2dd6492daff2eae4b74b9b3168c4196.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_37_0_hu71a993d8bd84808ac3773613cf8720b6_33679_76f74d80e418c4fd1a719eedbf282976.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_37_0_hu71a993d8bd84808ac3773613cf8720b6_33679_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_37_0_hu71a993d8bd84808ac3773613cf8720b6_33679_a2dd6492daff2eae4b74b9b3168c4196.webp width=592 height=210 loading=lazy data-zoomable></div></div></figure></p><p>As expected, the CT artifacts are not present anymore.</p><p>It is worth noting despite the CT slices have been correctly sorted and there are no holes in slice sequences anymore, the dataset is still not so straightforward to import since the number of slices per patient is not
always the same. The <code>load_dataset</code> function appears quite complex because it has to execute in sequence multiple steps to load and pre-process the entire image dataset:</p><ol><li><code>count_slices</code>: counts the number of slices per patient</li><li><code>merge_slices</code>: denoises (optionally) and merges all patient slices into a single scan</li><li><code>normalize_scan</code>: normalizes the scan values to the interval <code>[0, 1]</code></li><li><code>resize_scan</code>: resizes the scan across x, y and z axis to uniform the scan sizes to fixed values</li></ol><p>Finally, the returned dataset is a 4D array, i.e., an array of scans (3D images).</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>tqdm</span> <span class=kn>import</span> <span class=n>tqdm</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>resize_scan</span><span class=p>(</span><span class=n>scan</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;Resize the CT scan to a desired uniform size across all axis&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=c1># Set the desired depth</span>
</span></span><span class=line><span class=cl>  <span class=n>desired_depth</span> <span class=o>=</span> <span class=mi>64</span>
</span></span><span class=line><span class=cl>  <span class=n>desired_width</span> <span class=o>=</span> <span class=mi>128</span>
</span></span><span class=line><span class=cl>  <span class=n>desired_height</span> <span class=o>=</span> <span class=mi>128</span>
</span></span><span class=line><span class=cl>  <span class=c1># Get current depth</span>
</span></span><span class=line><span class=cl>  <span class=n>current_depth</span> <span class=o>=</span> <span class=n>scan</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=n>current_width</span> <span class=o>=</span> <span class=n>scan</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=n>current_height</span> <span class=o>=</span> <span class=n>scan</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=c1># Compute depth factor</span>
</span></span><span class=line><span class=cl>  <span class=n>depth</span> <span class=o>=</span> <span class=n>current_depth</span> <span class=o>/</span> <span class=n>desired_depth</span>
</span></span><span class=line><span class=cl>  <span class=n>width</span> <span class=o>=</span> <span class=n>current_width</span> <span class=o>/</span> <span class=n>desired_width</span>
</span></span><span class=line><span class=cl>  <span class=n>height</span> <span class=o>=</span> <span class=n>current_height</span> <span class=o>/</span> <span class=n>desired_height</span>
</span></span><span class=line><span class=cl>  <span class=n>depth_factor</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>depth</span>
</span></span><span class=line><span class=cl>  <span class=n>width_factor</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>width</span>
</span></span><span class=line><span class=cl>  <span class=n>height_factor</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=n>height</span>
</span></span><span class=line><span class=cl>  <span class=c1># Rotate</span>
</span></span><span class=line><span class=cl>  <span class=n>scan</span> <span class=o>=</span> <span class=n>ndimage</span><span class=o>.</span><span class=n>rotate</span><span class=p>(</span><span class=n>scan</span><span class=p>,</span> <span class=mi>90</span><span class=p>,</span> <span class=n>reshape</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># Resize across z-axis</span>
</span></span><span class=line><span class=cl>  <span class=n>scan</span> <span class=o>=</span> <span class=n>ndimage</span><span class=o>.</span><span class=n>zoom</span><span class=p>(</span><span class=n>scan</span><span class=p>,</span> <span class=p>(</span><span class=n>width_factor</span><span class=p>,</span> <span class=n>height_factor</span><span class=p>,</span> <span class=n>depth_factor</span><span class=p>),</span> <span class=n>order</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>scan</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>normalize_scan</span><span class=p>(</span><span class=n>scan</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;Normalize the scan to the interval [0, 1]&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=nb>min</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>  <span class=nb>max</span> <span class=o>=</span> <span class=mi>255</span>
</span></span><span class=line><span class=cl>  <span class=n>scan</span><span class=p>[</span><span class=n>scan</span> <span class=o>&lt;</span> <span class=nb>min</span><span class=p>]</span> <span class=o>=</span> <span class=nb>min</span>
</span></span><span class=line><span class=cl>  <span class=n>scan</span><span class=p>[</span><span class=n>scan</span> <span class=o>&gt;</span> <span class=nb>max</span><span class=p>]</span> <span class=o>=</span> <span class=nb>max</span>
</span></span><span class=line><span class=cl>  <span class=n>scan</span> <span class=o>=</span> <span class=p>(</span><span class=n>scan</span> <span class=o>-</span> <span class=nb>min</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=nb>max</span> <span class=o>-</span> <span class=nb>min</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>scan</span> <span class=o>=</span> <span class=n>scan</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=s2>&#34;float32&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>scan</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>merge_slices</span><span class=p>(</span><span class=n>path</span><span class=p>,</span> <span class=n>patient_id</span><span class=p>,</span> <span class=n>slice_count</span><span class=p>,</span> <span class=n>denoise</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;Merge all the slices for a patient into a scan&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=n>denoise</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>scan</span> <span class=o>=</span> <span class=nb>tuple</span><span class=p>(</span><span class=n>remove_noise</span><span class=p>(</span><span class=n>imageio</span><span class=o>.</span><span class=n>imread</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>path</span><span class=si>}</span><span class=s1>/</span><span class=si>{</span><span class=n>patient_id</span><span class=si>}</span><span class=s1> (</span><span class=si>{</span><span class=n>slice_id</span><span class=si>}</span><span class=s1>).jpg&#39;</span><span class=p>))</span> <span class=k>for</span> <span class=n>slice_id</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>slice_count</span><span class=o>+</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>scan</span> <span class=o>=</span> <span class=nb>tuple</span><span class=p>(</span><span class=n>imageio</span><span class=o>.</span><span class=n>imread</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>path</span><span class=si>}</span><span class=s1>/</span><span class=si>{</span><span class=n>patient_id</span><span class=si>}</span><span class=s1> (</span><span class=si>{</span><span class=n>slice_id</span><span class=si>}</span><span class=s1>).jpg&#39;</span><span class=p>)</span> <span class=k>for</span> <span class=n>slice_id</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>slice_count</span><span class=o>+</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>dstack</span><span class=p>(</span><span class=n>scan</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>count_slices</span><span class=p>(</span><span class=n>path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;Analyze the slices path and returns a dictionary with the slices count associated to each patient&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=n>slice_dict</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>dirname</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>filenames</span> <span class=ow>in</span> <span class=n>os</span><span class=o>.</span><span class=n>walk</span><span class=p>(</span><span class=n>path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=k>for</span> <span class=n>filename</span> <span class=ow>in</span> <span class=n>filenames</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>patient_id</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>filename</span><span class=o>.</span><span class=n>split</span><span class=p>()[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>patient_id</span> <span class=ow>not</span> <span class=ow>in</span> <span class=n>slice_dict</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=n>slice_dict</span><span class=p>[</span><span class=n>patient_id</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=n>slice_dict</span><span class=p>[</span><span class=n>patient_id</span><span class=p>]</span> <span class=o>=</span> <span class=n>slice_dict</span><span class=p>[</span><span class=n>patient_id</span><span class=p>]</span> <span class=o>+</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>slice_dict</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>collect_scan</span><span class=p>(</span><span class=n>path</span><span class=p>,</span> <span class=n>patient_id</span><span class=p>,</span> <span class=n>slice_count</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;Collect a scan for a patient id&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=c1># Get a single CT scan by merging all the slices from a single patient</span>
</span></span><span class=line><span class=cl>  <span class=c1># Before getting merged the slices are also denoised</span>
</span></span><span class=line><span class=cl>  <span class=n>scan</span> <span class=o>=</span> <span class=n>merge_slices</span><span class=p>(</span><span class=n>path</span><span class=p>,</span> <span class=n>patient_id</span><span class=p>,</span> <span class=n>slice_count</span><span class=p>,</span> <span class=n>denoise</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># Normalize the CT scan to the interval [0, 1]</span>
</span></span><span class=line><span class=cl>  <span class=n>scan</span> <span class=o>=</span> <span class=n>normalize_scan</span><span class=p>(</span><span class=n>scan</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># Resize the CT scan to uniform the size</span>
</span></span><span class=line><span class=cl>  <span class=n>scan</span> <span class=o>=</span> <span class=n>resize_scan</span><span class=p>(</span><span class=n>scan</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>scan</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_dataset</span><span class=p>(</span><span class=n>path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;Return the scans dataset as a 4D array&#34;&#34;&#34;</span> 
</span></span><span class=line><span class=cl>  <span class=c1># Get a dictionary with patient IDs and slice count per patient</span>
</span></span><span class=line><span class=cl>  <span class=n>slices_dict</span> <span class=o>=</span> <span class=n>count_slices</span><span class=p>(</span><span class=n>path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># Collect scans for each patient id</span>
</span></span><span class=line><span class=cl>  <span class=n>dataset</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=n>collect_scan</span><span class=p>(</span><span class=n>path</span><span class=p>,</span> <span class=n>patient_id</span><span class=p>,</span> <span class=n>slice_count</span><span class=p>)</span> <span class=k>for</span> <span class=n>patient_id</span><span class=p>,</span> <span class=n>slice_count</span> <span class=ow>in</span> <span class=n>tqdm</span><span class=p>(</span><span class=n>slices_dict</span><span class=o>.</span><span class=n>items</span><span class=p>())])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>dataset</span>
</span></span></code></pre></div><p>Both the normal and stroke datasets are imported from the respective paths. Since the process can take some minutes the <code>tqdm</code> library can help to check the progress in realtime.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>normal_dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=n>path</span><span class=o>=</span><span class=n>NORMAL_PATH</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>stroke_dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=n>path</span><span class=o>=</span><span class=n>STROKE_PATH</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>100%|| 51/51 [02:55&lt;00:00,  3.44s/it]
100%|| 31/31 [01:41&lt;00:00,  3.27s/it]
</code></pre><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>normal_dataset</span><span class=o>.</span><span class=n>shape</span><span class=p>,</span> <span class=n>stroke_dataset</span><span class=o>.</span><span class=n>shape</span>
</span></span></code></pre></div><pre><code>((51, 128, 128, 64), (31, 128, 128, 64))
</code></pre><p>The normal and stroke datasets are represented by rank-3 tensors of shape <code>(samples, height, width, depth)</code>. There are 51 normal and 31 stroke CT scans so the dataset is quite unbalanced.</p><p>The function <code>plot_slices_from_dataset</code> can be used to plot an entire CT scan from the loaded dataset.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>plot_scan_from_dataset</span><span class=p>(</span><span class=n>num_rows</span><span class=p>,</span> <span class=n>num_columns</span><span class=p>,</span> <span class=n>width</span><span class=p>,</span> <span class=n>height</span><span class=p>,</span> <span class=n>data</span><span class=p>,</span> <span class=n>title</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;Plot a scan from dataset&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=p>(</span><span class=n>num_rows</span><span class=p>,</span> <span class=n>num_columns</span><span class=p>,</span> <span class=n>width</span><span class=p>,</span> <span class=n>height</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  <span class=n>rows_data</span><span class=p>,</span> <span class=n>columns_data</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>data</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=n>heights</span> <span class=o>=</span> <span class=p>[</span><span class=n>slc</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=k>for</span> <span class=n>slc</span> <span class=ow>in</span> <span class=n>data</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=n>widths</span> <span class=o>=</span> <span class=p>[</span><span class=n>slc</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=k>for</span> <span class=n>slc</span> <span class=ow>in</span> <span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>]]</span>
</span></span><span class=line><span class=cl>  <span class=n>fig_width</span> <span class=o>=</span> <span class=mf>12.0</span>
</span></span><span class=line><span class=cl>  <span class=n>fig_height</span> <span class=o>=</span> <span class=n>fig_width</span> <span class=o>*</span> <span class=nb>sum</span><span class=p>(</span><span class=n>heights</span><span class=p>)</span> <span class=o>/</span> <span class=nb>sum</span><span class=p>(</span><span class=n>widths</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>f</span><span class=p>,</span> <span class=n>axarr</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span>
</span></span><span class=line><span class=cl>      <span class=n>rows_data</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=n>columns_data</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=n>fig_width</span><span class=p>,</span> <span class=n>fig_height</span><span class=p>),</span>
</span></span><span class=line><span class=cl>      <span class=n>gridspec_kw</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;height_ratios&#34;</span><span class=p>:</span> <span class=n>heights</span><span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>f</span><span class=o>.</span><span class=n>suptitle</span><span class=p>(</span><span class=n>title</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=mf>1.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>rows_data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>columns_data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>          <span class=n>axarr</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>]</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>data</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>j</span><span class=p>],</span> <span class=n>cmap</span><span class=o>=</span><span class=s2>&#34;gray&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>          <span class=n>axarr</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=n>j</span><span class=p>]</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s2>&#34;off&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>plt</span><span class=o>.</span><span class=n>subplots_adjust</span><span class=p>(</span><span class=n>wspace</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>hspace</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>left</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>right</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>bottom</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>top</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></div><p>The first scan from both the normal and stroke datasets is shown hereafter.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>plot_scan_from_dataset</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>normal_dataset</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:],</span> <span class=s2>&#34;Normal CT scan&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_48_0_huaf6266c585d299ca05fdc57077781f89_285227_7166f948faf3249230e2de8af6c976e0.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_48_0_huaf6266c585d299ca05fdc57077781f89_285227_3b4cd910e4799c61b19be8ce51aae928.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_48_0_huaf6266c585d299ca05fdc57077781f89_285227_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_48_0_huaf6266c585d299ca05fdc57077781f89_285227_7166f948faf3249230e2de8af6c976e0.webp width=760 height=218 loading=lazy data-zoomable></div></div></figure></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>plot_scan_from_dataset</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>stroke_dataset</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:],</span> <span class=s2>&#34;Stroke CT scan&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_49_0_huf6a37d4a6ead960cadcc6717609e4865_287423_d719ee2f988cc8a0e696d1d0244622e3.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_49_0_huf6a37d4a6ead960cadcc6717609e4865_287423_e21288fe975de4d607cdbb449efd05e3.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_49_0_huf6a37d4a6ead960cadcc6717609e4865_287423_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_49_0_huf6a37d4a6ead960cadcc6717609e4865_287423_d719ee2f988cc8a0e696d1d0244622e3.webp width=760 height=218 loading=lazy data-zoomable></div></div></figure></p><p>Both the datasets are now splitted and merged into <code>training</code> and <code>validation</code> datasets with a ratio of 70% and 30%.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># For the CT scans having presence of stroke assign 1 otherwise 0.</span>
</span></span><span class=line><span class=cl><span class=n>normal_labels</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>0</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>normal_dataset</span><span class=p>))])</span>
</span></span><span class=line><span class=cl><span class=n>stroke_labels</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>1</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>stroke_dataset</span><span class=p>))])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Split data in the ratio 70%-30% for training and validation.</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>math</span>
</span></span><span class=line><span class=cl><span class=n>VALIDATION_SPLIT</span> <span class=o>=</span> <span class=mf>0.7</span>
</span></span><span class=line><span class=cl><span class=n>normal_train_len</span> <span class=o>=</span> <span class=n>math</span><span class=o>.</span><span class=n>ceil</span><span class=p>(</span><span class=n>VALIDATION_SPLIT</span><span class=o>*</span><span class=nb>len</span><span class=p>(</span><span class=n>normal_labels</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>stroke_train_len</span> <span class=o>=</span> <span class=n>math</span><span class=o>.</span><span class=n>ceil</span><span class=p>(</span><span class=n>VALIDATION_SPLIT</span><span class=o>*</span><span class=nb>len</span><span class=p>(</span><span class=n>stroke_labels</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>x_train</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>((</span><span class=n>normal_dataset</span><span class=p>[:</span><span class=n>normal_train_len</span><span class=p>],</span> <span class=n>stroke_dataset</span><span class=p>[:</span><span class=n>stroke_train_len</span><span class=p>]),</span> <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>y_train</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>((</span><span class=n>normal_labels</span><span class=p>[:</span><span class=n>normal_train_len</span><span class=p>],</span> <span class=n>stroke_labels</span><span class=p>[:</span><span class=n>stroke_train_len</span><span class=p>]),</span> <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>x_val</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>((</span><span class=n>normal_dataset</span><span class=p>[</span><span class=n>normal_train_len</span><span class=p>:],</span> <span class=n>stroke_dataset</span><span class=p>[</span><span class=n>stroke_train_len</span><span class=p>:]),</span> <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>y_val</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>((</span><span class=n>normal_labels</span><span class=p>[</span><span class=n>normal_train_len</span><span class=p>:],</span> <span class=n>stroke_labels</span><span class=p>[</span><span class=n>stroke_train_len</span><span class=p>:]),</span> <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Training samples&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Normal: </span><span class=si>{</span><span class=n>normal_train_len</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Stroke: </span><span class=si>{</span><span class=n>stroke_train_len</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Total: </span><span class=si>{</span><span class=n>x_train</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Validation samples&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Normal: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>normal_dataset</span><span class=p>)</span> <span class=o>-</span> <span class=n>normal_train_len</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Stroke: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>stroke_dataset</span><span class=p>)</span> <span class=o>-</span> <span class=n>stroke_train_len</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Total: </span><span class=si>{</span><span class=n>x_val</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>Training samples
Normal: 36
Stroke: 22
Total: 58

Validation samples
Normal: 15
Stroke: 9
Total: 24
</code></pre><h2 id=dataset-augmentation>Dataset augmentation</h2><p>A machine learning model performs better and is more accurate when the dataset is rich and sufficient. Deep learning in general, but particularly in medical imaging, requires a large amount of training data in order to obtain good performance and avoid overfitting. To meet these challenges, increasing the quantity of training data is a common solution. Data augmentation is a common approach to enhance the performance and the results of machine learning models. It allows a small dataset to be rebalanced or enriched for any reason (time-consuming manual annotations, lack of accessible data&mldr;). The augmentation techniques must make sense with respect to the type of analysis desired and therefore positively influence the performance of the model during the learning phase: by applying a large number of augmentations, the performance will not necessarily be better. There are several types of transformations for medical images, but few examples which can be seen as good starting point for CT scans are provided in the following.</p><h3 id=rotation>Rotation</h3><p>This transformation consists of rotating the original image according to a desired angle. In medical image analysis, this represents a common augmentation technique. In this case the scan is rotated around z-axis by a random angle in the interval <code>[-45, 45]</code> degrees.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>rotation_layer</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>RandomRotation</span><span class=p>(</span><span class=n>factor</span><span class=o>=</span><span class=p>(</span><span class=o>-</span><span class=mf>0.125</span><span class=p>,</span> <span class=mf>0.125</span><span class=p>),</span> <span class=n>fill_mode</span><span class=o>=</span><span class=s1>&#39;constant&#39;</span><span class=p>,</span> <span class=n>fill_value</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plot_scan_from_dataset</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>x_train</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:],</span> <span class=s2>&#34;Original CT Scan&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plot_scan_from_dataset</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>rotation_layer</span><span class=p>(</span><span class=n>x_train</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:]),</span> <span class=s2>&#34;Rotated CT Scan&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_55_0_hu22903692c92ba947c6626019f1a7bc4e_285512_2f2da998956062c586358f4ae7449404.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_55_0_hu22903692c92ba947c6626019f1a7bc4e_285512_86ae2abfb6e86dd2f05a5530d260ccca.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_55_0_hu22903692c92ba947c6626019f1a7bc4e_285512_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_55_0_hu22903692c92ba947c6626019f1a7bc4e_285512_2f2da998956062c586358f4ae7449404.webp width=760 height=218 loading=lazy data-zoomable></div></div></figure></p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_55_1_huaf2b83aedc344bf80c0cc99ce801171e_291673_e97c24760429b0d3794f5acf81fbbf0b.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_55_1_huaf2b83aedc344bf80c0cc99ce801171e_291673_7095368e3302d95d5a2bc3d92c417f30.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_55_1_huaf2b83aedc344bf80c0cc99ce801171e_291673_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_55_1_huaf2b83aedc344bf80c0cc99ce801171e_291673_e97c24760429b0d3794f5acf81fbbf0b.webp width=760 height=218 loading=lazy data-zoomable></div></div></figure></p><h3 id=flip>Flip</h3><p>The image flips are performed along an axis of symmetry. For medical image enhancement, they can be performed vertically as well as horizontally, because images can be acquired in supine or prone position, and contain anatomical variations (e.g., situs inversus). An organ, whatever its location in the body, will always be the same organ.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>flipping_layer</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>RandomFlip</span><span class=p>(</span><span class=n>mode</span><span class=o>=</span><span class=s1>&#39;vertical&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plot_scan_from_dataset</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>x_train</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:],</span> <span class=s2>&#34;Original CT Scan&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plot_scan_from_dataset</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>flipping_layer</span><span class=p>(</span><span class=n>x_train</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:]),</span> <span class=s2>&#34;Flipped CT Scan&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_57_0_hu22903692c92ba947c6626019f1a7bc4e_285512_ddc72c38641cdcb6b3fe84c6c42ac0a4.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_57_0_hu22903692c92ba947c6626019f1a7bc4e_285512_398e9915f05652c5206f23b26b1d9a0c.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_57_0_hu22903692c92ba947c6626019f1a7bc4e_285512_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_57_0_hu22903692c92ba947c6626019f1a7bc4e_285512_ddc72c38641cdcb6b3fe84c6c42ac0a4.webp width=760 height=218 loading=lazy data-zoomable></div></div></figure></p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_57_1_hueca98666ee82f894096eece0713b0fa9_285107_cf203246c6e90eae406f934869c51b9a.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_57_1_hueca98666ee82f894096eece0713b0fa9_285107_fac8678409a0108a02958221191751a9.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_57_1_hueca98666ee82f894096eece0713b0fa9_285107_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_57_1_hueca98666ee82f894096eece0713b0fa9_285107_cf203246c6e90eae406f934869c51b9a.webp width=760 height=218 loading=lazy data-zoomable></div></div></figure></p><h3 id=shift>Shift</h3><p>This transformation can be performed along the x and/or y axis randomly. The transformed image keeps the same size and orientation as the original image, but is moved in the applied direction. The added pixels are filled with zeros.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>shifting_layer</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>RandomTranslation</span><span class=p>(</span><span class=n>height_factor</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>width_factor</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>fill_mode</span><span class=o>=</span><span class=s1>&#39;constant&#39;</span><span class=p>,</span> <span class=n>fill_value</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plot_scan_from_dataset</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>x_train</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:],</span> <span class=s2>&#34;Original CT Scan&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plot_scan_from_dataset</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>shifting_layer</span><span class=p>(</span><span class=n>x_train</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:]),</span> <span class=s2>&#34;Shifted CT Scan&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_59_0_hu22903692c92ba947c6626019f1a7bc4e_285512_59bc9af92e53090d956d6649cb32438c.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_59_0_hu22903692c92ba947c6626019f1a7bc4e_285512_7a9f3e8a54dc523ad03aa0e721b8050b.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_59_0_hu22903692c92ba947c6626019f1a7bc4e_285512_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_59_0_hu22903692c92ba947c6626019f1a7bc4e_285512_59bc9af92e53090d956d6649cb32438c.webp width=760 height=218 loading=lazy data-zoomable></div></div></figure></p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_59_1_huf672c62cdba27bb464119ac172f1cada_281281_0cfc199dfa28d2f49f4b4477ac8f5268.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_59_1_huf672c62cdba27bb464119ac172f1cada_281281_261e461b8503f5007c75d6abc4274cfc.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_59_1_huf672c62cdba27bb464119ac172f1cada_281281_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_59_1_huf672c62cdba27bb464119ac172f1cada_281281_0cfc199dfa28d2f49f4b4477ac8f5268.webp width=760 height=218 loading=lazy data-zoomable></div></div></figure></p><h3 id=zoom>Zoom</h3><p>A zoom augmentation randomly zooms the image in or out. The zoomed image keeps the same size and orientation as the original image.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>zoom_layer</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>RandomZoom</span><span class=p>(</span><span class=n>height_factor</span><span class=o>=</span><span class=mf>0.15</span><span class=p>,</span> <span class=n>fill_mode</span><span class=o>=</span><span class=s1>&#39;constant&#39;</span><span class=p>,</span> <span class=n>fill_value</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plot_scan_from_dataset</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>x_train</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:],</span> <span class=s2>&#34;Original CT Scan&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plot_scan_from_dataset</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>zoom_layer</span><span class=p>(</span><span class=n>x_train</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:]),</span> <span class=s2>&#34;Zoomed CT Scan&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_61_0_hu22903692c92ba947c6626019f1a7bc4e_285512_23536e2483cd66332d9c1e2fbb4b8e8a.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_61_0_hu22903692c92ba947c6626019f1a7bc4e_285512_9203dab1e5943e6896c13538226a4743.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_61_0_hu22903692c92ba947c6626019f1a7bc4e_285512_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_61_0_hu22903692c92ba947c6626019f1a7bc4e_285512_23536e2483cd66332d9c1e2fbb4b8e8a.webp width=760 height=218 loading=lazy data-zoomable></div></div></figure></p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_61_1_hu9f1ae8879943d1c1eec206fe4390ff57_289066_81ce815dafb86ae0e3036d3afbd5659f.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_61_1_hu9f1ae8879943d1c1eec206fe4390ff57_289066_2e7a12272af8d4c510cc2e0739da1fe1.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_61_1_hu9f1ae8879943d1c1eec206fe4390ff57_289066_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_61_1_hu9f1ae8879943d1c1eec206fe4390ff57_289066_81ce815dafb86ae0e3036d3afbd5659f.webp width=760 height=218 loading=lazy data-zoomable></div></div></figure></p><h3 id=shear>Shear</h3><p>Shearing is an affine transformation that consists of shifting in opposite directions the top and bottom of the image (horizontal shearing) or the right and left of the image (vertical shearing). Unlike the previous methods, the image is distorted. Shear augmentation is not available in <code>tensorflow</code> so the <code>keras_cv</code> package must be installed.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=err>!</span><span class=n>pip</span> <span class=n>install</span> <span class=n>keras_cv</span>
</span></span></code></pre></div><pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting keras_cv
  Downloading keras_cv-0.4.2-py3-none-any.whl (634 kB)
[2K     [90m[0m [32m634.9/634.9 kB[0m [31m13.2 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from keras_cv) (23.1)
Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from keras_cv) (1.4.0)
Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.9/dist-packages (from keras_cv) (4.8.3)
Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from keras_cv) (2022.10.31)
Requirement already satisfied: promise in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&gt;keras_cv) (2.3)
Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&gt;keras_cv) (1.13.1)
Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&gt;keras_cv) (4.65.0)
Requirement already satisfied: protobuf&gt;=3.12.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&gt;keras_cv) (3.20.3)
Requirement already satisfied: toml in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&gt;keras_cv) (0.10.2)
Requirement already satisfied: requests&gt;=2.19.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&gt;keras_cv) (2.27.1)
Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&gt;keras_cv) (8.1.3)
Requirement already satisfied: etils[enp,epath]&gt;=0.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&gt;keras_cv) (1.2.0)
Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&gt;keras_cv) (2.2.0)
Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&gt;keras_cv) (1.22.4)
Requirement already satisfied: wrapt in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&gt;keras_cv) (1.14.1)
Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&gt;keras_cv) (5.9.5)
Requirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&gt;keras_cv) (0.1.8)
Requirement already satisfied: importlib_resources in /usr/local/lib/python3.9/dist-packages (from etils[enp,epath]&gt;=0.9.0-&gt;tensorflow-datasets-&gt;keras_cv) (5.12.0)
Requirement already satisfied: zipp in /usr/local/lib/python3.9/dist-packages (from etils[enp,epath]&gt;=0.9.0-&gt;tensorflow-datasets-&gt;keras_cv) (3.15.0)
Requirement already satisfied: typing_extensions in /usr/local/lib/python3.9/dist-packages (from etils[enp,epath]&gt;=0.9.0-&gt;tensorflow-datasets-&gt;keras_cv) (4.5.0)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.9/dist-packages (from requests&gt;=2.19.0-&gt;tensorflow-datasets-&gt;keras_cv) (3.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests&gt;=2.19.0-&gt;tensorflow-datasets-&gt;keras_cv) (2022.12.7)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests&gt;=2.19.0-&gt;tensorflow-datasets-&gt;keras_cv) (1.26.15)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests&gt;=2.19.0-&gt;tensorflow-datasets-&gt;keras_cv) (2.0.12)
Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from promise-&gt;tensorflow-datasets-&gt;keras_cv) (1.16.0)
Requirement already satisfied: googleapis-common-protos&lt;2,&gt;=1.52.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-metadata-&gt;tensorflow-datasets-&gt;keras_cv) (1.59.0)
Installing collected packages: keras_cv
Successfully installed keras_cv-0.4.2
</code></pre><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>keras_cv</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>shear_layer</span> <span class=o>=</span> <span class=n>keras_cv</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>RandomShear</span><span class=p>(</span><span class=n>x_factor</span><span class=o>=</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>),</span> <span class=n>y_factor</span><span class=o>=</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>),</span> <span class=n>interpolation</span><span class=o>=</span><span class=s2>&#34;bilinear&#34;</span><span class=p>,</span> <span class=n>fill_mode</span><span class=o>=</span><span class=s2>&#34;nearest&#34;</span><span class=p>,</span> <span class=n>fill_value</span><span class=o>=</span><span class=mf>0.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plot_scan_from_dataset</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>x_train</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:],</span> <span class=s2>&#34;Original CT Scan&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plot_scan_from_dataset</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>shear_layer</span><span class=p>(</span><span class=n>x_train</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:]),</span> <span class=s2>&#34;Sheared CT Scan&#34;</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>You do not have Waymo Open Dataset installed, so KerasCV Waymo metrics are not available.
</code></pre><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_64_1_hu22903692c92ba947c6626019f1a7bc4e_285512_d84f082c02e398644a6c684284720b0e.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_64_1_hu22903692c92ba947c6626019f1a7bc4e_285512_206de1e447c7320d395b8235a13cd366.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_64_1_hu22903692c92ba947c6626019f1a7bc4e_285512_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_64_1_hu22903692c92ba947c6626019f1a7bc4e_285512_d84f082c02e398644a6c684284720b0e.webp width=760 height=218 loading=lazy data-zoomable></div></div></figure></p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_64_2_hufe7c3f52a905b1de42d643254255b8f5_270799_d5daecaad9fef1be7ae698a0962eb017.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_64_2_hufe7c3f52a905b1de42d643254255b8f5_270799_bc850dd67ed6a037027dfd8681149b66.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_64_2_hufe7c3f52a905b1de42d643254255b8f5_270799_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_64_2_hufe7c3f52a905b1de42d643254255b8f5_270799_d5daecaad9fef1be7ae698a0962eb017.webp width=760 height=218 loading=lazy data-zoomable></div></div></figure></p><h3 id=brightness>Brightness</h3><p>The higher the value of the brighteness, the lighter is the image. In order to increase the size of the data set in medical imaging, brightness variations belonging to the interval <code>[-0.1; 0.1]</code> are randomly applied.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>brighteness_layer</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>RandomBrightness</span><span class=p>(</span><span class=n>factor</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>value_range</span><span class=o>=</span><span class=p>[</span><span class=mf>0.0</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plot_scan_from_dataset</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>x_train</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:],</span> <span class=s2>&#34;Original CT Scan&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plot_scan_from_dataset</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>brighteness_layer</span><span class=p>(</span><span class=n>x_train</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:]),</span> <span class=s2>&#34;Brightened CT Scan&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_66_0_hu22903692c92ba947c6626019f1a7bc4e_285512_255c2fc8ba503f51c2dd6f4540695b9e.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_66_0_hu22903692c92ba947c6626019f1a7bc4e_285512_a269f5441f3542d4391fbcd947d2503e.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_66_0_hu22903692c92ba947c6626019f1a7bc4e_285512_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_66_0_hu22903692c92ba947c6626019f1a7bc4e_285512_255c2fc8ba503f51c2dd6f4540695b9e.webp width=760 height=218 loading=lazy data-zoomable></div></div></figure></p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_66_1_hu281aff6f463048ccdeda96e47fa9648b_284934_4aa41e22a06c69d0338574057328ece9.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_66_1_hu281aff6f463048ccdeda96e47fa9648b_284934_744c8a2ebcb5c5214fc5252fbb85095f.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_66_1_hu281aff6f463048ccdeda96e47fa9648b_284934_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_66_1_hu281aff6f463048ccdeda96e47fa9648b_284934_4aa41e22a06c69d0338574057328ece9.webp width=760 height=218 loading=lazy data-zoomable></div></div></figure></p><h2 id=contrast>Contrast</h2><p>The contrast of an image is increased when the darker pixels are darkened and the lighter pixels are lightened: a contrasted image will therefore contain a greater quantity of black and white. The contrast increase is clearly visible on image histogram, because the gap between the brightest and the darkest pixels is greater, i.e., the histogram is more spread out.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>contrast_layer</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>RandomContrast</span><span class=p>(</span><span class=n>factor</span><span class=o>=</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mf>1.2</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plot_scan_from_dataset</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>x_train</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:],</span> <span class=s2>&#34;Original CT Scan&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plot_scan_from_dataset</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=n>contrast_layer</span><span class=p>(</span><span class=n>x_train</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=p>:]),</span> <span class=s2>&#34;Contrasted CT Scan&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_68_0_hu22903692c92ba947c6626019f1a7bc4e_285512_6d03d99d673f097bfca993d70b027f74.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_68_0_hu22903692c92ba947c6626019f1a7bc4e_285512_8f367ad0a7e4fd35f9fcaa645f13bf0a.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_68_0_hu22903692c92ba947c6626019f1a7bc4e_285512_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_68_0_hu22903692c92ba947c6626019f1a7bc4e_285512_6d03d99d673f097bfca993d70b027f74.webp width=760 height=218 loading=lazy data-zoomable></div></div></figure></p><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_68_1_huec02491918b2062da692f16d5b5c9b8a_286684_fb2884c24223943b0329c61df1a9ddc1.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_68_1_huec02491918b2062da692f16d5b5c9b8a_286684_65ce2c19f4bb5c5e2558baa8c8f9f728.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_68_1_huec02491918b2062da692f16d5b5c9b8a_286684_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_68_1_huec02491918b2062da692f16d5b5c9b8a_286684_fb2884c24223943b0329c61df1a9ddc1.webp width=760 height=218 loading=lazy data-zoomable></div></div></figure></p><p>The training and validation data loaders must be defined. In this case, data augmentation is not applied through the data loader but directly on the CNN by adding the related augmentation layers.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Set TensorFlow random seed</span>
</span></span><span class=line><span class=cl><span class=n>tf</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>set_seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define data loaders</span>
</span></span><span class=line><span class=cl><span class=n>training_loader</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>Dataset</span><span class=o>.</span><span class=n>from_tensor_slices</span><span class=p>((</span><span class=n>x_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>validation_loader</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>Dataset</span><span class=o>.</span><span class=n>from_tensor_slices</span><span class=p>((</span><span class=n>x_val</span><span class=p>,</span> <span class=n>y_val</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define batch size</span>
</span></span><span class=line><span class=cl><span class=n>batch_size</span> <span class=o>=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Training dataset</span>
</span></span><span class=line><span class=cl><span class=n>training_dataset</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>training_loader</span><span class=o>.</span><span class=n>shuffle</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>x_train</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>batch</span><span class=p>(</span><span class=n>batch_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>prefetch</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Validation dataset</span>
</span></span><span class=line><span class=cl><span class=n>validation_dataset</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>validation_loader</span><span class=o>.</span><span class=n>shuffle</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>x_val</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>batch</span><span class=p>(</span><span class=n>batch_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>prefetch</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><h2 id=model-definition>Model definition</h2><p>The architecture of the 3D CNN is the same used <a href=https://keras.io/examples/vision/3D_image_classification/ target=_blank rel=noopener>here</a>, but, as already said, the CT scans are optionally augmented by passing them through some augmentation layers which have been directly embedded into the model. A reshape layer has also been added since the data is stored in rank-3 tensors of shape (samples, height, width, depth), a dimension of size 1 at axis 4 is needed in order to be able to perform 3D convolutions on the data. The additional dimension is needed to take into account the number of image channel which in this case is just 1.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>tensorflow</span> <span class=kn>import</span> <span class=n>keras</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>tensorflow.keras</span> <span class=kn>import</span> <span class=n>layers</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Default arguments</span>
</span></span><span class=line><span class=cl><span class=n>WIDTH</span><span class=o>=</span><span class=mi>128</span>
</span></span><span class=line><span class=cl><span class=n>HEIGHT</span><span class=o>=</span><span class=mi>128</span>
</span></span><span class=line><span class=cl><span class=n>DEPTH</span><span class=o>=</span><span class=mi>64</span>
</span></span><span class=line><span class=cl><span class=n>INITIAL_LEARNING_RATE</span><span class=o>=</span><span class=mf>0.0001</span>
</span></span><span class=line><span class=cl><span class=n>DECAY_STEPS</span><span class=o>=</span><span class=mi>100000</span>
</span></span><span class=line><span class=cl><span class=n>DECAY_RATE</span><span class=o>=</span><span class=mf>0.96</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Performance metrics</span>
</span></span><span class=line><span class=cl><span class=n>METRICS</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>TruePositives</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;tp&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>      <span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>FalsePositives</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;fp&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>      <span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>TrueNegatives</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;tn&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>      <span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>FalseNegatives</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;fn&#39;</span><span class=p>),</span> 
</span></span><span class=line><span class=cl>      <span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>BinaryAccuracy</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;accuracy&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>      <span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>Precision</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;precision&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>      <span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>Recall</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;recall&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>      <span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>AUC</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;auc&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>      <span class=n>keras</span><span class=o>.</span><span class=n>metrics</span><span class=o>.</span><span class=n>AUC</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=s1>&#39;prc&#39;</span><span class=p>,</span> <span class=n>curve</span><span class=o>=</span><span class=s1>&#39;PR&#39;</span><span class=p>),</span> <span class=c1># precision-recall curve</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>build_model</span><span class=p>(</span><span class=n>width</span><span class=o>=</span><span class=n>WIDTH</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                <span class=n>height</span><span class=o>=</span><span class=n>HEIGHT</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                <span class=n>depth</span><span class=o>=</span><span class=n>DEPTH</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                <span class=n>initial_learning_rate</span><span class=o>=</span><span class=n>INITIAL_LEARNING_RATE</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                <span class=n>decay_steps</span><span class=o>=</span><span class=n>DECAY_STEPS</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                <span class=n>decay_rate</span><span class=o>=</span><span class=n>DECAY_RATE</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>metrics</span><span class=o>=</span><span class=n>METRICS</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>augmentation</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>rotation</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>flip</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>shift</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>zoom</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>shear</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>brightness</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>contrast</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;Build a 3D convolutional neural network model with augmentation layers&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># Define the model</span>
</span></span><span class=line><span class=cl>  <span class=n>model</span> <span class=o>=</span> <span class=n>keras</span><span class=o>.</span><span class=n>Sequential</span><span class=p>()</span>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>keras</span><span class=o>.</span><span class=n>Input</span><span class=p>((</span><span class=n>width</span><span class=p>,</span> <span class=n>height</span><span class=p>,</span> <span class=n>depth</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># (Optionally) Add augmentation layers</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=n>augmentation</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>rotation</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>RandomRotation</span><span class=p>(</span><span class=n>factor</span><span class=o>=</span><span class=p>(</span><span class=o>-</span><span class=mf>0.125</span><span class=p>,</span> <span class=mf>0.125</span><span class=p>),</span> <span class=n>fill_mode</span><span class=o>=</span><span class=s1>&#39;constant&#39;</span><span class=p>,</span> <span class=n>fill_value</span><span class=o>=</span><span class=mi>0</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>flip</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>RandomFlip</span><span class=p>(</span><span class=n>mode</span><span class=o>=</span><span class=s1>&#39;vertical&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>shift</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>RandomTranslation</span><span class=p>(</span><span class=n>height_factor</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>width_factor</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>fill_mode</span><span class=o>=</span><span class=s1>&#39;constant&#39;</span><span class=p>,</span> <span class=n>fill_value</span><span class=o>=</span><span class=mi>0</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>zoom</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>RandomZoom</span><span class=p>(</span><span class=n>height_factor</span><span class=o>=</span><span class=mf>0.15</span><span class=p>,</span> <span class=n>fill_mode</span><span class=o>=</span><span class=s1>&#39;constant&#39;</span><span class=p>,</span> <span class=n>fill_value</span><span class=o>=</span><span class=mi>0</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>shear</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>keras_cv</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>RandomShear</span><span class=p>(</span><span class=n>x_factor</span><span class=o>=</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>),</span> <span class=n>y_factor</span><span class=o>=</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>),</span> <span class=n>interpolation</span><span class=o>=</span><span class=s2>&#34;bilinear&#34;</span><span class=p>,</span> <span class=n>fill_mode</span><span class=o>=</span><span class=s2>&#34;nearest&#34;</span><span class=p>,</span> <span class=n>fill_value</span><span class=o>=</span><span class=mf>0.0</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>brightness</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>RandomBrightness</span><span class=p>(</span><span class=n>factor</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>value_range</span><span class=o>=</span><span class=p>[</span><span class=mf>0.0</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>contrast</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>RandomContrast</span><span class=p>(</span><span class=n>factor</span><span class=o>=</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mf>1.2</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># Add a dimension to perform 3D convolutions</span>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>Reshape</span><span class=p>(</span><span class=n>target_shape</span><span class=o>=</span><span class=p>(</span><span class=n>width</span><span class=p>,</span> <span class=n>height</span><span class=p>,</span> <span class=n>depth</span><span class=p>,</span> <span class=mi>1</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>Conv3D</span><span class=p>(</span><span class=n>filters</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s2>&#34;relu&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>MaxPool3D</span><span class=p>(</span><span class=n>pool_size</span><span class=o>=</span><span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>BatchNormalization</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>Conv3D</span><span class=p>(</span><span class=n>filters</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s2>&#34;relu&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>MaxPool3D</span><span class=p>(</span><span class=n>pool_size</span><span class=o>=</span><span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>BatchNormalization</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>Conv3D</span><span class=p>(</span><span class=n>filters</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s2>&#34;relu&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>MaxPool3D</span><span class=p>(</span><span class=n>pool_size</span><span class=o>=</span><span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>BatchNormalization</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>Conv3D</span><span class=p>(</span><span class=n>filters</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s2>&#34;relu&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>MaxPool3D</span><span class=p>(</span><span class=n>pool_size</span><span class=o>=</span><span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>BatchNormalization</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>GlobalAveragePooling3D</span><span class=p>())</span>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=n>units</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s2>&#34;relu&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.3</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=n>units</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s2>&#34;sigmoid&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># Define the optimizer</span>
</span></span><span class=line><span class=cl>  <span class=n>lr_schedule</span> <span class=o>=</span> <span class=n>keras</span><span class=o>.</span><span class=n>optimizers</span><span class=o>.</span><span class=n>schedules</span><span class=o>.</span><span class=n>ExponentialDecay</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>initial_learning_rate</span><span class=p>,</span> <span class=n>decay_steps</span><span class=o>=</span><span class=n>decay_steps</span><span class=p>,</span> <span class=n>decay_rate</span><span class=o>=</span><span class=n>decay_rate</span><span class=p>,</span> <span class=n>staircase</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>  <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># Compile the model</span>
</span></span><span class=line><span class=cl>  <span class=n>model</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>=</span><span class=s2>&#34;binary_crossentropy&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>=</span><span class=n>keras</span><span class=o>.</span><span class=n>optimizers</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>learning_rate</span><span class=o>=</span><span class=n>lr_schedule</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>metrics</span><span class=o>=</span><span class=n>metrics</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>model</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Build the model with default parameters</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>build_model</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the model summary</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>summary</span><span class=p>()</span>
</span></span></code></pre></div><pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 reshape (Reshape)           (None, 128, 128, 64, 1)   0         
                                                                 
 conv3d (Conv3D)             (None, 126, 126, 62, 64)  1792      
                                                                 
 max_pooling3d (MaxPooling3D  (None, 63, 63, 31, 64)   0         
 )                                                               
                                                                 
 batch_normalization (BatchN  (None, 63, 63, 31, 64)   256       
 ormalization)                                                   
                                                                 
 conv3d_1 (Conv3D)           (None, 61, 61, 29, 64)    110656    
                                                                 
 max_pooling3d_1 (MaxPooling  (None, 30, 30, 14, 64)   0         
 3D)                                                             
                                                                 
 batch_normalization_1 (Batc  (None, 30, 30, 14, 64)   256       
 hNormalization)                                                 
                                                                 
 conv3d_2 (Conv3D)           (None, 28, 28, 12, 128)   221312    
                                                                 
 max_pooling3d_2 (MaxPooling  (None, 14, 14, 6, 128)   0         
 3D)                                                             
                                                                 
 batch_normalization_2 (Batc  (None, 14, 14, 6, 128)   512       
 hNormalization)                                                 
                                                                 
 conv3d_3 (Conv3D)           (None, 12, 12, 4, 256)    884992    
                                                                 
 max_pooling3d_3 (MaxPooling  (None, 6, 6, 2, 256)     0         
 3D)                                                             
                                                                 
 batch_normalization_3 (Batc  (None, 6, 6, 2, 256)     1024      
 hNormalization)                                                 
                                                                 
 global_average_pooling3d (G  (None, 256)              0         
 lobalAveragePooling3D)                                          
                                                                 
 dense (Dense)               (None, 512)               131584    
                                                                 
 dropout (Dropout)           (None, 512)               0         
                                                                 
 dense_1 (Dense)             (None, 1)                 513       
                                                                 
=================================================================
Total params: 1,352,897
Trainable params: 1,351,873
Non-trainable params: 1,024
_________________________________________________________________
</code></pre><h2 id=model-training>Model training</h2><p>The proposed model will be trained by default for 150 epochs in 4 different conditions:</p><ul><li><strong>Absent augmentation</strong>: all augmentation layers disabled</li><li><strong>Basic augmentation</strong>: brightness and contrast layers enabled</li><li><strong>Intermediate augmentation</strong>: brightness, contrast, rotation, flip and shift layers enabled</li><li><strong>Advanced augmentation</strong>: all augmentation layers enabled</li></ul><p>It is worth noting a <strong>Checkpoint callback</strong> is also defined to automatically save the model in <code>h5</code> format based on the validation Receiver Operating Characteristics Area Under Curve (ROC AUC) value. Please note the ROC AUC is preferred to the standard classification accuracy since the dataset is not balanced.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Default epochs number</span>
</span></span><span class=line><span class=cl><span class=n>EPOCHS</span><span class=o>=</span><span class=mi>150</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Callback</span>
</span></span><span class=line><span class=cl><span class=n>CHECKPOINT_CB</span> <span class=o>=</span> <span class=n>keras</span><span class=o>.</span><span class=n>callbacks</span><span class=o>.</span><span class=n>ModelCheckpoint</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;ct-scan-brain-stroke-detection-</span><span class=si>{epoch:03d}</span><span class=s2>-</span><span class=si>{val_auc:.4f}</span><span class=s2>.h5&#34;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>save_best_only</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>monitor</span><span class=o>=</span><span class=s1>&#39;val_auc&#39;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>mode</span><span class=o>=</span><span class=s1>&#39;max&#39;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Model training function</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>training_dataset</span><span class=p>,</span> <span class=n>validation_dataset</span><span class=p>,</span> <span class=n>epochs</span><span class=o>=</span><span class=n>EPOCHS</span><span class=p>,</span> <span class=n>callbacks</span><span class=o>=</span><span class=p>[</span><span class=n>CHECKPOINT_CB</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;Train a model doing validation at the end of each epoch&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=n>history</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>training_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>validation_data</span><span class=o>=</span><span class=n>validation_dataset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>epochs</span><span class=o>=</span><span class=n>epochs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>verbose</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>callbacks</span><span class=o>=</span><span class=n>callbacks</span>
</span></span><span class=line><span class=cl>  <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>history</span>
</span></span></code></pre></div><p>An empty dictionary to store model metrics is also created to store all the metrics.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>performance</span> <span class=o>=</span> <span class=p>{}</span>
</span></span></code></pre></div><h3 id=absent-augmentation>Absent augmentation</h3><p>In this case the data augmentation is completely disabled. The model will be trained by using only the CT scans already available in the training dataset.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>build_model</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>performance</span><span class=p>[</span><span class=s2>&#34;absent&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>train_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>training_dataset</span><span class=p>,</span> <span class=n>validation_dataset</span><span class=p>)</span>
</span></span></code></pre></div><div class=scrollable-output><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>    Epoch 1/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 27s 197ms/step - loss: 0.7002 - tp: 6.0000 - fp: 14.0000 - tn: 22.0000 - fn: 16.0000 - accuracy: 0.4828 - precision: 0.3000 - recall: 0.2727 - auc: 0.4236 - prc: 0.3796 - val_loss: 0.6891 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6741 - val_prc: 0.5665
</span></span><span class=line><span class=cl>    Epoch 2/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 170ms/step - loss: 0.6772 - tp: 9.0000 - fp: 7.0000 - tn: 29.0000 - fn: 13.0000 - accuracy: 0.6552 - precision: 0.5625 - recall: 0.4091 - auc: 0.5852 - prc: 0.4299 - val_loss: 0.6758 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6556 - val_prc: 0.6161
</span></span><span class=line><span class=cl>    Epoch 3/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 172ms/step - loss: 0.6412 - tp: 13.0000 - fp: 8.0000 - tn: 28.0000 - fn: 9.0000 - accuracy: 0.7069 - precision: 0.6190 - recall: 0.5909 - auc: 0.7184 - prc: 0.6360 - val_loss: 0.9218 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6111 - val_prc: 0.4476
</span></span><span class=line><span class=cl>    Epoch 4/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 171ms/step - loss: 0.6143 - tp: 10.0000 - fp: 5.0000 - tn: 31.0000 - fn: 12.0000 - accuracy: 0.7069 - precision: 0.6667 - recall: 0.4545 - auc: 0.7279 - prc: 0.6874 - val_loss: 0.7125 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6259 - val_prc: 0.5567
</span></span><span class=line><span class=cl>    Epoch 5/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 175ms/step - loss: 0.6074 - tp: 10.0000 - fp: 3.0000 - tn: 33.0000 - fn: 12.0000 - accuracy: 0.7414 - precision: 0.7692 - recall: 0.4545 - auc: 0.7330 - prc: 0.5813 - val_loss: 0.7482 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6519 - val_prc: 0.5625
</span></span><span class=line><span class=cl>    Epoch 6/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 173ms/step - loss: 0.6351 - tp: 8.0000 - fp: 7.0000 - tn: 29.0000 - fn: 14.0000 - accuracy: 0.6379 - precision: 0.5333 - recall: 0.3636 - auc: 0.6938 - prc: 0.5982 - val_loss: 1.2574 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6481 - val_prc: 0.6029
</span></span><span class=line><span class=cl>    Epoch 7/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 173ms/step - loss: 0.6018 - tp: 10.0000 - fp: 7.0000 - tn: 29.0000 - fn: 12.0000 - accuracy: 0.6724 - precision: 0.5882 - recall: 0.4545 - auc: 0.7551 - prc: 0.5616 - val_loss: 0.8819 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6556 - val_prc: 0.6027
</span></span><span class=line><span class=cl>    Epoch 8/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 174ms/step - loss: 0.5746 - tp: 14.0000 - fp: 7.0000 - tn: 29.0000 - fn: 8.0000 - accuracy: 0.7414 - precision: 0.6667 - recall: 0.6364 - auc: 0.7696 - prc: 0.6991 - val_loss: 1.0019 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5889 - val_prc: 0.5081
</span></span><span class=line><span class=cl>    Epoch 9/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 174ms/step - loss: 0.5749 - tp: 12.0000 - fp: 3.0000 - tn: 33.0000 - fn: 10.0000 - accuracy: 0.7759 - precision: 0.8000 - recall: 0.5455 - auc: 0.7254 - prc: 0.6337 - val_loss: 1.4884 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6111 - val_prc: 0.5376
</span></span><span class=line><span class=cl>    Epoch 10/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 187ms/step - loss: 0.5709 - tp: 10.0000 - fp: 7.0000 - tn: 29.0000 - fn: 12.0000 - accuracy: 0.6724 - precision: 0.5882 - recall: 0.4545 - auc: 0.7557 - prc: 0.6680 - val_loss: 1.6774 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6593 - val_prc: 0.6106
</span></span><span class=line><span class=cl>    Epoch 11/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.5601 - tp: 12.0000 - fp: 7.0000 - tn: 29.0000 - fn: 10.0000 - accuracy: 0.7069 - precision: 0.6316 - recall: 0.5455 - auc: 0.7670 - prc: 0.6901 - val_loss: 2.4892 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6519 - val_prc: 0.4787
</span></span><span class=line><span class=cl>    Epoch 12/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.5151 - tp: 14.0000 - fp: 5.0000 - tn: 31.0000 - fn: 8.0000 - accuracy: 0.7759 - precision: 0.7368 - recall: 0.6364 - auc: 0.8396 - prc: 0.7432 - val_loss: 2.5274 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6222 - val_prc: 0.4381
</span></span><span class=line><span class=cl>    Epoch 13/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.4865 - tp: 14.0000 - fp: 5.0000 - tn: 31.0000 - fn: 8.0000 - accuracy: 0.7759 - precision: 0.7368 - recall: 0.6364 - auc: 0.8396 - prc: 0.8283 - val_loss: 3.3881 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4667 - val_prc: 0.3570
</span></span><span class=line><span class=cl>    Epoch 14/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.4484 - tp: 15.0000 - fp: 2.0000 - tn: 34.0000 - fn: 7.0000 - accuracy: 0.8448 - precision: 0.8824 - recall: 0.6818 - auc: 0.9198 - prc: 0.8888 - val_loss: 1.4274 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5889 - val_prc: 0.5541
</span></span><span class=line><span class=cl>    Epoch 15/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 201ms/step - loss: 0.4467 - tp: 15.0000 - fp: 5.0000 - tn: 31.0000 - fn: 7.0000 - accuracy: 0.7931 - precision: 0.7500 - recall: 0.6818 - auc: 0.8946 - prc: 0.8335 - val_loss: 2.2831 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5889 - val_prc: 0.5586
</span></span><span class=line><span class=cl>    Epoch 16/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.3943 - tp: 16.0000 - fp: 2.0000 - tn: 34.0000 - fn: 6.0000 - accuracy: 0.8621 - precision: 0.8889 - recall: 0.7273 - auc: 0.9192 - prc: 0.8970 - val_loss: 5.1814 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.3750
</span></span><span class=line><span class=cl>    Epoch 17/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 201ms/step - loss: 0.3981 - tp: 18.0000 - fp: 4.0000 - tn: 32.0000 - fn: 4.0000 - accuracy: 0.8621 - precision: 0.8182 - recall: 0.8182 - auc: 0.9072 - prc: 0.8860 - val_loss: 4.0833 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.3750
</span></span><span class=line><span class=cl>    Epoch 18/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.2982 - tp: 21.0000 - fp: 5.0000 - tn: 31.0000 - fn: 1.0000 - accuracy: 0.8966 - precision: 0.8077 - recall: 0.9545 - auc: 0.9760 - prc: 0.9722 - val_loss: 1.5026 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5741 - val_prc: 0.5433
</span></span><span class=line><span class=cl>    Epoch 19/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.4235 - tp: 15.0000 - fp: 5.0000 - tn: 31.0000 - fn: 7.0000 - accuracy: 0.7931 - precision: 0.7500 - recall: 0.6818 - auc: 0.8832 - prc: 0.7512 - val_loss: 2.1605 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4963 - val_prc: 0.4582
</span></span><span class=line><span class=cl>    Epoch 20/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.4055 - tp: 16.0000 - fp: 4.0000 - tn: 32.0000 - fn: 6.0000 - accuracy: 0.8276 - precision: 0.8000 - recall: 0.7273 - auc: 0.9129 - prc: 0.8750 - val_loss: 1.7596 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6481 - val_prc: 0.5424
</span></span><span class=line><span class=cl>    Epoch 21/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.3645 - tp: 16.0000 - fp: 2.0000 - tn: 34.0000 - fn: 6.0000 - accuracy: 0.8621 - precision: 0.8889 - recall: 0.7273 - auc: 0.9280 - prc: 0.8974 - val_loss: 1.9915 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6370 - val_prc: 0.5410
</span></span><span class=line><span class=cl>    Epoch 22/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.2712 - tp: 19.0000 - fp: 3.0000 - tn: 33.0000 - fn: 3.0000 - accuracy: 0.8966 - precision: 0.8636 - recall: 0.8636 - auc: 0.9672 - prc: 0.9585 - val_loss: 0.8103 - val_tp: 4.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 5.0000 - val_accuracy: 0.4583 - val_precision: 0.3333 - val_recall: 0.4444 - val_auc: 0.5926 - val_prc: 0.5532
</span></span><span class=line><span class=cl>    Epoch 23/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 175ms/step - loss: 0.3840 - tp: 15.0000 - fp: 4.0000 - tn: 32.0000 - fn: 7.0000 - accuracy: 0.8103 - precision: 0.7895 - recall: 0.6818 - auc: 0.8832 - prc: 0.8661 - val_loss: 1.5774 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6185 - val_prc: 0.5903
</span></span><span class=line><span class=cl>    Epoch 24/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.3379 - tp: 19.0000 - fp: 6.0000 - tn: 30.0000 - fn: 3.0000 - accuracy: 0.8448 - precision: 0.7600 - recall: 0.8636 - auc: 0.9501 - prc: 0.9453 - val_loss: 0.8694 - val_tp: 6.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 3.0000 - val_accuracy: 0.5833 - val_precision: 0.4615 - val_recall: 0.6667 - val_auc: 0.6074 - val_prc: 0.5338
</span></span><span class=line><span class=cl>    Epoch 25/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 175ms/step - loss: 0.2800 - tp: 21.0000 - fp: 2.0000 - tn: 34.0000 - fn: 1.0000 - accuracy: 0.9483 - precision: 0.9130 - recall: 0.9545 - auc: 0.9811 - prc: 0.9720 - val_loss: 2.4292 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6370 - val_prc: 0.4767
</span></span><span class=line><span class=cl>    Epoch 26/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 203ms/step - loss: 0.4072 - tp: 16.0000 - fp: 7.0000 - tn: 29.0000 - fn: 6.0000 - accuracy: 0.7759 - precision: 0.6957 - recall: 0.7273 - auc: 0.8876 - prc: 0.8567 - val_loss: 1.6198 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.6815 - val_prc: 0.4556
</span></span><span class=line><span class=cl>    Epoch 27/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.3483 - tp: 15.0000 - fp: 1.0000 - tn: 35.0000 - fn: 7.0000 - accuracy: 0.8621 - precision: 0.9375 - recall: 0.6818 - auc: 0.9337 - prc: 0.9232 - val_loss: 2.2016 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6963 - val_prc: 0.6890
</span></span><span class=line><span class=cl>    Epoch 28/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.2698 - tp: 17.0000 - fp: 2.0000 - tn: 34.0000 - fn: 5.0000 - accuracy: 0.8793 - precision: 0.8947 - recall: 0.7727 - auc: 0.9747 - prc: 0.9634 - val_loss: 0.8487 - val_tp: 5.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 4.0000 - val_accuracy: 0.5833 - val_precision: 0.4545 - val_recall: 0.5556 - val_auc: 0.6444 - val_prc: 0.5897
</span></span><span class=line><span class=cl>    Epoch 29/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.4407 - tp: 15.0000 - fp: 6.0000 - tn: 30.0000 - fn: 7.0000 - accuracy: 0.7759 - precision: 0.7143 - recall: 0.6818 - auc: 0.8611 - prc: 0.8201 - val_loss: 0.8850 - val_tp: 3.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.7083 - val_precision: 0.7500 - val_recall: 0.3333 - val_auc: 0.6741 - val_prc: 0.5209
</span></span><span class=line><span class=cl>    Epoch 30/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.2629 - tp: 16.0000 - fp: 1.0000 - tn: 35.0000 - fn: 6.0000 - accuracy: 0.8793 - precision: 0.9412 - recall: 0.7273 - auc: 0.9760 - prc: 0.9617 - val_loss: 1.5557 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.6852 - val_prc: 0.5492
</span></span><span class=line><span class=cl>    Epoch 31/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 201ms/step - loss: 0.1817 - tp: 21.0000 - fp: 3.0000 - tn: 33.0000 - fn: 1.0000 - accuracy: 0.9310 - precision: 0.8750 - recall: 0.9545 - auc: 0.9931 - prc: 0.9889 - val_loss: 1.0616 - val_tp: 6.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 3.0000 - val_accuracy: 0.5000 - val_precision: 0.4000 - val_recall: 0.6667 - val_auc: 0.6778 - val_prc: 0.5999
</span></span><span class=line><span class=cl>    Epoch 32/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.2270 - tp: 18.0000 - fp: 2.0000 - tn: 34.0000 - fn: 4.0000 - accuracy: 0.8966 - precision: 0.9000 - recall: 0.8182 - auc: 0.9729 - prc: 0.9623 - val_loss: 1.7977 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6148 - val_prc: 0.4962
</span></span><span class=line><span class=cl>    Epoch 33/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.2288 - tp: 21.0000 - fp: 2.0000 - tn: 34.0000 - fn: 1.0000 - accuracy: 0.9483 - precision: 0.9130 - recall: 0.9545 - auc: 0.9874 - prc: 0.9798 - val_loss: 1.0614 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 2.0000 - val_accuracy: 0.5417 - val_precision: 0.4375 - val_recall: 0.7778 - val_auc: 0.6222 - val_prc: 0.5203
</span></span><span class=line><span class=cl>    Epoch 34/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.2219 - tp: 20.0000 - fp: 2.0000 - tn: 34.0000 - fn: 2.0000 - accuracy: 0.9310 - precision: 0.9091 - recall: 0.9091 - auc: 0.9785 - prc: 0.9716 - val_loss: 0.8000 - val_tp: 5.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 4.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.5556 - val_auc: 0.6667 - val_prc: 0.5838
</span></span><span class=line><span class=cl>    Epoch 35/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.3234 - tp: 15.0000 - fp: 2.0000 - tn: 34.0000 - fn: 7.0000 - accuracy: 0.8448 - precision: 0.8824 - recall: 0.6818 - auc: 0.9306 - prc: 0.9080 - val_loss: 2.3090 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5741 - val_prc: 0.4023
</span></span><span class=line><span class=cl>    Epoch 36/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.2608 - tp: 19.0000 - fp: 2.0000 - tn: 34.0000 - fn: 3.0000 - accuracy: 0.9138 - precision: 0.9048 - recall: 0.8636 - auc: 0.9697 - prc: 0.9545 - val_loss: 0.9518 - val_tp: 6.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 3.0000 - val_accuracy: 0.5833 - val_precision: 0.4615 - val_recall: 0.6667 - val_auc: 0.7037 - val_prc: 0.6025
</span></span><span class=line><span class=cl>    Epoch 37/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.2390 - tp: 18.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 4.0000 - accuracy: 0.9310 - precision: 1.0000 - recall: 0.8182 - auc: 0.9634 - prc: 0.9554 - val_loss: 0.8774 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.5630 - val_prc: 0.5661
</span></span><span class=line><span class=cl>    Epoch 38/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 199ms/step - loss: 0.0959 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.9335 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.5704 - val_prc: 0.5011
</span></span><span class=line><span class=cl>    Epoch 39/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 175ms/step - loss: 0.1951 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9962 - prc: 0.9936 - val_loss: 2.5183 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5889 - val_prc: 0.3990
</span></span><span class=line><span class=cl>    Epoch 40/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1823 - tp: 21.0000 - fp: 2.0000 - tn: 34.0000 - fn: 1.0000 - accuracy: 0.9483 - precision: 0.9130 - recall: 0.9545 - auc: 0.9848 - prc: 0.9738 - val_loss: 1.6855 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.6037 - val_prc: 0.6092
</span></span><span class=line><span class=cl>    Epoch 41/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 175ms/step - loss: 0.2639 - tp: 18.0000 - fp: 2.0000 - tn: 34.0000 - fn: 4.0000 - accuracy: 0.8966 - precision: 0.9000 - recall: 0.8182 - auc: 0.9653 - prc: 0.9454 - val_loss: 1.5368 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.6741 - val_prc: 0.5285
</span></span><span class=line><span class=cl>    Epoch 42/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 199ms/step - loss: 0.2371 - tp: 18.0000 - fp: 2.0000 - tn: 34.0000 - fn: 4.0000 - accuracy: 0.8966 - precision: 0.9000 - recall: 0.8182 - auc: 0.9823 - prc: 0.9715 - val_loss: 1.2670 - val_tp: 8.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 1.0000 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.8889 - val_auc: 0.6852 - val_prc: 0.4862
</span></span><span class=line><span class=cl>    Epoch 43/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1463 - tp: 21.0000 - fp: 3.0000 - tn: 33.0000 - fn: 1.0000 - accuracy: 0.9310 - precision: 0.8750 - recall: 0.9545 - auc: 0.9937 - prc: 0.9914 - val_loss: 4.2052 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5519 - val_prc: 0.4005
</span></span><span class=line><span class=cl>    Epoch 44/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.2017 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9912 - prc: 0.9866 - val_loss: 1.6621 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.6778 - val_prc: 0.6399
</span></span><span class=line><span class=cl>    Epoch 45/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.1629 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9899 - prc: 0.9856 - val_loss: 0.9936 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6630 - val_prc: 0.5719
</span></span><span class=line><span class=cl>    Epoch 46/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.2487 - tp: 17.0000 - fp: 1.0000 - tn: 35.0000 - fn: 5.0000 - accuracy: 0.8966 - precision: 0.9444 - recall: 0.7727 - auc: 0.9697 - prc: 0.9577 - val_loss: 0.9438 - val_tp: 4.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 5.0000 - val_accuracy: 0.5417 - val_precision: 0.4000 - val_recall: 0.4444 - val_auc: 0.6407 - val_prc: 0.5744
</span></span><span class=line><span class=cl>    Epoch 47/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.1986 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9899 - prc: 0.9856 - val_loss: 0.9540 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.6148 - val_prc: 0.5791
</span></span><span class=line><span class=cl>    Epoch 48/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1564 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9975 - prc: 0.9961 - val_loss: 1.5473 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.6926 - val_prc: 0.6765
</span></span><span class=line><span class=cl>    Epoch 49/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 200ms/step - loss: 0.1103 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6924 - val_tp: 7.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 2.0000 - val_accuracy: 0.4583 - val_precision: 0.3889 - val_recall: 0.7778 - val_auc: 0.6074 - val_prc: 0.4373
</span></span><span class=line><span class=cl>    Epoch 50/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.2040 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9747 - prc: 0.9741 - val_loss: 1.6458 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.6000 - val_prc: 0.4968
</span></span><span class=line><span class=cl>    Epoch 51/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1739 - tp: 20.0000 - fp: 2.0000 - tn: 34.0000 - fn: 2.0000 - accuracy: 0.9310 - precision: 0.9091 - recall: 0.9091 - auc: 0.9842 - prc: 0.9797 - val_loss: 2.3496 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6444 - val_prc: 0.4245
</span></span><span class=line><span class=cl>    Epoch 52/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.1342 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 0.9955 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.7296 - val_prc: 0.5711
</span></span><span class=line><span class=cl>    Epoch 53/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.0941 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 0.9987 - prc: 0.9980 - val_loss: 1.0994 - val_tp: 6.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 3.0000 - val_accuracy: 0.5417 - val_precision: 0.4286 - val_recall: 0.6667 - val_auc: 0.6667 - val_prc: 0.5371
</span></span><span class=line><span class=cl>    Epoch 54/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.1554 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9949 - prc: 0.9913 - val_loss: 0.9879 - val_tp: 5.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 4.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.5556 - val_auc: 0.7074 - val_prc: 0.5396
</span></span><span class=line><span class=cl>    Epoch 55/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 175ms/step - loss: 0.2241 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9665 - prc: 0.9654 - val_loss: 1.3689 - val_tp: 3.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.7083 - val_precision: 0.7500 - val_recall: 0.3333 - val_auc: 0.6667 - val_prc: 0.6136
</span></span><span class=line><span class=cl>    Epoch 56/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 199ms/step - loss: 0.1488 - tp: 20.0000 - fp: 2.0000 - tn: 34.0000 - fn: 2.0000 - accuracy: 0.9310 - precision: 0.9091 - recall: 0.9091 - auc: 0.9912 - prc: 0.9871 - val_loss: 1.0276 - val_tp: 5.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 4.0000 - val_accuracy: 0.5417 - val_precision: 0.4167 - val_recall: 0.5556 - val_auc: 0.7074 - val_prc: 0.5311
</span></span><span class=line><span class=cl>    Epoch 57/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1302 - tp: 21.0000 - fp: 2.0000 - tn: 34.0000 - fn: 1.0000 - accuracy: 0.9483 - precision: 0.9130 - recall: 0.9545 - auc: 0.9924 - prc: 0.9882 - val_loss: 1.4677 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.6667 - val_prc: 0.4548
</span></span><span class=line><span class=cl>    Epoch 58/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 199ms/step - loss: 0.0934 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 0.9975 - prc: 0.9959 - val_loss: 1.1227 - val_tp: 5.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 4.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.5556 - val_auc: 0.6519 - val_prc: 0.4788
</span></span><span class=line><span class=cl>    Epoch 59/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.0896 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 1.2691 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6704 - val_prc: 0.5122
</span></span><span class=line><span class=cl>    Epoch 60/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.0990 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.2702 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6593 - val_prc: 0.4669
</span></span><span class=line><span class=cl>    Epoch 61/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.1886 - tp: 17.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 5.0000 - accuracy: 0.9138 - precision: 1.0000 - recall: 0.7727 - auc: 0.9886 - prc: 0.9814 - val_loss: 1.4041 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.6037 - val_prc: 0.5516
</span></span><span class=line><span class=cl>    Epoch 62/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1292 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9912 - prc: 0.9880 - val_loss: 1.7597 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 8.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.1111 - val_auc: 0.5481 - val_prc: 0.4779
</span></span><span class=line><span class=cl>    Epoch 63/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 199ms/step - loss: 0.1297 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9949 - prc: 0.9929 - val_loss: 2.6302 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.6444 - val_prc: 0.6408
</span></span><span class=line><span class=cl>    Epoch 64/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1330 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9937 - prc: 0.9889 - val_loss: 1.0390 - val_tp: 4.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 5.0000 - val_accuracy: 0.5000 - val_precision: 0.3636 - val_recall: 0.4444 - val_auc: 0.6630 - val_prc: 0.4934
</span></span><span class=line><span class=cl>    Epoch 65/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1245 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9937 - prc: 0.9914 - val_loss: 1.0608 - val_tp: 5.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 4.0000 - val_accuracy: 0.6667 - val_precision: 0.5556 - val_recall: 0.5556 - val_auc: 0.6481 - val_prc: 0.5704
</span></span><span class=line><span class=cl>    Epoch 66/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.1628 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9716 - prc: 0.9752 - val_loss: 2.2087 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.6000 - val_prc: 0.6069
</span></span><span class=line><span class=cl>    Epoch 67/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1194 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9962 - prc: 0.9944 - val_loss: 4.2144 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5556 - val_prc: 0.5004
</span></span><span class=line><span class=cl>    Epoch 68/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0941 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6846 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.6222 - val_prc: 0.6412
</span></span><span class=line><span class=cl>    Epoch 69/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1476 - tp: 21.0000 - fp: 2.0000 - tn: 34.0000 - fn: 1.0000 - accuracy: 0.9483 - precision: 0.9130 - recall: 0.9545 - auc: 0.9949 - prc: 0.9923 - val_loss: 1.7396 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.6444 - val_prc: 0.5999
</span></span><span class=line><span class=cl>    Epoch 70/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1227 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9962 - prc: 0.9940 - val_loss: 2.6796 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6815 - val_prc: 0.4732
</span></span><span class=line><span class=cl>    Epoch 71/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0697 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.4592 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.7296 - val_prc: 0.5296
</span></span><span class=line><span class=cl>    Epoch 72/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.1266 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9924 - prc: 0.9901 - val_loss: 3.2876 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6407 - val_prc: 0.4582
</span></span><span class=line><span class=cl>    Epoch 73/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 175ms/step - loss: 0.1239 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9975 - prc: 0.9961 - val_loss: 2.2804 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.6185 - val_prc: 0.4414
</span></span><span class=line><span class=cl>    Epoch 74/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 199ms/step - loss: 0.2016 - tp: 19.0000 - fp: 2.0000 - tn: 34.0000 - fn: 3.0000 - accuracy: 0.9138 - precision: 0.9048 - recall: 0.8636 - auc: 0.9798 - prc: 0.9700 - val_loss: 1.2627 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.6963 - val_prc: 0.6087
</span></span><span class=line><span class=cl>    Epoch 75/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.1060 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 1.3861 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.6926 - val_prc: 0.6100
</span></span><span class=line><span class=cl>    Epoch 76/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 199ms/step - loss: 0.1422 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9886 - prc: 0.9816 - val_loss: 1.2345 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 6.0000 - val_accuracy: 0.5833 - val_precision: 0.4286 - val_recall: 0.3333 - val_auc: 0.6296 - val_prc: 0.5761
</span></span><span class=line><span class=cl>    Epoch 77/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.1297 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9912 - prc: 0.9866 - val_loss: 1.2191 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6556 - val_prc: 0.4480
</span></span><span class=line><span class=cl>    Epoch 78/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.0902 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.1026 - val_tp: 4.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 5.0000 - val_accuracy: 0.5417 - val_precision: 0.4000 - val_recall: 0.4444 - val_auc: 0.6667 - val_prc: 0.5737
</span></span><span class=line><span class=cl>    Epoch 79/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0901 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9987 - prc: 0.9980 - val_loss: 1.1582 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 7.0000 - val_accuracy: 0.5833 - val_precision: 0.4000 - val_recall: 0.2222 - val_auc: 0.6556 - val_prc: 0.5782
</span></span><span class=line><span class=cl>    Epoch 80/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.0799 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5908 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.6444 - val_prc: 0.4394
</span></span><span class=line><span class=cl>    Epoch 81/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0732 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.1505 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6667 - val_prc: 0.4678
</span></span><span class=line><span class=cl>    Epoch 82/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.0690 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.0628 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6926 - val_prc: 0.5508
</span></span><span class=line><span class=cl>    Epoch 83/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.0638 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 6.1388 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5667 - val_prc: 0.4091
</span></span><span class=line><span class=cl>    Epoch 84/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0597 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.2742 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.6519 - val_prc: 0.4380
</span></span><span class=line><span class=cl>    Epoch 85/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.0775 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.1804 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6704 - val_prc: 0.5004
</span></span><span class=line><span class=cl>    Epoch 86/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 175ms/step - loss: 0.0678 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.1592 - val_tp: 2.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 7.0000 - val_accuracy: 0.5000 - val_precision: 0.2857 - val_recall: 0.2222 - val_auc: 0.6407 - val_prc: 0.5148
</span></span><span class=line><span class=cl>    Epoch 87/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 198ms/step - loss: 0.1512 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9798 - prc: 0.9763 - val_loss: 2.1435 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.6296 - val_prc: 0.4175
</span></span><span class=line><span class=cl>    Epoch 88/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1141 - tp: 21.0000 - fp: 2.0000 - tn: 34.0000 - fn: 1.0000 - accuracy: 0.9483 - precision: 0.9130 - recall: 0.9545 - auc: 0.9949 - prc: 0.9929 - val_loss: 2.9144 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6111 - val_prc: 0.5895
</span></span><span class=line><span class=cl>    Epoch 89/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.1031 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.3662 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.5630 - val_prc: 0.5318
</span></span><span class=line><span class=cl>    Epoch 90/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 200ms/step - loss: 0.2066 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9659 - prc: 0.9595 - val_loss: 1.1912 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.6741 - val_prc: 0.6291
</span></span><span class=line><span class=cl>    Epoch 91/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.1104 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9962 - prc: 0.9944 - val_loss: 1.2353 - val_tp: 7.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 2.0000 - val_accuracy: 0.7083 - val_precision: 0.5833 - val_recall: 0.7778 - val_auc: 0.6370 - val_prc: 0.5101
</span></span><span class=line><span class=cl>    Epoch 92/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0842 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9975 - prc: 0.9961 - val_loss: 1.3635 - val_tp: 7.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 2.0000 - val_accuracy: 0.6667 - val_precision: 0.5385 - val_recall: 0.7778 - val_auc: 0.6444 - val_prc: 0.4446
</span></span><span class=line><span class=cl>    Epoch 93/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.0366 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3471 - val_tp: 6.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 3.0000 - val_accuracy: 0.5833 - val_precision: 0.4615 - val_recall: 0.6667 - val_auc: 0.6481 - val_prc: 0.4888
</span></span><span class=line><span class=cl>    Epoch 94/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0423 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.1969 - val_tp: 5.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 4.0000 - val_accuracy: 0.5833 - val_precision: 0.4545 - val_recall: 0.5556 - val_auc: 0.6704 - val_prc: 0.5168
</span></span><span class=line><span class=cl>    Epoch 95/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0497 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.7935 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.5667 - val_prc: 0.5603
</span></span><span class=line><span class=cl>    Epoch 96/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.1108 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9962 - prc: 0.9936 - val_loss: 1.2713 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 6.0000 - val_accuracy: 0.5833 - val_precision: 0.4286 - val_recall: 0.3333 - val_auc: 0.6741 - val_prc: 0.5315
</span></span><span class=line><span class=cl>    Epoch 97/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.1410 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9855 - prc: 0.9805 - val_loss: 1.8814 - val_tp: 3.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.7083 - val_precision: 0.7500 - val_recall: 0.3333 - val_auc: 0.5667 - val_prc: 0.5949
</span></span><span class=line><span class=cl>    Epoch 98/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.1199 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9937 - prc: 0.9895 - val_loss: 1.6763 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6407 - val_prc: 0.4256
</span></span><span class=line><span class=cl>    Epoch 99/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0804 - tp: 22.0000 - fp: 2.0000 - tn: 34.0000 - fn: 0.0000e+00 - accuracy: 0.9655 - precision: 0.9167 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4800 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.5667 - val_prc: 0.4307
</span></span><span class=line><span class=cl>    Epoch 100/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.1267 - tp: 21.0000 - fp: 2.0000 - tn: 34.0000 - fn: 1.0000 - accuracy: 0.9483 - precision: 0.9130 - recall: 0.9545 - auc: 0.9899 - prc: 0.9838 - val_loss: 1.5902 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 7.0000 - val_accuracy: 0.5833 - val_precision: 0.4000 - val_recall: 0.2222 - val_auc: 0.6074 - val_prc: 0.4193
</span></span><span class=line><span class=cl>    Epoch 101/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0394 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5032 - val_tp: 4.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 5.0000 - val_accuracy: 0.5833 - val_precision: 0.4444 - val_recall: 0.4444 - val_auc: 0.6778 - val_prc: 0.4642
</span></span><span class=line><span class=cl>    Epoch 102/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0717 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3194 - val_tp: 5.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 4.0000 - val_accuracy: 0.5833 - val_precision: 0.4545 - val_recall: 0.5556 - val_auc: 0.6667 - val_prc: 0.4895
</span></span><span class=line><span class=cl>    Epoch 103/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0620 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9994 - prc: 0.9990 - val_loss: 1.3006 - val_tp: 4.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 5.0000 - val_accuracy: 0.5833 - val_precision: 0.4444 - val_recall: 0.4444 - val_auc: 0.6370 - val_prc: 0.4972
</span></span><span class=line><span class=cl>    Epoch 104/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 201ms/step - loss: 0.0364 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.2496 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.6519 - val_prc: 0.5683
</span></span><span class=line><span class=cl>    Epoch 105/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 175ms/step - loss: 0.0381 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5330 - val_tp: 6.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 3.0000 - val_accuracy: 0.5417 - val_precision: 0.4286 - val_recall: 0.6667 - val_auc: 0.6556 - val_prc: 0.4690
</span></span><span class=line><span class=cl>    Epoch 106/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.0475 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.8588 - val_tp: 9.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6667 - val_precision: 0.5294 - val_recall: 1.0000 - val_auc: 0.6370 - val_prc: 0.4340
</span></span><span class=line><span class=cl>    Epoch 107/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 201ms/step - loss: 0.0497 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6444 - val_tp: 8.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 1.0000 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.8889 - val_auc: 0.6481 - val_prc: 0.4369
</span></span><span class=line><span class=cl>    Epoch 108/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.0306 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5228 - val_tp: 5.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 4.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.5556 - val_auc: 0.6815 - val_prc: 0.4597
</span></span><span class=line><span class=cl>    Epoch 109/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0238 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5728 - val_tp: 6.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 3.0000 - val_accuracy: 0.5833 - val_precision: 0.4615 - val_recall: 0.6667 - val_auc: 0.6889 - val_prc: 0.4670
</span></span><span class=line><span class=cl>    Epoch 110/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0216 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.3391 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7148 - val_prc: 0.5073
</span></span><span class=line><span class=cl>    Epoch 111/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0164 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6520 - val_tp: 8.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 1.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.8889 - val_auc: 0.6593 - val_prc: 0.4373
</span></span><span class=line><span class=cl>    Epoch 112/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0236 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3961 - val_tp: 5.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 4.0000 - val_accuracy: 0.5833 - val_precision: 0.4545 - val_recall: 0.5556 - val_auc: 0.7000 - val_prc: 0.5038
</span></span><span class=line><span class=cl>    Epoch 113/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 202ms/step - loss: 0.0113 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.9034 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 2.0000 - val_accuracy: 0.5417 - val_precision: 0.4375 - val_recall: 0.7778 - val_auc: 0.6667 - val_prc: 0.4808
</span></span><span class=line><span class=cl>    Epoch 114/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0524 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5860 - val_tp: 4.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 5.0000 - val_accuracy: 0.5833 - val_precision: 0.4444 - val_recall: 0.4444 - val_auc: 0.6370 - val_prc: 0.4572
</span></span><span class=line><span class=cl>    Epoch 115/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 201ms/step - loss: 0.0723 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9975 - prc: 0.9959 - val_loss: 4.4519 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6111 - val_prc: 0.5895
</span></span><span class=line><span class=cl>    Epoch 116/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0839 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6600 - val_tp: 4.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 5.0000 - val_accuracy: 0.5833 - val_precision: 0.4444 - val_recall: 0.4444 - val_auc: 0.6370 - val_prc: 0.5225
</span></span><span class=line><span class=cl>    Epoch 117/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.1030 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9861 - prc: 0.9846 - val_loss: 2.1225 - val_tp: 9.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6667 - val_precision: 0.5294 - val_recall: 1.0000 - val_auc: 0.6519 - val_prc: 0.4370
</span></span><span class=line><span class=cl>    Epoch 118/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0572 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 0.9987 - prc: 0.9980 - val_loss: 2.9734 - val_tp: 8.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4211 - val_recall: 0.8889 - val_auc: 0.5000 - val_prc: 0.3483
</span></span><span class=line><span class=cl>    Epoch 119/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.0498 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.0978 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 7.0000 - val_accuracy: 0.5833 - val_precision: 0.4000 - val_recall: 0.2222 - val_auc: 0.6407 - val_prc: 0.5501
</span></span><span class=line><span class=cl>    Epoch 120/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 200ms/step - loss: 0.0777 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9962 - prc: 0.9944 - val_loss: 3.4611 - val_tp: 6.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 3.0000 - val_accuracy: 0.4167 - val_precision: 0.3529 - val_recall: 0.6667 - val_auc: 0.4259 - val_prc: 0.3369
</span></span><span class=line><span class=cl>    Epoch 121/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 175ms/step - loss: 0.0966 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 0.9949 - prc: 0.9913 - val_loss: 1.6355 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.6481 - val_prc: 0.4467
</span></span><span class=line><span class=cl>    Epoch 122/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 175ms/step - loss: 0.0975 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9924 - prc: 0.9901 - val_loss: 5.3627 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6667 - val_prc: 0.4737
</span></span><span class=line><span class=cl>    Epoch 123/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.0575 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4247 - val_tp: 7.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.7778 - val_auc: 0.6296 - val_prc: 0.4429
</span></span><span class=line><span class=cl>    Epoch 124/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 202ms/step - loss: 0.0508 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4254 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 6.0000 - val_accuracy: 0.5833 - val_precision: 0.4286 - val_recall: 0.3333 - val_auc: 0.5074 - val_prc: 0.4519
</span></span><span class=line><span class=cl>    Epoch 125/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 201ms/step - loss: 0.0282 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4721 - val_tp: 3.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 6.0000 - val_accuracy: 0.5000 - val_precision: 0.3333 - val_recall: 0.3333 - val_auc: 0.6148 - val_prc: 0.5433
</span></span><span class=line><span class=cl>    Epoch 126/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0435 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5210 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.6630 - val_prc: 0.5017
</span></span><span class=line><span class=cl>    Epoch 127/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.0587 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3495 - val_tp: 3.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 6.0000 - val_accuracy: 0.5417 - val_precision: 0.3750 - val_recall: 0.3333 - val_auc: 0.6741 - val_prc: 0.5087
</span></span><span class=line><span class=cl>    Epoch 128/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0341 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.7384 - val_tp: 7.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 2.0000 - val_accuracy: 0.5833 - val_precision: 0.4667 - val_recall: 0.7778 - val_auc: 0.6000 - val_prc: 0.4126
</span></span><span class=line><span class=cl>    Epoch 129/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0354 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5934 - val_tp: 8.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 1.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.8889 - val_auc: 0.6370 - val_prc: 0.4527
</span></span><span class=line><span class=cl>    Epoch 130/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0356 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6407 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 6.0000 - val_accuracy: 0.5833 - val_precision: 0.4286 - val_recall: 0.3333 - val_auc: 0.5963 - val_prc: 0.4800
</span></span><span class=line><span class=cl>    Epoch 131/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.0248 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.9388 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.6037 - val_prc: 0.5653
</span></span><span class=line><span class=cl>    Epoch 132/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0358 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6263 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.6370 - val_prc: 0.4450
</span></span><span class=line><span class=cl>    Epoch 133/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.0149 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.7919 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 6.0000 - val_accuracy: 0.5833 - val_precision: 0.4286 - val_recall: 0.3333 - val_auc: 0.6037 - val_prc: 0.5565
</span></span><span class=line><span class=cl>    Epoch 134/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0399 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.3672 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.6111 - val_prc: 0.5895
</span></span><span class=line><span class=cl>    Epoch 135/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.0111 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.8030 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.6111 - val_prc: 0.5895
</span></span><span class=line><span class=cl>    Epoch 136/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0055 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.9866 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.6407 - val_prc: 0.6022
</span></span><span class=line><span class=cl>    Epoch 137/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.0820 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9975 - prc: 0.9959 - val_loss: 1.8939 - val_tp: 8.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 1.0000 - val_accuracy: 0.7083 - val_precision: 0.5714 - val_recall: 0.8889 - val_auc: 0.7185 - val_prc: 0.4880
</span></span><span class=line><span class=cl>    Epoch 138/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.0297 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5812 - val_tp: 5.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 4.0000 - val_accuracy: 0.5417 - val_precision: 0.4167 - val_recall: 0.5556 - val_auc: 0.6296 - val_prc: 0.4863
</span></span><span class=line><span class=cl>    Epoch 139/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 201ms/step - loss: 0.0379 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4258 - val_tp: 5.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 4.0000 - val_accuracy: 0.5833 - val_precision: 0.4545 - val_recall: 0.5556 - val_auc: 0.5815 - val_prc: 0.4501
</span></span><span class=line><span class=cl>    Epoch 140/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0119 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3512 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 5.0000 - val_accuracy: 0.6667 - val_precision: 0.5714 - val_recall: 0.4444 - val_auc: 0.7000 - val_prc: 0.6010
</span></span><span class=line><span class=cl>    Epoch 141/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0464 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3362 - val_tp: 4.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 5.0000 - val_accuracy: 0.5417 - val_precision: 0.4000 - val_recall: 0.4444 - val_auc: 0.6593 - val_prc: 0.5819
</span></span><span class=line><span class=cl>    Epoch 142/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 202ms/step - loss: 0.0424 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4989 - val_tp: 8.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 1.0000 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.8889 - val_auc: 0.6556 - val_prc: 0.5460
</span></span><span class=line><span class=cl>    Epoch 143/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.0245 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.9789 - val_tp: 7.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.7778 - val_auc: 0.6185 - val_prc: 0.4106
</span></span><span class=line><span class=cl>    Epoch 144/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0889 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9949 - prc: 0.9929 - val_loss: 2.0951 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.6333 - val_prc: 0.4392
</span></span><span class=line><span class=cl>    Epoch 145/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0748 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.1505 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 3.0000 - val_accuracy: 0.3750 - val_precision: 0.3333 - val_recall: 0.6667 - val_auc: 0.4259 - val_prc: 0.3118
</span></span><span class=line><span class=cl>    Epoch 146/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.0888 - tp: 22.0000 - fp: 2.0000 - tn: 34.0000 - fn: 0.0000e+00 - accuracy: 0.9655 - precision: 0.9167 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3046 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 5.0000 - val_accuracy: 0.6667 - val_precision: 0.5714 - val_recall: 0.4444 - val_auc: 0.6481 - val_prc: 0.6198
</span></span><span class=line><span class=cl>    Epoch 147/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 202ms/step - loss: 0.1112 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9924 - prc: 0.9870 - val_loss: 3.0559 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5778 - val_prc: 0.5134
</span></span><span class=line><span class=cl>    Epoch 148/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1741 - tp: 18.0000 - fp: 2.0000 - tn: 34.0000 - fn: 4.0000 - accuracy: 0.8966 - precision: 0.9000 - recall: 0.8182 - auc: 0.9804 - prc: 0.9692 - val_loss: 2.1499 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 6.0000 - val_accuracy: 0.6667 - val_precision: 0.6000 - val_recall: 0.3333 - val_auc: 0.5815 - val_prc: 0.5663
</span></span><span class=line><span class=cl>    Epoch 149/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.1287 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9785 - prc: 0.9799 - val_loss: 2.6137 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.5926 - val_prc: 0.5749
</span></span><span class=line><span class=cl>    Epoch 150/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 203ms/step - loss: 0.0795 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4128 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 6.0000 - val_accuracy: 0.5833 - val_precision: 0.4286 - val_recall: 0.3333 - val_auc: 0.6593 - val_prc: 0.5844
</span></span></code></pre></div></div><h3 id=basic-augmentation>Basic augmentation</h3><p>The basic augmentation is very light since it just enables the brightness and contrast layers. The expected results are not much better with respect to the previous case.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>build_model</span><span class=p>(</span><span class=n>augmentation</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>rotation</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>flip</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>shift</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>zoom</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>shear</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>brightness</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>contrast</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>performance</span><span class=p>[</span><span class=s2>&#34;basic&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>train_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>training_dataset</span><span class=p>,</span> <span class=n>validation_dataset</span><span class=p>)</span>
</span></span></code></pre></div><div class=scrollable-output><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>    Epoch 1/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 10s 199ms/step - loss: 0.6830 - tp: 12.0000 - fp: 12.0000 - tn: 39.0000 - fn: 19.0000 - accuracy: 0.6220 - precision: 0.5000 - recall: 0.3871 - auc: 0.5569 - prc: 0.4748 - val_loss: 0.6913 - val_tp: 5.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 4.0000 - val_accuracy: 0.5833 - val_precision: 0.4545 - val_recall: 0.5556 - val_auc: 0.6296 - val_prc: 0.4677
</span></span><span class=line><span class=cl>    Epoch 2/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.6188 - tp: 10.0000 - fp: 4.0000 - tn: 32.0000 - fn: 12.0000 - accuracy: 0.7241 - precision: 0.7143 - recall: 0.4545 - auc: 0.7664 - prc: 0.7183 - val_loss: 0.7491 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6000 - val_prc: 0.5361
</span></span><span class=line><span class=cl>    Epoch 3/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.6501 - tp: 9.0000 - fp: 7.0000 - tn: 29.0000 - fn: 13.0000 - accuracy: 0.6552 - precision: 0.5625 - recall: 0.4091 - auc: 0.6237 - prc: 0.5183 - val_loss: 0.7112 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6222 - val_prc: 0.5844
</span></span><span class=line><span class=cl>    Epoch 4/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.5945 - tp: 12.0000 - fp: 5.0000 - tn: 31.0000 - fn: 10.0000 - accuracy: 0.7414 - precision: 0.7059 - recall: 0.5455 - auc: 0.7311 - prc: 0.6222 - val_loss: 0.8578 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5963 - val_prc: 0.5271
</span></span><span class=line><span class=cl>    Epoch 5/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6198 - tp: 4.0000 - fp: 2.0000 - tn: 34.0000 - fn: 18.0000 - accuracy: 0.6552 - precision: 0.6667 - recall: 0.1818 - auc: 0.6913 - prc: 0.6345 - val_loss: 0.6775 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6000 - val_prc: 0.5625
</span></span><span class=line><span class=cl>    Epoch 6/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.5820 - tp: 10.0000 - fp: 4.0000 - tn: 32.0000 - fn: 12.0000 - accuracy: 0.7241 - precision: 0.7143 - recall: 0.4545 - auc: 0.7620 - prc: 0.7166 - val_loss: 0.9705 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5963 - val_prc: 0.5628
</span></span><span class=line><span class=cl>    Epoch 7/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.5588 - tp: 10.0000 - fp: 4.0000 - tn: 32.0000 - fn: 12.0000 - accuracy: 0.7241 - precision: 0.7143 - recall: 0.4545 - auc: 0.7519 - prc: 0.7334 - val_loss: 1.0259 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5778 - val_prc: 0.5460
</span></span><span class=line><span class=cl>    Epoch 8/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.5384 - tp: 15.0000 - fp: 6.0000 - tn: 30.0000 - fn: 7.0000 - accuracy: 0.7759 - precision: 0.7143 - recall: 0.6818 - auc: 0.8030 - prc: 0.7375 - val_loss: 3.4091 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5333 - val_prc: 0.3913
</span></span><span class=line><span class=cl>    Epoch 9/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.5811 - tp: 12.0000 - fp: 12.0000 - tn: 24.0000 - fn: 10.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.5455 - auc: 0.7273 - prc: 0.6568 - val_loss: 0.8861 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5778 - val_prc: 0.5455
</span></span><span class=line><span class=cl>    Epoch 10/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 200ms/step - loss: 0.5691 - tp: 9.0000 - fp: 6.0000 - tn: 30.0000 - fn: 13.0000 - accuracy: 0.6724 - precision: 0.6000 - recall: 0.4091 - auc: 0.7727 - prc: 0.6987 - val_loss: 1.1090 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4630 - val_prc: 0.4555
</span></span><span class=line><span class=cl>    Epoch 11/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 175ms/step - loss: 0.6058 - tp: 11.0000 - fp: 8.0000 - tn: 28.0000 - fn: 11.0000 - accuracy: 0.6724 - precision: 0.5789 - recall: 0.5000 - auc: 0.7279 - prc: 0.6410 - val_loss: 2.1531 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6296 - val_prc: 0.5617
</span></span><span class=line><span class=cl>    Epoch 12/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.5140 - tp: 15.0000 - fp: 5.0000 - tn: 31.0000 - fn: 7.0000 - accuracy: 0.7931 - precision: 0.7500 - recall: 0.6818 - auc: 0.8220 - prc: 0.7629 - val_loss: 2.8898 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4556 - val_prc: 0.3475
</span></span><span class=line><span class=cl>    Epoch 13/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.4759 - tp: 14.0000 - fp: 2.0000 - tn: 34.0000 - fn: 8.0000 - accuracy: 0.8276 - precision: 0.8750 - recall: 0.6364 - auc: 0.8693 - prc: 0.8204 - val_loss: 1.1536 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5667 - val_prc: 0.5347
</span></span><span class=line><span class=cl>    Epoch 14/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.4612 - tp: 16.0000 - fp: 5.0000 - tn: 31.0000 - fn: 6.0000 - accuracy: 0.8103 - precision: 0.7619 - recall: 0.7273 - auc: 0.8668 - prc: 0.8601 - val_loss: 4.0509 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.3750
</span></span><span class=line><span class=cl>    Epoch 15/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.5514 - tp: 13.0000 - fp: 11.0000 - tn: 25.0000 - fn: 9.0000 - accuracy: 0.6552 - precision: 0.5417 - recall: 0.5909 - auc: 0.7734 - prc: 0.6824 - val_loss: 2.7095 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4815 - val_prc: 0.4583
</span></span><span class=line><span class=cl>    Epoch 16/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.5104 - tp: 15.0000 - fp: 6.0000 - tn: 30.0000 - fn: 7.0000 - accuracy: 0.7759 - precision: 0.7143 - recall: 0.6818 - auc: 0.8378 - prc: 0.7721 - val_loss: 3.3760 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6111 - val_prc: 0.4402
</span></span><span class=line><span class=cl>    Epoch 17/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.4790 - tp: 16.0000 - fp: 5.0000 - tn: 31.0000 - fn: 6.0000 - accuracy: 0.8103 - precision: 0.7619 - recall: 0.7273 - auc: 0.8422 - prc: 0.7598 - val_loss: 0.7231 - val_tp: 5.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 4.0000 - val_accuracy: 0.4583 - val_precision: 0.3571 - val_recall: 0.5556 - val_auc: 0.4778 - val_prc: 0.5576
</span></span><span class=line><span class=cl>    Epoch 18/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.4418 - tp: 15.0000 - fp: 5.0000 - tn: 31.0000 - fn: 7.0000 - accuracy: 0.7931 - precision: 0.7500 - recall: 0.6818 - auc: 0.8908 - prc: 0.8472 - val_loss: 0.8642 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.5148 - val_prc: 0.5184
</span></span><span class=line><span class=cl>    Epoch 19/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.4891 - tp: 10.0000 - fp: 1.0000 - tn: 35.0000 - fn: 12.0000 - accuracy: 0.7759 - precision: 0.9091 - recall: 0.4545 - auc: 0.8422 - prc: 0.8125 - val_loss: 1.3278 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5259 - val_prc: 0.5516
</span></span><span class=line><span class=cl>    Epoch 20/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.4552 - tp: 13.0000 - fp: 3.0000 - tn: 33.0000 - fn: 9.0000 - accuracy: 0.7931 - precision: 0.8125 - recall: 0.5909 - auc: 0.8586 - prc: 0.8386 - val_loss: 2.7479 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4778 - val_prc: 0.4492
</span></span><span class=line><span class=cl>    Epoch 21/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.3782 - tp: 16.0000 - fp: 3.0000 - tn: 33.0000 - fn: 6.0000 - accuracy: 0.8448 - precision: 0.8421 - recall: 0.7273 - auc: 0.9318 - prc: 0.9067 - val_loss: 1.4158 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6074 - val_prc: 0.5685
</span></span><span class=line><span class=cl>    Epoch 22/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.4321 - tp: 15.0000 - fp: 4.0000 - tn: 32.0000 - fn: 7.0000 - accuracy: 0.8103 - precision: 0.7895 - recall: 0.6818 - auc: 0.8643 - prc: 0.8522 - val_loss: 3.3259 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6111 - val_prc: 0.4476
</span></span><span class=line><span class=cl>    Epoch 23/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.3929 - tp: 16.0000 - fp: 4.0000 - tn: 32.0000 - fn: 6.0000 - accuracy: 0.8276 - precision: 0.8000 - recall: 0.7273 - auc: 0.9015 - prc: 0.8851 - val_loss: 1.3029 - val_tp: 8.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 1.0000 - val_accuracy: 0.3333 - val_precision: 0.3478 - val_recall: 0.8889 - val_auc: 0.4593 - val_prc: 0.5056
</span></span><span class=line><span class=cl>    Epoch 24/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.4009 - tp: 16.0000 - fp: 4.0000 - tn: 32.0000 - fn: 6.0000 - accuracy: 0.8276 - precision: 0.8000 - recall: 0.7273 - auc: 0.9040 - prc: 0.8784 - val_loss: 2.6127 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5630 - val_prc: 0.4837
</span></span><span class=line><span class=cl>    Epoch 25/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 201ms/step - loss: 0.3749 - tp: 17.0000 - fp: 4.0000 - tn: 32.0000 - fn: 5.0000 - accuracy: 0.8448 - precision: 0.8095 - recall: 0.7727 - auc: 0.9129 - prc: 0.9011 - val_loss: 1.5429 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4852 - val_prc: 0.5009
</span></span><span class=line><span class=cl>    Epoch 26/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.3584 - tp: 15.0000 - fp: 2.0000 - tn: 34.0000 - fn: 7.0000 - accuracy: 0.8448 - precision: 0.8824 - recall: 0.6818 - auc: 0.9236 - prc: 0.8998 - val_loss: 1.2788 - val_tp: 8.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4167 - val_precision: 0.3810 - val_recall: 0.8889 - val_auc: 0.5074 - val_prc: 0.5531
</span></span><span class=line><span class=cl>    Epoch 27/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 199ms/step - loss: 0.3122 - tp: 19.0000 - fp: 2.0000 - tn: 34.0000 - fn: 3.0000 - accuracy: 0.9138 - precision: 0.9048 - recall: 0.8636 - auc: 0.9665 - prc: 0.9604 - val_loss: 1.8011 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4963 - val_prc: 0.5184
</span></span><span class=line><span class=cl>    Epoch 28/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 175ms/step - loss: 0.4442 - tp: 15.0000 - fp: 3.0000 - tn: 33.0000 - fn: 7.0000 - accuracy: 0.8276 - precision: 0.8333 - recall: 0.6818 - auc: 0.8567 - prc: 0.8369 - val_loss: 1.3424 - val_tp: 8.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 1.0000 - val_accuracy: 0.3333 - val_precision: 0.3478 - val_recall: 0.8889 - val_auc: 0.4852 - val_prc: 0.4913
</span></span><span class=line><span class=cl>    Epoch 29/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.3409 - tp: 17.0000 - fp: 2.0000 - tn: 34.0000 - fn: 5.0000 - accuracy: 0.8793 - precision: 0.8947 - recall: 0.7727 - auc: 0.9362 - prc: 0.9189 - val_loss: 2.1606 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5037 - val_prc: 0.5351
</span></span><span class=line><span class=cl>    Epoch 30/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.3147 - tp: 17.0000 - fp: 3.0000 - tn: 33.0000 - fn: 5.0000 - accuracy: 0.8621 - precision: 0.8500 - recall: 0.7727 - auc: 0.9438 - prc: 0.9278 - val_loss: 1.0792 - val_tp: 8.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4211 - val_recall: 0.8889 - val_auc: 0.5889 - val_prc: 0.5584
</span></span><span class=line><span class=cl>    Epoch 31/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.3214 - tp: 17.0000 - fp: 4.0000 - tn: 32.0000 - fn: 5.0000 - accuracy: 0.8448 - precision: 0.8095 - recall: 0.7727 - auc: 0.9343 - prc: 0.9314 - val_loss: 3.0873 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6741 - val_prc: 0.4884
</span></span><span class=line><span class=cl>    Epoch 32/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.3385 - tp: 19.0000 - fp: 4.0000 - tn: 32.0000 - fn: 3.0000 - accuracy: 0.8793 - precision: 0.8261 - recall: 0.8636 - auc: 0.9476 - prc: 0.9213 - val_loss: 1.8834 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6519 - val_prc: 0.4720
</span></span><span class=line><span class=cl>    Epoch 33/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.2997 - tp: 18.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 4.0000 - accuracy: 0.9310 - precision: 1.0000 - recall: 0.8182 - auc: 0.9583 - prc: 0.9510 - val_loss: 1.0953 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.6111 - val_prc: 0.5667
</span></span><span class=line><span class=cl>    Epoch 34/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.2365 - tp: 18.0000 - fp: 2.0000 - tn: 34.0000 - fn: 4.0000 - accuracy: 0.8966 - precision: 0.9000 - recall: 0.8182 - auc: 0.9779 - prc: 0.9683 - val_loss: 1.1344 - val_tp: 6.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 3.0000 - val_accuracy: 0.3333 - val_precision: 0.3158 - val_recall: 0.6667 - val_auc: 0.5148 - val_prc: 0.5397
</span></span><span class=line><span class=cl>    Epoch 35/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.1734 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9899 - prc: 0.9856 - val_loss: 2.4849 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5296 - val_prc: 0.3963
</span></span><span class=line><span class=cl>    Epoch 36/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.2748 - tp: 17.0000 - fp: 1.0000 - tn: 35.0000 - fn: 5.0000 - accuracy: 0.8966 - precision: 0.9444 - recall: 0.7727 - auc: 0.9729 - prc: 0.9567 - val_loss: 2.0846 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5704 - val_prc: 0.4378
</span></span><span class=line><span class=cl>    Epoch 37/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.2393 - tp: 18.0000 - fp: 2.0000 - tn: 34.0000 - fn: 4.0000 - accuracy: 0.8966 - precision: 0.9000 - recall: 0.8182 - auc: 0.9792 - prc: 0.9694 - val_loss: 1.2777 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7074 - val_prc: 0.5293
</span></span><span class=line><span class=cl>    Epoch 38/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 201ms/step - loss: 0.1857 - tp: 20.0000 - fp: 2.0000 - tn: 34.0000 - fn: 2.0000 - accuracy: 0.9310 - precision: 0.9091 - recall: 0.9091 - auc: 0.9937 - prc: 0.9899 - val_loss: 1.1879 - val_tp: 8.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4167 - val_precision: 0.3810 - val_recall: 0.8889 - val_auc: 0.6037 - val_prc: 0.5722
</span></span><span class=line><span class=cl>    Epoch 39/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.1526 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9994 - prc: 0.9990 - val_loss: 1.7134 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6037 - val_prc: 0.5734
</span></span><span class=line><span class=cl>    Epoch 40/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.2425 - tp: 18.0000 - fp: 3.0000 - tn: 33.0000 - fn: 4.0000 - accuracy: 0.8793 - precision: 0.8571 - recall: 0.8182 - auc: 0.9646 - prc: 0.9552 - val_loss: 1.0025 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.5741 - val_prc: 0.5739
</span></span><span class=line><span class=cl>    Epoch 41/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.2049 - tp: 19.0000 - fp: 2.0000 - tn: 34.0000 - fn: 3.0000 - accuracy: 0.9138 - precision: 0.9048 - recall: 0.8636 - auc: 0.9867 - prc: 0.9788 - val_loss: 0.7786 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.6185 - val_prc: 0.5937
</span></span><span class=line><span class=cl>    Epoch 42/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.2102 - tp: 18.0000 - fp: 1.0000 - tn: 35.0000 - fn: 4.0000 - accuracy: 0.9138 - precision: 0.9474 - recall: 0.8182 - auc: 0.9697 - prc: 0.9607 - val_loss: 3.9611 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5556 - val_prc: 0.4016
</span></span><span class=line><span class=cl>    Epoch 43/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.2055 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9804 - prc: 0.9729 - val_loss: 0.8082 - val_tp: 7.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 2.0000 - val_accuracy: 0.7083 - val_precision: 0.5833 - val_recall: 0.7778 - val_auc: 0.6815 - val_prc: 0.6163
</span></span><span class=line><span class=cl>    Epoch 44/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.2180 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9880 - prc: 0.9789 - val_loss: 2.1966 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4178
</span></span><span class=line><span class=cl>    Epoch 45/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.2158 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9760 - prc: 0.9684 - val_loss: 2.3301 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6444 - val_prc: 0.5369
</span></span><span class=line><span class=cl>    Epoch 46/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.1186 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 2.6398 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6370 - val_prc: 0.4977
</span></span><span class=line><span class=cl>    Epoch 47/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.2241 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9893 - prc: 0.9840 - val_loss: 0.9055 - val_tp: 3.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.7083 - val_precision: 0.7500 - val_recall: 0.3333 - val_auc: 0.5889 - val_prc: 0.5996
</span></span><span class=line><span class=cl>    Epoch 48/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 200ms/step - loss: 0.2135 - tp: 21.0000 - fp: 4.0000 - tn: 32.0000 - fn: 1.0000 - accuracy: 0.9138 - precision: 0.8400 - recall: 0.9545 - auc: 0.9798 - prc: 0.9763 - val_loss: 1.1924 - val_tp: 8.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 1.0000 - val_accuracy: 0.4583 - val_precision: 0.4000 - val_recall: 0.8889 - val_auc: 0.6815 - val_prc: 0.6382
</span></span><span class=line><span class=cl>    Epoch 49/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1642 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9975 - prc: 0.9959 - val_loss: 1.0873 - val_tp: 6.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 3.0000 - val_accuracy: 0.5000 - val_precision: 0.4000 - val_recall: 0.6667 - val_auc: 0.5926 - val_prc: 0.5676
</span></span><span class=line><span class=cl>    Epoch 50/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1233 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 2.4068 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6037 - val_prc: 0.4214
</span></span><span class=line><span class=cl>    Epoch 51/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.0946 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.2321 - val_tp: 8.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4211 - val_recall: 0.8889 - val_auc: 0.6593 - val_prc: 0.6299
</span></span><span class=line><span class=cl>    Epoch 52/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.1450 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9912 - prc: 0.9864 - val_loss: 3.7010 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6926 - val_prc: 0.4969
</span></span><span class=line><span class=cl>    Epoch 53/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 202ms/step - loss: 0.2643 - tp: 16.0000 - fp: 3.0000 - tn: 33.0000 - fn: 6.0000 - accuracy: 0.8448 - precision: 0.8421 - recall: 0.7273 - auc: 0.9571 - prc: 0.9395 - val_loss: 1.5267 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6296 - val_prc: 0.4843
</span></span><span class=line><span class=cl>    Epoch 54/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.2133 - tp: 21.0000 - fp: 3.0000 - tn: 33.0000 - fn: 1.0000 - accuracy: 0.9310 - precision: 0.8750 - recall: 0.9545 - auc: 0.9823 - prc: 0.9808 - val_loss: 1.6550 - val_tp: 5.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 4.0000 - val_accuracy: 0.2500 - val_precision: 0.2632 - val_recall: 0.5556 - val_auc: 0.4259 - val_prc: 0.4297
</span></span><span class=line><span class=cl>    Epoch 55/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.1688 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9975 - prc: 0.9961 - val_loss: 0.9434 - val_tp: 5.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 4.0000 - val_accuracy: 0.5417 - val_precision: 0.4167 - val_recall: 0.5556 - val_auc: 0.5926 - val_prc: 0.5287
</span></span><span class=line><span class=cl>    Epoch 56/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.1485 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9924 - prc: 0.9893 - val_loss: 1.1409 - val_tp: 7.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 2.0000 - val_accuracy: 0.5000 - val_precision: 0.4118 - val_recall: 0.7778 - val_auc: 0.6370 - val_prc: 0.5996
</span></span><span class=line><span class=cl>    Epoch 57/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.1526 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 0.9962 - prc: 0.9936 - val_loss: 2.1477 - val_tp: 8.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4167 - val_precision: 0.3810 - val_recall: 0.8889 - val_auc: 0.5704 - val_prc: 0.4882
</span></span><span class=line><span class=cl>    Epoch 58/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 200ms/step - loss: 0.1417 - tp: 20.0000 - fp: 2.0000 - tn: 34.0000 - fn: 2.0000 - accuracy: 0.9310 - precision: 0.9091 - recall: 0.9091 - auc: 0.9924 - prc: 0.9888 - val_loss: 1.6656 - val_tp: 7.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 2.0000 - val_accuracy: 0.3333 - val_precision: 0.3333 - val_recall: 0.7778 - val_auc: 0.5259 - val_prc: 0.5352
</span></span><span class=line><span class=cl>    Epoch 59/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.2337 - tp: 16.0000 - fp: 1.0000 - tn: 35.0000 - fn: 6.0000 - accuracy: 0.8793 - precision: 0.9412 - recall: 0.7273 - auc: 0.9672 - prc: 0.9556 - val_loss: 2.4534 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6370 - val_prc: 0.4575
</span></span><span class=line><span class=cl>    Epoch 60/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1521 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9912 - prc: 0.9864 - val_loss: 3.3470 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6296 - val_prc: 0.4461
</span></span><span class=line><span class=cl>    Epoch 61/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 176ms/step - loss: 0.1245 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9924 - prc: 0.9893 - val_loss: 1.4928 - val_tp: 8.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.5417 - val_precision: 0.4444 - val_recall: 0.8889 - val_auc: 0.6444 - val_prc: 0.5180
</span></span><span class=line><span class=cl>    Epoch 62/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 203ms/step - loss: 0.1665 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9937 - prc: 0.9889 - val_loss: 2.6169 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5852 - val_prc: 0.4785
</span></span><span class=line><span class=cl>    Epoch 63/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0910 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.0362 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5481 - val_prc: 0.4198
</span></span><span class=line><span class=cl>    Epoch 64/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 203ms/step - loss: 0.1491 - tp: 18.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 4.0000 - accuracy: 0.9310 - precision: 1.0000 - recall: 0.8182 - auc: 0.9918 - prc: 0.9882 - val_loss: 3.3631 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6259 - val_prc: 0.4418
</span></span><span class=line><span class=cl>    Epoch 65/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0948 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9962 - prc: 0.9940 - val_loss: 1.4223 - val_tp: 7.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 2.0000 - val_accuracy: 0.4583 - val_precision: 0.3889 - val_recall: 0.7778 - val_auc: 0.6259 - val_prc: 0.6189
</span></span><span class=line><span class=cl>    Epoch 66/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0844 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.5829 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5556 - val_prc: 0.4016
</span></span><span class=line><span class=cl>    Epoch 67/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.1120 - tp: 20.0000 - fp: 2.0000 - tn: 34.0000 - fn: 2.0000 - accuracy: 0.9310 - precision: 0.9091 - recall: 0.9091 - auc: 0.9937 - prc: 0.9904 - val_loss: 3.1984 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4889 - val_prc: 0.3933
</span></span><span class=line><span class=cl>    Epoch 68/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 201ms/step - loss: 0.2126 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9646 - prc: 0.9588 - val_loss: 5.4056 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6000 - val_prc: 0.4286
</span></span><span class=line><span class=cl>    Epoch 69/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.2655 - tp: 16.0000 - fp: 2.0000 - tn: 34.0000 - fn: 6.0000 - accuracy: 0.8621 - precision: 0.8889 - recall: 0.7273 - auc: 0.9628 - prc: 0.9417 - val_loss: 1.1726 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 3.0000 - val_accuracy: 0.3750 - val_precision: 0.3333 - val_recall: 0.6667 - val_auc: 0.5704 - val_prc: 0.5607
</span></span><span class=line><span class=cl>    Epoch 70/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.1365 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9937 - prc: 0.9904 - val_loss: 3.3981 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5370 - val_prc: 0.3859
</span></span><span class=line><span class=cl>    Epoch 71/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.1574 - tp: 20.0000 - fp: 2.0000 - tn: 34.0000 - fn: 2.0000 - accuracy: 0.9310 - precision: 0.9091 - recall: 0.9091 - auc: 0.9861 - prc: 0.9806 - val_loss: 3.3246 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5444 - val_prc: 0.4212
</span></span><span class=line><span class=cl>    Epoch 72/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.1275 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.1590 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5556 - val_prc: 0.4016
</span></span><span class=line><span class=cl>    Epoch 73/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0838 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 1.9734 - val_tp: 8.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 1.0000 - val_accuracy: 0.3750 - val_precision: 0.3636 - val_recall: 0.8889 - val_auc: 0.5185 - val_prc: 0.4171
</span></span><span class=line><span class=cl>    Epoch 74/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.1088 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 0.9962 - prc: 0.9936 - val_loss: 4.0157 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4667 - val_prc: 0.3500
</span></span><span class=line><span class=cl>    Epoch 75/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.1446 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9899 - prc: 0.9837 - val_loss: 2.9612 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5778 - val_prc: 0.4154
</span></span><span class=line><span class=cl>    Epoch 76/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 203ms/step - loss: 0.0713 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 0.9987 - prc: 0.9980 - val_loss: 4.5733 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6000 - val_prc: 0.4286
</span></span><span class=line><span class=cl>    Epoch 77/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0964 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.7162 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5630 - val_prc: 0.3880
</span></span><span class=line><span class=cl>    Epoch 78/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.1358 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9874 - prc: 0.9827 - val_loss: 1.3227 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 2.0000 - val_accuracy: 0.5417 - val_precision: 0.4375 - val_recall: 0.7778 - val_auc: 0.6333 - val_prc: 0.4920
</span></span><span class=line><span class=cl>    Epoch 79/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.0856 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 2.6552 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5185 - val_prc: 0.4217
</span></span><span class=line><span class=cl>    Epoch 80/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.1499 - tp: 18.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 4.0000 - accuracy: 0.9310 - precision: 1.0000 - recall: 0.8182 - auc: 0.9912 - prc: 0.9862 - val_loss: 1.2554 - val_tp: 4.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 5.0000 - val_accuracy: 0.5417 - val_precision: 0.4000 - val_recall: 0.4444 - val_auc: 0.5296 - val_prc: 0.5386
</span></span><span class=line><span class=cl>    Epoch 81/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0599 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.0355 - val_tp: 7.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 2.0000 - val_accuracy: 0.3750 - val_precision: 0.3500 - val_recall: 0.7778 - val_auc: 0.5185 - val_prc: 0.4231
</span></span><span class=line><span class=cl>    Epoch 82/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0777 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9962 - prc: 0.9944 - val_loss: 1.7000 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 3.0000 - val_accuracy: 0.3750 - val_precision: 0.3333 - val_recall: 0.6667 - val_auc: 0.5333 - val_prc: 0.4734
</span></span><span class=line><span class=cl>    Epoch 83/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 201ms/step - loss: 0.0676 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.8261 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5407 - val_prc: 0.4026
</span></span><span class=line><span class=cl>    Epoch 84/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.0933 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.7199 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5296 - val_prc: 0.3871
</span></span><span class=line><span class=cl>    Epoch 85/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.0603 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 5.5722 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5667 - val_prc: 0.4091
</span></span><span class=line><span class=cl>    Epoch 86/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0923 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 2.8736 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6556 - val_prc: 0.4638
</span></span><span class=line><span class=cl>    Epoch 87/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 204ms/step - loss: 0.0645 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 1.7041 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 4.0000 - val_accuracy: 0.3750 - val_precision: 0.3125 - val_recall: 0.5556 - val_auc: 0.4741 - val_prc: 0.4138
</span></span><span class=line><span class=cl>    Epoch 88/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0570 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.4840 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5778 - val_prc: 0.4226
</span></span><span class=line><span class=cl>    Epoch 89/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0424 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.4750 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5407 - val_prc: 0.3916
</span></span><span class=line><span class=cl>    Epoch 90/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.1142 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9880 - prc: 0.9861 - val_loss: 3.5888 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4963 - val_prc: 0.3667
</span></span><span class=line><span class=cl>    Epoch 91/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0507 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.0560 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.3679
</span></span><span class=line><span class=cl>    Epoch 92/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 202ms/step - loss: 0.0612 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.2421 - val_tp: 7.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 2.0000 - val_accuracy: 0.4167 - val_precision: 0.3684 - val_recall: 0.7778 - val_auc: 0.5333 - val_prc: 0.4312
</span></span><span class=line><span class=cl>    Epoch 93/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.1112 - tp: 21.0000 - fp: 3.0000 - tn: 33.0000 - fn: 1.0000 - accuracy: 0.9310 - precision: 0.8750 - recall: 0.9545 - auc: 0.9937 - prc: 0.9914 - val_loss: 2.1516 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.7259 - val_prc: 0.6492
</span></span><span class=line><span class=cl>    Epoch 94/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.1179 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9937 - prc: 0.9914 - val_loss: 1.4414 - val_tp: 6.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 3.0000 - val_accuracy: 0.5000 - val_precision: 0.4000 - val_recall: 0.6667 - val_auc: 0.6259 - val_prc: 0.5550
</span></span><span class=line><span class=cl>    Epoch 95/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.1062 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9937 - prc: 0.9914 - val_loss: 2.7095 - val_tp: 8.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4167 - val_precision: 0.3810 - val_recall: 0.8889 - val_auc: 0.4815 - val_prc: 0.3770
</span></span><span class=line><span class=cl>    Epoch 96/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 202ms/step - loss: 0.0810 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.9633 - val_tp: 5.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 4.0000 - val_accuracy: 0.4167 - val_precision: 0.3333 - val_recall: 0.5556 - val_auc: 0.4704 - val_prc: 0.4114
</span></span><span class=line><span class=cl>    Epoch 97/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0859 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9994 - prc: 0.9990 - val_loss: 1.9116 - val_tp: 5.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 4.0000 - val_accuracy: 0.3333 - val_precision: 0.2941 - val_recall: 0.5556 - val_auc: 0.4630 - val_prc: 0.3964
</span></span><span class=line><span class=cl>    Epoch 98/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0968 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9886 - prc: 0.9866 - val_loss: 2.7720 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5778 - val_prc: 0.4204
</span></span><span class=line><span class=cl>    Epoch 99/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0579 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.6175 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5222 - val_prc: 0.3843
</span></span><span class=line><span class=cl>    Epoch 100/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.0369 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.2924 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4667 - val_prc: 0.3500
</span></span><span class=line><span class=cl>    Epoch 101/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0925 - tp: 22.0000 - fp: 2.0000 - tn: 34.0000 - fn: 0.0000e+00 - accuracy: 0.9655 - precision: 0.9167 - recall: 1.0000 - auc: 0.9962 - prc: 0.9936 - val_loss: 2.2516 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5259 - val_prc: 0.4097
</span></span><span class=line><span class=cl>    Epoch 102/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 203ms/step - loss: 0.0926 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9962 - prc: 0.9936 - val_loss: 2.0684 - val_tp: 8.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 1.0000 - val_accuracy: 0.3750 - val_precision: 0.3636 - val_recall: 0.8889 - val_auc: 0.5407 - val_prc: 0.4287
</span></span><span class=line><span class=cl>    Epoch 103/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0658 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.8156 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.4815 - val_prc: 0.3588
</span></span><span class=line><span class=cl>    Epoch 104/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 202ms/step - loss: 0.0603 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.3681 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.4667 - val_prc: 0.3429
</span></span><span class=line><span class=cl>    Epoch 105/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0254 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.4728 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4519 - val_prc: 0.3385
</span></span><span class=line><span class=cl>    Epoch 106/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0220 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.9446 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5185 - val_prc: 0.4030
</span></span><span class=line><span class=cl>    Epoch 107/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.0149 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.6206 - val_tp: 8.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 1.0000 - val_accuracy: 0.3750 - val_precision: 0.3636 - val_recall: 0.8889 - val_auc: 0.5037 - val_prc: 0.4005
</span></span><span class=line><span class=cl>    Epoch 108/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 202ms/step - loss: 0.0628 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.1908 - val_tp: 8.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4167 - val_precision: 0.3810 - val_recall: 0.8889 - val_auc: 0.6370 - val_prc: 0.5367
</span></span><span class=line><span class=cl>    Epoch 109/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0694 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.3011 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4222 - val_prc: 0.3490
</span></span><span class=line><span class=cl>    Epoch 110/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0740 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.0451 - val_tp: 8.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4211 - val_recall: 0.8889 - val_auc: 0.6074 - val_prc: 0.4386
</span></span><span class=line><span class=cl>    Epoch 111/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0756 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9962 - prc: 0.9936 - val_loss: 3.3727 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.5852 - val_prc: 0.4179
</span></span><span class=line><span class=cl>    Epoch 112/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.1125 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9924 - prc: 0.9893 - val_loss: 1.3505 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6111 - val_prc: 0.5408
</span></span><span class=line><span class=cl>    Epoch 113/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0879 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9949 - prc: 0.9929 - val_loss: 6.0629 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5667 - val_prc: 0.4091
</span></span><span class=line><span class=cl>    Epoch 114/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.0532 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.3074 - val_tp: 5.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 4.0000 - val_accuracy: 0.3333 - val_precision: 0.2941 - val_recall: 0.5556 - val_auc: 0.4852 - val_prc: 0.4030
</span></span><span class=line><span class=cl>    Epoch 115/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 201ms/step - loss: 0.1137 - tp: 20.0000 - fp: 2.0000 - tn: 34.0000 - fn: 2.0000 - accuracy: 0.9310 - precision: 0.9091 - recall: 0.9091 - auc: 0.9924 - prc: 0.9886 - val_loss: 1.7581 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.4556 - val_prc: 0.4986
</span></span><span class=line><span class=cl>    Epoch 116/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0722 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.2569 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 3.0000 - val_accuracy: 0.3750 - val_precision: 0.3333 - val_recall: 0.6667 - val_auc: 0.4556 - val_prc: 0.3915
</span></span><span class=line><span class=cl>    Epoch 117/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0887 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 1.6542 - val_tp: 5.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 4.0000 - val_accuracy: 0.5833 - val_precision: 0.4545 - val_recall: 0.5556 - val_auc: 0.5111 - val_prc: 0.4582
</span></span><span class=line><span class=cl>    Epoch 118/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.0650 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3462 - val_tp: 5.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 4.0000 - val_accuracy: 0.5000 - val_precision: 0.3846 - val_recall: 0.5556 - val_auc: 0.5481 - val_prc: 0.5434
</span></span><span class=line><span class=cl>    Epoch 119/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0646 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4556 - val_tp: 5.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 4.0000 - val_accuracy: 0.5417 - val_precision: 0.4167 - val_recall: 0.5556 - val_auc: 0.5185 - val_prc: 0.4586
</span></span><span class=line><span class=cl>    Epoch 120/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 204ms/step - loss: 0.0925 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9949 - prc: 0.9929 - val_loss: 1.4570 - val_tp: 4.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 5.0000 - val_accuracy: 0.5000 - val_precision: 0.3636 - val_recall: 0.4444 - val_auc: 0.5111 - val_prc: 0.5224
</span></span><span class=line><span class=cl>    Epoch 121/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0649 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5245 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 4.0000 - val_accuracy: 0.3750 - val_precision: 0.3125 - val_recall: 0.5556 - val_auc: 0.5185 - val_prc: 0.4232
</span></span><span class=line><span class=cl>    Epoch 122/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.0733 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 1.7170 - val_tp: 5.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 4.0000 - val_accuracy: 0.4167 - val_precision: 0.3333 - val_recall: 0.5556 - val_auc: 0.4926 - val_prc: 0.4044
</span></span><span class=line><span class=cl>    Epoch 123/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0667 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.8725 - val_tp: 7.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 2.0000 - val_accuracy: 0.4167 - val_precision: 0.3684 - val_recall: 0.7778 - val_auc: 0.5259 - val_prc: 0.3983
</span></span><span class=line><span class=cl>    Epoch 124/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.0969 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.0981 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.7259 - val_prc: 0.5298
</span></span><span class=line><span class=cl>    Epoch 125/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0381 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.9360 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.7000 - val_prc: 0.5000
</span></span><span class=line><span class=cl>    Epoch 126/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 203ms/step - loss: 0.0656 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9994 - prc: 0.9990 - val_loss: 4.9518 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6000 - val_prc: 0.4286
</span></span><span class=line><span class=cl>    Epoch 127/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0255 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.6203 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6481 - val_prc: 0.4632
</span></span><span class=line><span class=cl>    Epoch 128/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0593 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.5356 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5481 - val_prc: 0.4167
</span></span><span class=line><span class=cl>    Epoch 129/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.0628 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9975 - prc: 0.9961 - val_loss: 2.4770 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7333 - val_prc: 0.5378
</span></span><span class=line><span class=cl>    Epoch 130/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0474 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.2094 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6593 - val_prc: 0.4694
</span></span><span class=line><span class=cl>    Epoch 131/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.0504 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.4861 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5407 - val_prc: 0.3911
</span></span><span class=line><span class=cl>    Epoch 132/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0231 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.0904 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.4852 - val_prc: 0.3634
</span></span><span class=line><span class=cl>    Epoch 133/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0270 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.2913 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.4481 - val_prc: 0.3385
</span></span><span class=line><span class=cl>    Epoch 134/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0095 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.4317 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5222 - val_prc: 0.3846
</span></span><span class=line><span class=cl>    Epoch 135/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.0220 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.4199 - val_tp: 5.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 4.0000 - val_accuracy: 0.3333 - val_precision: 0.2941 - val_recall: 0.5556 - val_auc: 0.4852 - val_prc: 0.3649
</span></span><span class=line><span class=cl>    Epoch 136/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0174 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.6998 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 3.0000 - val_accuracy: 0.3750 - val_precision: 0.3333 - val_recall: 0.6667 - val_auc: 0.4593 - val_prc: 0.3626
</span></span><span class=line><span class=cl>    Epoch 137/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0079 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.4095 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.3775
</span></span><span class=line><span class=cl>    Epoch 138/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.0085 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.3366 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5037 - val_prc: 0.3786
</span></span><span class=line><span class=cl>    Epoch 139/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0092 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.8076 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.4259 - val_prc: 0.3315
</span></span><span class=line><span class=cl>    Epoch 140/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 203ms/step - loss: 0.0059 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.4575 - val_tp: 8.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4167 - val_precision: 0.3810 - val_recall: 0.8889 - val_auc: 0.4963 - val_prc: 0.4059
</span></span><span class=line><span class=cl>    Epoch 141/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0131 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.2473 - val_tp: 8.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 1.0000 - val_accuracy: 0.4583 - val_precision: 0.4000 - val_recall: 0.8889 - val_auc: 0.5185 - val_prc: 0.4143
</span></span><span class=line><span class=cl>    Epoch 142/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.0465 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.7348 - val_tp: 5.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 4.0000 - val_accuracy: 0.4583 - val_precision: 0.3571 - val_recall: 0.5556 - val_auc: 0.5333 - val_prc: 0.4518
</span></span><span class=line><span class=cl>    Epoch 143/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0906 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6769 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.5963 - val_prc: 0.5623
</span></span><span class=line><span class=cl>    Epoch 144/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0388 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3065 - val_tp: 4.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 5.0000 - val_accuracy: 0.5833 - val_precision: 0.4444 - val_recall: 0.4444 - val_auc: 0.5741 - val_prc: 0.5469
</span></span><span class=line><span class=cl>    Epoch 145/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0332 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5890 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 2.0000 - val_accuracy: 0.5417 - val_precision: 0.4375 - val_recall: 0.7778 - val_auc: 0.6148 - val_prc: 0.4760
</span></span><span class=line><span class=cl>    Epoch 146/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0701 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9962 - prc: 0.9940 - val_loss: 3.6880 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.4481 - val_prc: 0.3441
</span></span><span class=line><span class=cl>    Epoch 147/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.0342 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.1409 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 4.0000 - val_accuracy: 0.3750 - val_precision: 0.3125 - val_recall: 0.5556 - val_auc: 0.4926 - val_prc: 0.3831
</span></span><span class=line><span class=cl>    Epoch 148/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.0566 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.9883 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6000 - val_prc: 0.4391
</span></span><span class=line><span class=cl>    Epoch 149/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.0578 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 4.5376 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5852 - val_prc: 0.4203
</span></span><span class=line><span class=cl>    Epoch 150/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.0794 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9975 - prc: 0.9959 - val_loss: 3.9708 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6667 - val_prc: 0.4737
</span></span></code></pre></div></div><h3 id=intermediate-augmentation>Intermediate augmentation</h3><p>Additional layers, i.e., rotation, flip and shift, are enabled which will deeply enrich the training dataset.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>build_model</span><span class=p>(</span><span class=n>augmentation</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>rotation</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>flip</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>shift</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>zoom</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>shear</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>brightness</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>contrast</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>performance</span><span class=p>[</span><span class=s2>&#34;intermediate&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>train_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>training_dataset</span><span class=p>,</span> <span class=n>validation_dataset</span><span class=p>)</span>
</span></span></code></pre></div><div class=scrollable-output><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>    Epoch 1/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 10s 199ms/step - loss: 0.7231 - tp: 16.0000 - fp: 27.0000 - tn: 24.0000 - fn: 15.0000 - accuracy: 0.4878 - precision: 0.3721 - recall: 0.5161 - auc: 0.4956 - prc: 0.3989 - val_loss: 0.6800 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.3750
</span></span><span class=line><span class=cl>    Epoch 2/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6889 - tp: 3.0000 - fp: 8.0000 - tn: 28.0000 - fn: 19.0000 - accuracy: 0.5345 - precision: 0.2727 - recall: 0.1364 - auc: 0.4356 - prc: 0.3383 - val_loss: 0.6677 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3333 - val_prc: 0.2886
</span></span><span class=line><span class=cl>    Epoch 3/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6853 - tp: 4.0000 - fp: 4.0000 - tn: 32.0000 - fn: 18.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.1818 - auc: 0.4470 - prc: 0.3943 - val_loss: 0.6686 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4000 - val_prc: 0.3155
</span></span><span class=line><span class=cl>    Epoch 4/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6844 - tp: 1.0000 - fp: 5.0000 - tn: 31.0000 - fn: 21.0000 - accuracy: 0.5517 - precision: 0.1667 - recall: 0.0455 - auc: 0.4691 - prc: 0.3680 - val_loss: 0.7572 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4778 - val_prc: 0.3643
</span></span><span class=line><span class=cl>    Epoch 5/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.6479 - tp: 4.0000 - fp: 6.0000 - tn: 30.0000 - fn: 18.0000 - accuracy: 0.5862 - precision: 0.4000 - recall: 0.1818 - auc: 0.6086 - prc: 0.4274 - val_loss: 0.9019 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4000 - val_prc: 0.3155
</span></span><span class=line><span class=cl>    Epoch 6/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6591 - tp: 6.0000 - fp: 8.0000 - tn: 28.0000 - fn: 16.0000 - accuracy: 0.5862 - precision: 0.4286 - recall: 0.2727 - auc: 0.5922 - prc: 0.4135 - val_loss: 0.7039 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4630 - val_prc: 0.3416
</span></span><span class=line><span class=cl>    Epoch 7/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6428 - tp: 9.0000 - fp: 10.0000 - tn: 26.0000 - fn: 13.0000 - accuracy: 0.6034 - precision: 0.4737 - recall: 0.4091 - auc: 0.6345 - prc: 0.4728 - val_loss: 0.6765 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4630 - val_prc: 0.3887
</span></span><span class=line><span class=cl>    Epoch 8/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6761 - tp: 3.0000 - fp: 5.0000 - tn: 31.0000 - fn: 19.0000 - accuracy: 0.5862 - precision: 0.3750 - recall: 0.1364 - auc: 0.5038 - prc: 0.3718 - val_loss: 1.3303 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4111 - val_prc: 0.3283
</span></span><span class=line><span class=cl>    Epoch 9/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.6448 - tp: 3.0000 - fp: 3.0000 - tn: 33.0000 - fn: 19.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.1364 - auc: 0.6635 - prc: 0.5027 - val_loss: 1.3146 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.3750
</span></span><span class=line><span class=cl>    Epoch 10/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 202ms/step - loss: 0.7098 - tp: 2.0000 - fp: 8.0000 - tn: 28.0000 - fn: 20.0000 - accuracy: 0.5172 - precision: 0.2000 - recall: 0.0909 - auc: 0.4369 - prc: 0.3235 - val_loss: 1.2832 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6556 - val_prc: 0.5505
</span></span><span class=line><span class=cl>    Epoch 11/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.6728 - tp: 2.0000 - fp: 5.0000 - tn: 31.0000 - fn: 20.0000 - accuracy: 0.5690 - precision: 0.2857 - recall: 0.0909 - auc: 0.5145 - prc: 0.3877 - val_loss: 1.0651 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5444 - val_prc: 0.4924
</span></span><span class=line><span class=cl>    Epoch 12/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6299 - tp: 4.0000 - fp: 3.0000 - tn: 33.0000 - fn: 18.0000 - accuracy: 0.6379 - precision: 0.5714 - recall: 0.1818 - auc: 0.6604 - prc: 0.5622 - val_loss: 0.7223 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5889 - val_prc: 0.3991
</span></span><span class=line><span class=cl>    Epoch 13/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.7063 - tp: 2.0000 - fp: 6.0000 - tn: 30.0000 - fn: 20.0000 - accuracy: 0.5517 - precision: 0.2500 - recall: 0.0909 - auc: 0.4539 - prc: 0.3761 - val_loss: 0.8667 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4407 - val_prc: 0.3629
</span></span><span class=line><span class=cl>    Epoch 14/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6713 - tp: 3.0000 - fp: 5.0000 - tn: 31.0000 - fn: 19.0000 - accuracy: 0.5862 - precision: 0.3750 - recall: 0.1364 - auc: 0.5139 - prc: 0.4051 - val_loss: 0.6503 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6333 - val_prc: 0.5285
</span></span><span class=line><span class=cl>    Epoch 15/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6131 - tp: 7.0000 - fp: 4.0000 - tn: 32.0000 - fn: 15.0000 - accuracy: 0.6724 - precision: 0.6364 - recall: 0.3182 - auc: 0.7153 - prc: 0.5919 - val_loss: 0.9687 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5074 - val_prc: 0.4616
</span></span><span class=line><span class=cl>    Epoch 16/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 203ms/step - loss: 0.6645 - tp: 1.0000 - fp: 5.0000 - tn: 31.0000 - fn: 21.0000 - accuracy: 0.5517 - precision: 0.1667 - recall: 0.0455 - auc: 0.5657 - prc: 0.3811 - val_loss: 1.1999 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3296 - val_prc: 0.3140
</span></span><span class=line><span class=cl>    Epoch 17/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.6871 - tp: 2.0000 - fp: 4.0000 - tn: 32.0000 - fn: 20.0000 - accuracy: 0.5862 - precision: 0.3333 - recall: 0.0909 - auc: 0.5051 - prc: 0.3926 - val_loss: 1.1274 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3074 - val_prc: 0.3098
</span></span><span class=line><span class=cl>    Epoch 18/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6332 - tp: 4.0000 - fp: 3.0000 - tn: 33.0000 - fn: 18.0000 - accuracy: 0.6379 - precision: 0.5714 - recall: 0.1818 - auc: 0.6793 - prc: 0.4978 - val_loss: 0.7809 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5037 - val_prc: 0.3814
</span></span><span class=line><span class=cl>    Epoch 19/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6442 - tp: 8.0000 - fp: 6.0000 - tn: 30.0000 - fn: 14.0000 - accuracy: 0.6552 - precision: 0.5714 - recall: 0.3636 - auc: 0.6016 - prc: 0.5000 - val_loss: 0.6405 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.6556 - val_prc: 0.6124
</span></span><span class=line><span class=cl>    Epoch 20/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6440 - tp: 9.0000 - fp: 10.0000 - tn: 26.0000 - fn: 13.0000 - accuracy: 0.6034 - precision: 0.4737 - recall: 0.4091 - auc: 0.6654 - prc: 0.5345 - val_loss: 0.9431 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6741 - val_prc: 0.6805
</span></span><span class=line><span class=cl>    Epoch 21/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.6616 - tp: 11.0000 - fp: 7.0000 - tn: 29.0000 - fn: 11.0000 - accuracy: 0.6897 - precision: 0.6111 - recall: 0.5000 - auc: 0.6477 - prc: 0.5794 - val_loss: 0.6928 - val_tp: 5.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 4.0000 - val_accuracy: 0.5000 - val_precision: 0.3846 - val_recall: 0.5556 - val_auc: 0.5481 - val_prc: 0.5116
</span></span><span class=line><span class=cl>    Epoch 22/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.7111 - tp: 2.0000 - fp: 6.0000 - tn: 30.0000 - fn: 20.0000 - accuracy: 0.5517 - precision: 0.2500 - recall: 0.0909 - auc: 0.4217 - prc: 0.3235 - val_loss: 0.6896 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 9.0000 - val_accuracy: 0.5417 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4407 - val_prc: 0.3527
</span></span><span class=line><span class=cl>    Epoch 23/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6780 - tp: 5.0000 - fp: 3.0000 - tn: 33.0000 - fn: 17.0000 - accuracy: 0.6552 - precision: 0.6250 - recall: 0.2273 - auc: 0.6162 - prc: 0.4667 - val_loss: 0.7727 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 3.0000 - val_accuracy: 0.3750 - val_precision: 0.3333 - val_recall: 0.6667 - val_auc: 0.3593 - val_prc: 0.3773
</span></span><span class=line><span class=cl>    Epoch 24/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.6768 - tp: 2.0000 - fp: 3.0000 - tn: 33.0000 - fn: 20.0000 - accuracy: 0.6034 - precision: 0.4000 - recall: 0.0909 - auc: 0.5347 - prc: 0.3901 - val_loss: 0.7188 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 8.0000 - val_accuracy: 0.5833 - val_precision: 0.3333 - val_recall: 0.1111 - val_auc: 0.3074 - val_prc: 0.3651
</span></span><span class=line><span class=cl>    Epoch 25/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6734 - tp: 2.0000 - fp: 4.0000 - tn: 32.0000 - fn: 20.0000 - accuracy: 0.5862 - precision: 0.3333 - recall: 0.0909 - auc: 0.4905 - prc: 0.4147 - val_loss: 0.7435 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3370 - val_prc: 0.3695
</span></span><span class=line><span class=cl>    Epoch 26/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.6894 - tp: 5.0000 - fp: 5.0000 - tn: 31.0000 - fn: 17.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2273 - auc: 0.5271 - prc: 0.4133 - val_loss: 0.7057 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3741 - val_prc: 0.3137
</span></span><span class=line><span class=cl>    Epoch 27/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 202ms/step - loss: 0.6588 - tp: 3.0000 - fp: 2.0000 - tn: 34.0000 - fn: 19.0000 - accuracy: 0.6379 - precision: 0.6000 - recall: 0.1364 - auc: 0.6206 - prc: 0.4957 - val_loss: 0.6932 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4296 - val_prc: 0.3303
</span></span><span class=line><span class=cl>    Epoch 28/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.6489 - tp: 2.0000 - fp: 2.0000 - tn: 34.0000 - fn: 20.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.0909 - auc: 0.5884 - prc: 0.4461 - val_loss: 0.7580 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3778 - val_prc: 0.2952
</span></span><span class=line><span class=cl>    Epoch 29/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.6667 - tp: 4.0000 - fp: 4.0000 - tn: 32.0000 - fn: 18.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.1818 - auc: 0.5745 - prc: 0.4509 - val_loss: 0.6758 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.4407 - val_prc: 0.4427
</span></span><span class=line><span class=cl>    Epoch 30/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.6734 - tp: 7.0000 - fp: 6.0000 - tn: 30.0000 - fn: 15.0000 - accuracy: 0.6379 - precision: 0.5385 - recall: 0.3182 - auc: 0.5568 - prc: 0.4381 - val_loss: 0.7776 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5963 - val_prc: 0.3982
</span></span><span class=line><span class=cl>    Epoch 31/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6876 - tp: 6.0000 - fp: 8.0000 - tn: 28.0000 - fn: 16.0000 - accuracy: 0.5862 - precision: 0.4286 - recall: 0.2727 - auc: 0.5366 - prc: 0.3830 - val_loss: 0.7346 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.4111 - val_prc: 0.4668
</span></span><span class=line><span class=cl>    Epoch 32/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 202ms/step - loss: 0.6331 - tp: 6.0000 - fp: 6.0000 - tn: 30.0000 - fn: 16.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2727 - auc: 0.6610 - prc: 0.4939 - val_loss: 0.6994 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6926 - val_prc: 0.6041
</span></span><span class=line><span class=cl>    Epoch 33/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6269 - tp: 8.0000 - fp: 5.0000 - tn: 31.0000 - fn: 14.0000 - accuracy: 0.6724 - precision: 0.6154 - recall: 0.3636 - auc: 0.6629 - prc: 0.5904 - val_loss: 0.6840 - val_tp: 8.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4211 - val_recall: 0.8889 - val_auc: 0.6593 - val_prc: 0.5837
</span></span><span class=line><span class=cl>    Epoch 34/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6252 - tp: 9.0000 - fp: 6.0000 - tn: 30.0000 - fn: 13.0000 - accuracy: 0.6724 - precision: 0.6000 - recall: 0.4091 - auc: 0.6629 - prc: 0.5198 - val_loss: 0.7985 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5630 - val_prc: 0.5478
</span></span><span class=line><span class=cl>    Epoch 35/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6482 - tp: 3.0000 - fp: 3.0000 - tn: 33.0000 - fn: 19.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.1364 - auc: 0.6042 - prc: 0.4433 - val_loss: 0.8125 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5889 - val_prc: 0.5534
</span></span><span class=line><span class=cl>    Epoch 36/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.6576 - tp: 8.0000 - fp: 6.0000 - tn: 30.0000 - fn: 14.0000 - accuracy: 0.6552 - precision: 0.5714 - recall: 0.3636 - auc: 0.5878 - prc: 0.4602 - val_loss: 0.8182 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6111 - val_prc: 0.6427
</span></span><span class=line><span class=cl>    Epoch 37/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 202ms/step - loss: 0.5779 - tp: 9.0000 - fp: 3.0000 - tn: 33.0000 - fn: 13.0000 - accuracy: 0.7241 - precision: 0.7500 - recall: 0.4091 - auc: 0.7557 - prc: 0.6339 - val_loss: 0.8414 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6000 - val_prc: 0.5591
</span></span><span class=line><span class=cl>    Epoch 38/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.6377 - tp: 6.0000 - fp: 6.0000 - tn: 30.0000 - fn: 16.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2727 - auc: 0.6345 - prc: 0.5422 - val_loss: 0.8881 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5037 - val_prc: 0.3854
</span></span><span class=line><span class=cl>    Epoch 39/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.5844 - tp: 9.0000 - fp: 4.0000 - tn: 32.0000 - fn: 13.0000 - accuracy: 0.7069 - precision: 0.6923 - recall: 0.4091 - auc: 0.7298 - prc: 0.6593 - val_loss: 0.8948 - val_tp: 8.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 1.0000 - val_accuracy: 0.3333 - val_precision: 0.3478 - val_recall: 0.8889 - val_auc: 0.4148 - val_prc: 0.3516
</span></span><span class=line><span class=cl>    Epoch 40/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.6297 - tp: 12.0000 - fp: 7.0000 - tn: 29.0000 - fn: 10.0000 - accuracy: 0.7069 - precision: 0.6316 - recall: 0.5455 - auc: 0.6635 - prc: 0.5439 - val_loss: 0.6382 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6778 - val_prc: 0.5666
</span></span><span class=line><span class=cl>    Epoch 41/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.6754 - tp: 8.0000 - fp: 10.0000 - tn: 26.0000 - fn: 14.0000 - accuracy: 0.5862 - precision: 0.4444 - recall: 0.3636 - auc: 0.6023 - prc: 0.4386 - val_loss: 0.5928 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.7000 - val_prc: 0.5393
</span></span><span class=line><span class=cl>    Epoch 42/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 204ms/step - loss: 0.6478 - tp: 6.0000 - fp: 5.0000 - tn: 31.0000 - fn: 16.0000 - accuracy: 0.6379 - precision: 0.5455 - recall: 0.2727 - auc: 0.6143 - prc: 0.4462 - val_loss: 0.7146 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.7000 - val_prc: 0.5030
</span></span><span class=line><span class=cl>    Epoch 43/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6467 - tp: 5.0000 - fp: 6.0000 - tn: 30.0000 - fn: 17.0000 - accuracy: 0.6034 - precision: 0.4545 - recall: 0.2273 - auc: 0.6136 - prc: 0.5181 - val_loss: 0.6625 - val_tp: 8.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 1.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.8889 - val_auc: 0.7444 - val_prc: 0.6732
</span></span><span class=line><span class=cl>    Epoch 44/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 205ms/step - loss: 0.5776 - tp: 10.0000 - fp: 3.0000 - tn: 33.0000 - fn: 12.0000 - accuracy: 0.7414 - precision: 0.7692 - recall: 0.4545 - auc: 0.7740 - prc: 0.6486 - val_loss: 0.8812 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.7704 - val_prc: 0.6667
</span></span><span class=line><span class=cl>    Epoch 45/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6245 - tp: 6.0000 - fp: 6.0000 - tn: 30.0000 - fn: 16.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2727 - auc: 0.6818 - prc: 0.4868 - val_loss: 0.6010 - val_tp: 6.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.6667 - val_auc: 0.7259 - val_prc: 0.6229
</span></span><span class=line><span class=cl>    Epoch 46/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 201ms/step - loss: 0.5504 - tp: 12.0000 - fp: 7.0000 - tn: 29.0000 - fn: 10.0000 - accuracy: 0.7069 - precision: 0.6316 - recall: 0.5455 - auc: 0.8005 - prc: 0.6214 - val_loss: 0.6673 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7704 - val_prc: 0.6662
</span></span><span class=line><span class=cl>    Epoch 47/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6320 - tp: 10.0000 - fp: 7.0000 - tn: 29.0000 - fn: 12.0000 - accuracy: 0.6724 - precision: 0.5882 - recall: 0.4545 - auc: 0.6616 - prc: 0.5851 - val_loss: 1.2353 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5963 - val_prc: 0.6506
</span></span><span class=line><span class=cl>    Epoch 48/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6673 - tp: 5.0000 - fp: 6.0000 - tn: 30.0000 - fn: 17.0000 - accuracy: 0.6034 - precision: 0.4545 - recall: 0.2273 - auc: 0.5587 - prc: 0.4591 - val_loss: 0.6620 - val_tp: 5.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 4.0000 - val_accuracy: 0.5000 - val_precision: 0.3846 - val_recall: 0.5556 - val_auc: 0.6741 - val_prc: 0.6882
</span></span><span class=line><span class=cl>    Epoch 49/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.6260 - tp: 5.0000 - fp: 5.0000 - tn: 31.0000 - fn: 17.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2273 - auc: 0.6515 - prc: 0.4895 - val_loss: 0.6224 - val_tp: 6.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.7500 - val_precision: 0.6667 - val_recall: 0.6667 - val_auc: 0.7000 - val_prc: 0.5446
</span></span><span class=line><span class=cl>    Epoch 50/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.5576 - tp: 8.0000 - fp: 4.0000 - tn: 32.0000 - fn: 14.0000 - accuracy: 0.6897 - precision: 0.6667 - recall: 0.3636 - auc: 0.7809 - prc: 0.7074 - val_loss: 0.6304 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 5.0000 - val_accuracy: 0.7083 - val_precision: 0.6667 - val_recall: 0.4444 - val_auc: 0.6444 - val_prc: 0.5080
</span></span><span class=line><span class=cl>    Epoch 51/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 201ms/step - loss: 0.5758 - tp: 6.0000 - fp: 7.0000 - tn: 29.0000 - fn: 16.0000 - accuracy: 0.6034 - precision: 0.4615 - recall: 0.2727 - auc: 0.7443 - prc: 0.5919 - val_loss: 0.5417 - val_tp: 7.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.7778 - val_auc: 0.7481 - val_prc: 0.6548
</span></span><span class=line><span class=cl>    Epoch 52/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6394 - tp: 11.0000 - fp: 10.0000 - tn: 26.0000 - fn: 11.0000 - accuracy: 0.6379 - precision: 0.5238 - recall: 0.5000 - auc: 0.6313 - prc: 0.5428 - val_loss: 0.8636 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.7407 - val_prc: 0.6544
</span></span><span class=line><span class=cl>    Epoch 53/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.5710 - tp: 11.0000 - fp: 5.0000 - tn: 31.0000 - fn: 11.0000 - accuracy: 0.7241 - precision: 0.6875 - recall: 0.5000 - auc: 0.7614 - prc: 0.6236 - val_loss: 0.5986 - val_tp: 6.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 3.0000 - val_accuracy: 0.7083 - val_precision: 0.6000 - val_recall: 0.6667 - val_auc: 0.7704 - val_prc: 0.6903
</span></span><span class=line><span class=cl>    Epoch 54/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6205 - tp: 8.0000 - fp: 9.0000 - tn: 27.0000 - fn: 14.0000 - accuracy: 0.6034 - precision: 0.4706 - recall: 0.3636 - auc: 0.6597 - prc: 0.5286 - val_loss: 0.6661 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7926 - val_prc: 0.7478
</span></span><span class=line><span class=cl>    Epoch 55/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6115 - tp: 8.0000 - fp: 8.0000 - tn: 28.0000 - fn: 14.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.3636 - auc: 0.6881 - prc: 0.5360 - val_loss: 0.6422 - val_tp: 8.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.5417 - val_precision: 0.4444 - val_recall: 0.8889 - val_auc: 0.7741 - val_prc: 0.7251
</span></span><span class=line><span class=cl>    Epoch 56/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.5945 - tp: 10.0000 - fp: 9.0000 - tn: 27.0000 - fn: 12.0000 - accuracy: 0.6379 - precision: 0.5263 - recall: 0.4545 - auc: 0.7146 - prc: 0.5257 - val_loss: 0.8486 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.6852 - val_prc: 0.5973
</span></span><span class=line><span class=cl>    Epoch 57/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6536 - tp: 9.0000 - fp: 8.0000 - tn: 28.0000 - fn: 13.0000 - accuracy: 0.6379 - precision: 0.5294 - recall: 0.4091 - auc: 0.6143 - prc: 0.5606 - val_loss: 0.8299 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.7630 - val_prc: 0.5696
</span></span><span class=line><span class=cl>    Epoch 58/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.5820 - tp: 11.0000 - fp: 7.0000 - tn: 29.0000 - fn: 11.0000 - accuracy: 0.6897 - precision: 0.6111 - recall: 0.5000 - auc: 0.7412 - prc: 0.5989 - val_loss: 0.8487 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.7926 - val_prc: 0.7304
</span></span><span class=line><span class=cl>    Epoch 59/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.5255 - tp: 14.0000 - fp: 8.0000 - tn: 28.0000 - fn: 8.0000 - accuracy: 0.7241 - precision: 0.6364 - recall: 0.6364 - auc: 0.8024 - prc: 0.6227 - val_loss: 1.0695 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.7667 - val_prc: 0.6272
</span></span><span class=line><span class=cl>    Epoch 60/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.5907 - tp: 11.0000 - fp: 8.0000 - tn: 28.0000 - fn: 11.0000 - accuracy: 0.6724 - precision: 0.5789 - recall: 0.5000 - auc: 0.7140 - prc: 0.5619 - val_loss: 0.9581 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.7333 - val_prc: 0.5601
</span></span><span class=line><span class=cl>    Epoch 61/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 203ms/step - loss: 0.6408 - tp: 7.0000 - fp: 10.0000 - tn: 26.0000 - fn: 15.0000 - accuracy: 0.5690 - precision: 0.4118 - recall: 0.3182 - auc: 0.6326 - prc: 0.4991 - val_loss: 0.7301 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.7407 - val_prc: 0.5834
</span></span><span class=line><span class=cl>    Epoch 62/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.6845 - tp: 6.0000 - fp: 8.0000 - tn: 28.0000 - fn: 16.0000 - accuracy: 0.5862 - precision: 0.4286 - recall: 0.2727 - auc: 0.5713 - prc: 0.4162 - val_loss: 0.5686 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.7815 - val_prc: 0.7189
</span></span><span class=line><span class=cl>    Epoch 63/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6058 - tp: 11.0000 - fp: 4.0000 - tn: 32.0000 - fn: 11.0000 - accuracy: 0.7414 - precision: 0.7333 - recall: 0.5000 - auc: 0.7096 - prc: 0.6545 - val_loss: 0.6273 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.6444 - val_prc: 0.4692
</span></span><span class=line><span class=cl>    Epoch 64/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.5758 - tp: 10.0000 - fp: 7.0000 - tn: 29.0000 - fn: 12.0000 - accuracy: 0.6724 - precision: 0.5882 - recall: 0.4545 - auc: 0.7443 - prc: 0.5750 - val_loss: 0.5612 - val_tp: 6.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.6667 - val_auc: 0.7852 - val_prc: 0.6986
</span></span><span class=line><span class=cl>    Epoch 65/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.5364 - tp: 14.0000 - fp: 5.0000 - tn: 31.0000 - fn: 8.0000 - accuracy: 0.7759 - precision: 0.7368 - recall: 0.6364 - auc: 0.8043 - prc: 0.7823 - val_loss: 0.7267 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7815 - val_prc: 0.7058
</span></span><span class=line><span class=cl>    Epoch 66/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.5138 - tp: 10.0000 - fp: 4.0000 - tn: 32.0000 - fn: 12.0000 - accuracy: 0.7241 - precision: 0.7143 - recall: 0.4545 - auc: 0.8258 - prc: 0.7563 - val_loss: 0.8425 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7926 - val_prc: 0.6857
</span></span><span class=line><span class=cl>    Epoch 67/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.6064 - tp: 10.0000 - fp: 5.0000 - tn: 31.0000 - fn: 12.0000 - accuracy: 0.7069 - precision: 0.6667 - recall: 0.4545 - auc: 0.7020 - prc: 0.6413 - val_loss: 1.0756 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.7630 - val_prc: 0.6048
</span></span><span class=line><span class=cl>    Epoch 68/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.4752 - tp: 13.0000 - fp: 5.0000 - tn: 31.0000 - fn: 9.0000 - accuracy: 0.7586 - precision: 0.7222 - recall: 0.5909 - auc: 0.8586 - prc: 0.8092 - val_loss: 0.5514 - val_tp: 8.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 1.0000 - val_accuracy: 0.7083 - val_precision: 0.5714 - val_recall: 0.8889 - val_auc: 0.7778 - val_prc: 0.6908
</span></span><span class=line><span class=cl>    Epoch 69/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.5680 - tp: 7.0000 - fp: 6.0000 - tn: 30.0000 - fn: 15.0000 - accuracy: 0.6379 - precision: 0.5385 - recall: 0.3182 - auc: 0.7601 - prc: 0.6544 - val_loss: 0.7441 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7778 - val_prc: 0.6757
</span></span><span class=line><span class=cl>    Epoch 70/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.5528 - tp: 14.0000 - fp: 11.0000 - tn: 25.0000 - fn: 8.0000 - accuracy: 0.6724 - precision: 0.5600 - recall: 0.6364 - auc: 0.7620 - prc: 0.6741 - val_loss: 0.7975 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.8222 - val_prc: 0.7165
</span></span><span class=line><span class=cl>    Epoch 71/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6495 - tp: 8.0000 - fp: 10.0000 - tn: 26.0000 - fn: 14.0000 - accuracy: 0.5862 - precision: 0.4444 - recall: 0.3636 - auc: 0.6433 - prc: 0.4926 - val_loss: 0.5878 - val_tp: 6.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.7500 - val_precision: 0.6667 - val_recall: 0.6667 - val_auc: 0.7630 - val_prc: 0.6391
</span></span><span class=line><span class=cl>    Epoch 72/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 202ms/step - loss: 0.5368 - tp: 13.0000 - fp: 5.0000 - tn: 31.0000 - fn: 9.0000 - accuracy: 0.7586 - precision: 0.7222 - recall: 0.5909 - auc: 0.7986 - prc: 0.7753 - val_loss: 0.6693 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.8222 - val_prc: 0.7316
</span></span><span class=line><span class=cl>    Epoch 73/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.5834 - tp: 8.0000 - fp: 5.0000 - tn: 31.0000 - fn: 14.0000 - accuracy: 0.6724 - precision: 0.6154 - recall: 0.3636 - auc: 0.7109 - prc: 0.6415 - val_loss: 0.8784 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7852 - val_prc: 0.6437
</span></span><span class=line><span class=cl>    Epoch 74/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.5698 - tp: 9.0000 - fp: 5.0000 - tn: 31.0000 - fn: 13.0000 - accuracy: 0.6897 - precision: 0.6429 - recall: 0.4091 - auc: 0.7380 - prc: 0.6186 - val_loss: 0.7223 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7852 - val_prc: 0.6321
</span></span><span class=line><span class=cl>    Epoch 75/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.5552 - tp: 9.0000 - fp: 3.0000 - tn: 33.0000 - fn: 13.0000 - accuracy: 0.7241 - precision: 0.7500 - recall: 0.4091 - auc: 0.7677 - prc: 0.6878 - val_loss: 0.5878 - val_tp: 9.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7083 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.8296 - val_prc: 0.7571
</span></span><span class=line><span class=cl>    Epoch 76/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.6154 - tp: 6.0000 - fp: 8.0000 - tn: 28.0000 - fn: 16.0000 - accuracy: 0.5862 - precision: 0.4286 - recall: 0.2727 - auc: 0.6667 - prc: 0.5832 - val_loss: 1.0197 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.8074 - val_prc: 0.6452
</span></span><span class=line><span class=cl>    Epoch 77/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.4835 - tp: 15.0000 - fp: 7.0000 - tn: 29.0000 - fn: 7.0000 - accuracy: 0.7586 - precision: 0.6818 - recall: 0.6818 - auc: 0.8712 - prc: 0.8272 - val_loss: 0.7506 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7519 - val_prc: 0.5957
</span></span><span class=line><span class=cl>    Epoch 78/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.4491 - tp: 17.0000 - fp: 6.0000 - tn: 30.0000 - fn: 5.0000 - accuracy: 0.8103 - precision: 0.7391 - recall: 0.7727 - auc: 0.8838 - prc: 0.8397 - val_loss: 0.5670 - val_tp: 8.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 1.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.8889 - val_auc: 0.8333 - val_prc: 0.8122
</span></span><span class=line><span class=cl>    Epoch 79/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 203ms/step - loss: 0.6433 - tp: 8.0000 - fp: 8.0000 - tn: 28.0000 - fn: 14.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.3636 - auc: 0.6244 - prc: 0.5385 - val_loss: 0.7280 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7370 - val_prc: 0.5898
</span></span><span class=line><span class=cl>    Epoch 80/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.4756 - tp: 14.0000 - fp: 6.0000 - tn: 30.0000 - fn: 8.0000 - accuracy: 0.7586 - precision: 0.7000 - recall: 0.6364 - auc: 0.8491 - prc: 0.7622 - val_loss: 0.9462 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.7444 - val_prc: 0.5806
</span></span><span class=line><span class=cl>    Epoch 81/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.5501 - tp: 15.0000 - fp: 6.0000 - tn: 30.0000 - fn: 7.0000 - accuracy: 0.7759 - precision: 0.7143 - recall: 0.6818 - auc: 0.7677 - prc: 0.7080 - val_loss: 0.7317 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.7259 - val_prc: 0.5787
</span></span><span class=line><span class=cl>    Epoch 82/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.5671 - tp: 12.0000 - fp: 7.0000 - tn: 29.0000 - fn: 10.0000 - accuracy: 0.7069 - precision: 0.6316 - recall: 0.5455 - auc: 0.7633 - prc: 0.6235 - val_loss: 0.6504 - val_tp: 8.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.5417 - val_precision: 0.4444 - val_recall: 0.8889 - val_auc: 0.7222 - val_prc: 0.5968
</span></span><span class=line><span class=cl>    Epoch 83/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.5685 - tp: 12.0000 - fp: 11.0000 - tn: 25.0000 - fn: 10.0000 - accuracy: 0.6379 - precision: 0.5217 - recall: 0.5455 - auc: 0.7348 - prc: 0.5781 - val_loss: 0.5893 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.7407 - val_prc: 0.5896
</span></span><span class=line><span class=cl>    Epoch 84/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.4972 - tp: 17.0000 - fp: 6.0000 - tn: 30.0000 - fn: 5.0000 - accuracy: 0.8103 - precision: 0.7391 - recall: 0.7727 - auc: 0.8371 - prc: 0.7867 - val_loss: 0.5521 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 5.0000 - val_accuracy: 0.6667 - val_precision: 0.5714 - val_recall: 0.4444 - val_auc: 0.7407 - val_prc: 0.5887
</span></span><span class=line><span class=cl>    Epoch 85/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.5048 - tp: 12.0000 - fp: 2.0000 - tn: 34.0000 - fn: 10.0000 - accuracy: 0.7931 - precision: 0.8571 - recall: 0.5455 - auc: 0.8346 - prc: 0.8221 - val_loss: 0.6126 - val_tp: 8.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 1.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.8889 - val_auc: 0.7333 - val_prc: 0.6328
</span></span><span class=line><span class=cl>    Epoch 86/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.4749 - tp: 15.0000 - fp: 5.0000 - tn: 31.0000 - fn: 7.0000 - accuracy: 0.7931 - precision: 0.7500 - recall: 0.6818 - auc: 0.8554 - prc: 0.8553 - val_loss: 0.5405 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 5.0000 - val_accuracy: 0.7083 - val_precision: 0.6667 - val_recall: 0.4444 - val_auc: 0.7519 - val_prc: 0.6317
</span></span><span class=line><span class=cl>    Epoch 87/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.4594 - tp: 13.0000 - fp: 4.0000 - tn: 32.0000 - fn: 9.0000 - accuracy: 0.7759 - precision: 0.7647 - recall: 0.5909 - auc: 0.8636 - prc: 0.8104 - val_loss: 0.5732 - val_tp: 5.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 4.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.5556 - val_auc: 0.7704 - val_prc: 0.6328
</span></span><span class=line><span class=cl>    Epoch 88/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.4853 - tp: 13.0000 - fp: 5.0000 - tn: 31.0000 - fn: 9.0000 - accuracy: 0.7586 - precision: 0.7222 - recall: 0.5909 - auc: 0.8422 - prc: 0.7794 - val_loss: 0.6447 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.7111 - val_prc: 0.6129
</span></span><span class=line><span class=cl>    Epoch 89/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 204ms/step - loss: 0.4654 - tp: 13.0000 - fp: 6.0000 - tn: 30.0000 - fn: 9.0000 - accuracy: 0.7414 - precision: 0.6842 - recall: 0.5909 - auc: 0.8529 - prc: 0.7959 - val_loss: 0.5588 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.7556 - val_prc: 0.5767
</span></span><span class=line><span class=cl>    Epoch 90/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.5127 - tp: 13.0000 - fp: 5.0000 - tn: 31.0000 - fn: 9.0000 - accuracy: 0.7586 - precision: 0.7222 - recall: 0.5909 - auc: 0.8207 - prc: 0.8025 - val_loss: 0.5891 - val_tp: 7.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.7778 - val_auc: 0.7259 - val_prc: 0.5909
</span></span><span class=line><span class=cl>    Epoch 91/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.4447 - tp: 16.0000 - fp: 6.0000 - tn: 30.0000 - fn: 6.0000 - accuracy: 0.7931 - precision: 0.7273 - recall: 0.7273 - auc: 0.8744 - prc: 0.8160 - val_loss: 0.9514 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.7370 - val_prc: 0.5892
</span></span><span class=line><span class=cl>    Epoch 92/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.4973 - tp: 12.0000 - fp: 6.0000 - tn: 30.0000 - fn: 10.0000 - accuracy: 0.7241 - precision: 0.6667 - recall: 0.5455 - auc: 0.8093 - prc: 0.7440 - val_loss: 0.7238 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.8222 - val_prc: 0.6338
</span></span><span class=line><span class=cl>    Epoch 93/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.4992 - tp: 13.0000 - fp: 6.0000 - tn: 30.0000 - fn: 9.0000 - accuracy: 0.7414 - precision: 0.6842 - recall: 0.5909 - auc: 0.8213 - prc: 0.7252 - val_loss: 0.5491 - val_tp: 6.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 3.0000 - val_accuracy: 0.7083 - val_precision: 0.6000 - val_recall: 0.6667 - val_auc: 0.7741 - val_prc: 0.6171
</span></span><span class=line><span class=cl>    Epoch 94/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.4720 - tp: 11.0000 - fp: 2.0000 - tn: 34.0000 - fn: 11.0000 - accuracy: 0.7759 - precision: 0.8462 - recall: 0.5000 - auc: 0.8327 - prc: 0.8080 - val_loss: 0.7878 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7778 - val_prc: 0.6203
</span></span><span class=line><span class=cl>    Epoch 95/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.4566 - tp: 13.0000 - fp: 5.0000 - tn: 31.0000 - fn: 9.0000 - accuracy: 0.7586 - precision: 0.7222 - recall: 0.5909 - auc: 0.8516 - prc: 0.7921 - val_loss: 0.8299 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7444 - val_prc: 0.5831
</span></span><span class=line><span class=cl>    Epoch 96/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 203ms/step - loss: 0.3962 - tp: 18.0000 - fp: 3.0000 - tn: 33.0000 - fn: 4.0000 - accuracy: 0.8793 - precision: 0.8571 - recall: 0.8182 - auc: 0.9205 - prc: 0.8865 - val_loss: 0.6900 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.7407 - val_prc: 0.5802
</span></span><span class=line><span class=cl>    Epoch 97/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.4767 - tp: 16.0000 - fp: 8.0000 - tn: 28.0000 - fn: 6.0000 - accuracy: 0.7586 - precision: 0.6667 - recall: 0.7273 - auc: 0.8314 - prc: 0.7729 - val_loss: 0.9409 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.7630 - val_prc: 0.5902
</span></span><span class=line><span class=cl>    Epoch 98/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.5089 - tp: 13.0000 - fp: 6.0000 - tn: 30.0000 - fn: 9.0000 - accuracy: 0.7414 - precision: 0.6842 - recall: 0.5909 - auc: 0.8068 - prc: 0.7213 - val_loss: 0.7647 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7926 - val_prc: 0.6194
</span></span><span class=line><span class=cl>    Epoch 99/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.3814 - tp: 18.0000 - fp: 3.0000 - tn: 33.0000 - fn: 4.0000 - accuracy: 0.8793 - precision: 0.8571 - recall: 0.8182 - auc: 0.9211 - prc: 0.8757 - val_loss: 0.6917 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7630 - val_prc: 0.5997
</span></span><span class=line><span class=cl>    Epoch 100/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.4576 - tp: 14.0000 - fp: 7.0000 - tn: 29.0000 - fn: 8.0000 - accuracy: 0.7414 - precision: 0.6667 - recall: 0.6364 - auc: 0.8403 - prc: 0.7991 - val_loss: 0.5468 - val_tp: 7.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 2.0000 - val_accuracy: 0.7083 - val_precision: 0.5833 - val_recall: 0.7778 - val_auc: 0.7926 - val_prc: 0.6373
</span></span><span class=line><span class=cl>    Epoch 101/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.4992 - tp: 10.0000 - fp: 6.0000 - tn: 30.0000 - fn: 12.0000 - accuracy: 0.6897 - precision: 0.6250 - recall: 0.4545 - auc: 0.8150 - prc: 0.6876 - val_loss: 0.5874 - val_tp: 9.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7917 - val_precision: 0.6429 - val_recall: 1.0000 - val_auc: 0.7963 - val_prc: 0.6272
</span></span><span class=line><span class=cl>    Epoch 102/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.3978 - tp: 16.0000 - fp: 5.0000 - tn: 31.0000 - fn: 6.0000 - accuracy: 0.8103 - precision: 0.7619 - recall: 0.7273 - auc: 0.8971 - prc: 0.8646 - val_loss: 0.5416 - val_tp: 9.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7083 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.8481 - val_prc: 0.7233
</span></span><span class=line><span class=cl>    Epoch 103/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 203ms/step - loss: 0.3225 - tp: 20.0000 - fp: 4.0000 - tn: 32.0000 - fn: 2.0000 - accuracy: 0.8966 - precision: 0.8333 - recall: 0.9091 - auc: 0.9508 - prc: 0.9096 - val_loss: 0.6056 - val_tp: 9.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7500 - val_precision: 0.6000 - val_recall: 1.0000 - val_auc: 0.8111 - val_prc: 0.6288
</span></span><span class=line><span class=cl>    Epoch 104/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 177ms/step - loss: 0.4978 - tp: 14.0000 - fp: 7.0000 - tn: 29.0000 - fn: 8.0000 - accuracy: 0.7414 - precision: 0.6667 - recall: 0.6364 - auc: 0.8169 - prc: 0.7811 - val_loss: 0.5363 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 7.0000 - val_accuracy: 0.5833 - val_precision: 0.4000 - val_recall: 0.2222 - val_auc: 0.8259 - val_prc: 0.6409
</span></span><span class=line><span class=cl>    Epoch 105/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.4204 - tp: 17.0000 - fp: 7.0000 - tn: 29.0000 - fn: 5.0000 - accuracy: 0.7931 - precision: 0.7083 - recall: 0.7727 - auc: 0.8920 - prc: 0.8506 - val_loss: 0.7022 - val_tp: 8.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.7917 - val_precision: 0.6667 - val_recall: 0.8889 - val_auc: 0.7852 - val_prc: 0.6055
</span></span><span class=line><span class=cl>    Epoch 106/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 178ms/step - loss: 0.4013 - tp: 14.0000 - fp: 5.0000 - tn: 31.0000 - fn: 8.0000 - accuracy: 0.7759 - precision: 0.7368 - recall: 0.6364 - auc: 0.8984 - prc: 0.8537 - val_loss: 0.6417 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 5.0000 - val_accuracy: 0.6667 - val_precision: 0.5714 - val_recall: 0.4444 - val_auc: 0.8074 - val_prc: 0.6291
</span></span><span class=line><span class=cl>    Epoch 107/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.4677 - tp: 15.0000 - fp: 7.0000 - tn: 29.0000 - fn: 7.0000 - accuracy: 0.7586 - precision: 0.6818 - recall: 0.6818 - auc: 0.8403 - prc: 0.7835 - val_loss: 0.7031 - val_tp: 9.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6667 - val_precision: 0.5294 - val_recall: 1.0000 - val_auc: 0.7556 - val_prc: 0.5980
</span></span><span class=line><span class=cl>    Epoch 108/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.4087 - tp: 17.0000 - fp: 7.0000 - tn: 29.0000 - fn: 5.0000 - accuracy: 0.7931 - precision: 0.7083 - recall: 0.7727 - auc: 0.8965 - prc: 0.8407 - val_loss: 0.5617 - val_tp: 7.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 2.0000 - val_accuracy: 0.7083 - val_precision: 0.5833 - val_recall: 0.7778 - val_auc: 0.7704 - val_prc: 0.6275
</span></span><span class=line><span class=cl>    Epoch 109/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.3948 - tp: 18.0000 - fp: 7.0000 - tn: 29.0000 - fn: 4.0000 - accuracy: 0.8103 - precision: 0.7200 - recall: 0.8182 - auc: 0.9141 - prc: 0.8720 - val_loss: 0.7229 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7926 - val_prc: 0.6126
</span></span><span class=line><span class=cl>    Epoch 110/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.4375 - tp: 15.0000 - fp: 3.0000 - tn: 33.0000 - fn: 7.0000 - accuracy: 0.8276 - precision: 0.8333 - recall: 0.6818 - auc: 0.8712 - prc: 0.8051 - val_loss: 0.9132 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7963 - val_prc: 0.5592
</span></span><span class=line><span class=cl>    Epoch 111/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 204ms/step - loss: 0.4325 - tp: 14.0000 - fp: 4.0000 - tn: 32.0000 - fn: 8.0000 - accuracy: 0.7931 - precision: 0.7778 - recall: 0.6364 - auc: 0.8725 - prc: 0.8424 - val_loss: 0.7350 - val_tp: 7.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.7778 - val_auc: 0.7519 - val_prc: 0.5969
</span></span><span class=line><span class=cl>    Epoch 112/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 206ms/step - loss: 0.3652 - tp: 18.0000 - fp: 3.0000 - tn: 33.0000 - fn: 4.0000 - accuracy: 0.8793 - precision: 0.8571 - recall: 0.8182 - auc: 0.9173 - prc: 0.8903 - val_loss: 0.7394 - val_tp: 9.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7917 - val_precision: 0.6429 - val_recall: 1.0000 - val_auc: 0.8148 - val_prc: 0.5568
</span></span><span class=line><span class=cl>    Epoch 113/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.3341 - tp: 18.0000 - fp: 3.0000 - tn: 33.0000 - fn: 4.0000 - accuracy: 0.8793 - precision: 0.8571 - recall: 0.8182 - auc: 0.9318 - prc: 0.8883 - val_loss: 0.7916 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.8074 - val_prc: 0.5688
</span></span><span class=line><span class=cl>    Epoch 114/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 204ms/step - loss: 0.3653 - tp: 16.0000 - fp: 6.0000 - tn: 30.0000 - fn: 6.0000 - accuracy: 0.7931 - precision: 0.7273 - recall: 0.7273 - auc: 0.9129 - prc: 0.8670 - val_loss: 0.5830 - val_tp: 9.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7917 - val_precision: 0.6429 - val_recall: 1.0000 - val_auc: 0.8259 - val_prc: 0.6409
</span></span><span class=line><span class=cl>    Epoch 115/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.4516 - tp: 14.0000 - fp: 7.0000 - tn: 29.0000 - fn: 8.0000 - accuracy: 0.7414 - precision: 0.6667 - recall: 0.6364 - auc: 0.8573 - prc: 0.8112 - val_loss: 0.9753 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7556 - val_prc: 0.5279
</span></span><span class=line><span class=cl>    Epoch 116/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.3821 - tp: 15.0000 - fp: 2.0000 - tn: 34.0000 - fn: 7.0000 - accuracy: 0.8448 - precision: 0.8824 - recall: 0.6818 - auc: 0.9217 - prc: 0.8727 - val_loss: 0.8852 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 2.0000 - val_accuracy: 0.5417 - val_precision: 0.4375 - val_recall: 0.7778 - val_auc: 0.7111 - val_prc: 0.5018
</span></span><span class=line><span class=cl>    Epoch 117/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.3503 - tp: 19.0000 - fp: 6.0000 - tn: 30.0000 - fn: 3.0000 - accuracy: 0.8448 - precision: 0.7600 - recall: 0.8636 - auc: 0.9312 - prc: 0.9195 - val_loss: 0.8045 - val_tp: 7.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.7917 - val_precision: 0.7000 - val_recall: 0.7778 - val_auc: 0.6778 - val_prc: 0.4830
</span></span><span class=line><span class=cl>    Epoch 118/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.3895 - tp: 15.0000 - fp: 2.0000 - tn: 34.0000 - fn: 7.0000 - accuracy: 0.8448 - precision: 0.8824 - recall: 0.6818 - auc: 0.9034 - prc: 0.8964 - val_loss: 0.6635 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.7556 - val_prc: 0.6040
</span></span><span class=line><span class=cl>    Epoch 119/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 186ms/step - loss: 0.5087 - tp: 12.0000 - fp: 10.0000 - tn: 26.0000 - fn: 10.0000 - accuracy: 0.6552 - precision: 0.5455 - recall: 0.5455 - auc: 0.7948 - prc: 0.7226 - val_loss: 0.6657 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.8000 - val_prc: 0.5502
</span></span><span class=line><span class=cl>    Epoch 120/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.2348 - tp: 21.0000 - fp: 2.0000 - tn: 34.0000 - fn: 1.0000 - accuracy: 0.9483 - precision: 0.9130 - recall: 0.9545 - auc: 0.9798 - prc: 0.9608 - val_loss: 0.5682 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 5.0000 - val_accuracy: 0.6667 - val_precision: 0.5714 - val_recall: 0.4444 - val_auc: 0.7778 - val_prc: 0.6127
</span></span><span class=line><span class=cl>    Epoch 121/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.3735 - tp: 17.0000 - fp: 5.0000 - tn: 31.0000 - fn: 5.0000 - accuracy: 0.8276 - precision: 0.7727 - recall: 0.7727 - auc: 0.9097 - prc: 0.8467 - val_loss: 0.5960 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.7222 - val_prc: 0.6640
</span></span><span class=line><span class=cl>    Epoch 122/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.3904 - tp: 18.0000 - fp: 4.0000 - tn: 32.0000 - fn: 4.0000 - accuracy: 0.8621 - precision: 0.8182 - recall: 0.8182 - auc: 0.9059 - prc: 0.8604 - val_loss: 0.7521 - val_tp: 7.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.7917 - val_precision: 0.7000 - val_recall: 0.7778 - val_auc: 0.8074 - val_prc: 0.5730
</span></span><span class=line><span class=cl>    Epoch 123/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.4307 - tp: 13.0000 - fp: 4.0000 - tn: 32.0000 - fn: 9.0000 - accuracy: 0.7759 - precision: 0.7647 - recall: 0.5909 - auc: 0.8662 - prc: 0.8304 - val_loss: 0.8221 - val_tp: 8.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 1.0000 - val_accuracy: 0.7500 - val_precision: 0.6154 - val_recall: 0.8889 - val_auc: 0.7815 - val_prc: 0.5605
</span></span><span class=line><span class=cl>    Epoch 124/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.3608 - tp: 15.0000 - fp: 4.0000 - tn: 32.0000 - fn: 7.0000 - accuracy: 0.8103 - precision: 0.7895 - recall: 0.6818 - auc: 0.9173 - prc: 0.8897 - val_loss: 0.6435 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 6.0000 - val_accuracy: 0.6667 - val_precision: 0.6000 - val_recall: 0.3333 - val_auc: 0.7963 - val_prc: 0.6412
</span></span><span class=line><span class=cl>    Epoch 125/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 204ms/step - loss: 0.4595 - tp: 12.0000 - fp: 7.0000 - tn: 29.0000 - fn: 10.0000 - accuracy: 0.7069 - precision: 0.6316 - recall: 0.5455 - auc: 0.8510 - prc: 0.8111 - val_loss: 0.5586 - val_tp: 7.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.7917 - val_precision: 0.7000 - val_recall: 0.7778 - val_auc: 0.8444 - val_prc: 0.6860
</span></span><span class=line><span class=cl>    Epoch 126/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.5282 - tp: 14.0000 - fp: 6.0000 - tn: 30.0000 - fn: 8.0000 - accuracy: 0.7586 - precision: 0.7000 - recall: 0.6364 - auc: 0.7973 - prc: 0.7196 - val_loss: 0.5984 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.8444 - val_prc: 0.6145
</span></span><span class=line><span class=cl>    Epoch 127/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.2486 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9823 - prc: 0.9752 - val_loss: 0.5118 - val_tp: 5.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7500 - val_precision: 0.7143 - val_recall: 0.5556 - val_auc: 0.8296 - val_prc: 0.6650
</span></span><span class=line><span class=cl>    Epoch 128/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.3434 - tp: 18.0000 - fp: 4.0000 - tn: 32.0000 - fn: 4.0000 - accuracy: 0.8621 - precision: 0.8182 - recall: 0.8182 - auc: 0.9261 - prc: 0.9242 - val_loss: 0.8890 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.8519 - val_prc: 0.6766
</span></span><span class=line><span class=cl>    Epoch 129/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.3145 - tp: 18.0000 - fp: 4.0000 - tn: 32.0000 - fn: 4.0000 - accuracy: 0.8621 - precision: 0.8182 - recall: 0.8182 - auc: 0.9457 - prc: 0.9302 - val_loss: 0.7309 - val_tp: 9.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7917 - val_precision: 0.6429 - val_recall: 1.0000 - val_auc: 0.8296 - val_prc: 0.5784
</span></span><span class=line><span class=cl>    Epoch 130/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 205ms/step - loss: 0.3860 - tp: 15.0000 - fp: 5.0000 - tn: 31.0000 - fn: 7.0000 - accuracy: 0.7931 - precision: 0.7500 - recall: 0.6818 - auc: 0.9040 - prc: 0.8792 - val_loss: 0.7924 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7741 - val_prc: 0.6130
</span></span><span class=line><span class=cl>    Epoch 131/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.3228 - tp: 16.0000 - fp: 3.0000 - tn: 33.0000 - fn: 6.0000 - accuracy: 0.8448 - precision: 0.8421 - recall: 0.7273 - auc: 0.9337 - prc: 0.9099 - val_loss: 0.5971 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 5.0000 - val_accuracy: 0.7083 - val_precision: 0.6667 - val_recall: 0.4444 - val_auc: 0.7630 - val_prc: 0.6222
</span></span><span class=line><span class=cl>    Epoch 132/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.4218 - tp: 16.0000 - fp: 6.0000 - tn: 30.0000 - fn: 6.0000 - accuracy: 0.7931 - precision: 0.7273 - recall: 0.7273 - auc: 0.8788 - prc: 0.8136 - val_loss: 0.5367 - val_tp: 6.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.6667 - val_auc: 0.7704 - val_prc: 0.5306
</span></span><span class=line><span class=cl>    Epoch 133/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.3656 - tp: 17.0000 - fp: 5.0000 - tn: 31.0000 - fn: 5.0000 - accuracy: 0.8276 - precision: 0.7727 - recall: 0.7727 - auc: 0.9078 - prc: 0.8838 - val_loss: 0.9682 - val_tp: 9.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6667 - val_precision: 0.5294 - val_recall: 1.0000 - val_auc: 0.8074 - val_prc: 0.5502
</span></span><span class=line><span class=cl>    Epoch 134/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.3243 - tp: 17.0000 - fp: 3.0000 - tn: 33.0000 - fn: 5.0000 - accuracy: 0.8621 - precision: 0.8500 - recall: 0.7727 - auc: 0.9426 - prc: 0.9233 - val_loss: 1.0982 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7074 - val_prc: 0.4750
</span></span><span class=line><span class=cl>    Epoch 135/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 205ms/step - loss: 0.3823 - tp: 15.0000 - fp: 6.0000 - tn: 30.0000 - fn: 7.0000 - accuracy: 0.7759 - precision: 0.7143 - recall: 0.6818 - auc: 0.9015 - prc: 0.8525 - val_loss: 0.6301 - val_tp: 6.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.7500 - val_precision: 0.6667 - val_recall: 0.6667 - val_auc: 0.7556 - val_prc: 0.5358
</span></span><span class=line><span class=cl>    Epoch 136/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.3087 - tp: 19.0000 - fp: 6.0000 - tn: 30.0000 - fn: 3.0000 - accuracy: 0.8448 - precision: 0.7600 - recall: 0.8636 - auc: 0.9457 - prc: 0.9215 - val_loss: 0.6437 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.7444 - val_prc: 0.6089
</span></span><span class=line><span class=cl>    Epoch 137/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.2735 - tp: 19.0000 - fp: 3.0000 - tn: 33.0000 - fn: 3.0000 - accuracy: 0.8966 - precision: 0.8636 - recall: 0.8636 - auc: 0.9602 - prc: 0.9406 - val_loss: 0.7527 - val_tp: 8.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 1.0000 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.8889 - val_auc: 0.7407 - val_prc: 0.5234
</span></span><span class=line><span class=cl>    Epoch 138/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.3350 - tp: 15.0000 - fp: 3.0000 - tn: 33.0000 - fn: 7.0000 - accuracy: 0.8276 - precision: 0.8333 - recall: 0.6818 - auc: 0.9318 - prc: 0.8967 - val_loss: 1.2845 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.6778 - val_prc: 0.4751
</span></span><span class=line><span class=cl>    Epoch 139/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.2660 - tp: 20.0000 - fp: 4.0000 - tn: 32.0000 - fn: 2.0000 - accuracy: 0.8966 - precision: 0.8333 - recall: 0.9091 - auc: 0.9634 - prc: 0.9440 - val_loss: 1.0685 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7519 - val_prc: 0.5315
</span></span><span class=line><span class=cl>    Epoch 140/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.3174 - tp: 17.0000 - fp: 1.0000 - tn: 35.0000 - fn: 5.0000 - accuracy: 0.8966 - precision: 0.9444 - recall: 0.7727 - auc: 0.9362 - prc: 0.9181 - val_loss: 0.5186 - val_tp: 9.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7500 - val_precision: 0.6000 - val_recall: 1.0000 - val_auc: 0.8185 - val_prc: 0.6623
</span></span><span class=line><span class=cl>    Epoch 141/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.2520 - tp: 21.0000 - fp: 3.0000 - tn: 33.0000 - fn: 1.0000 - accuracy: 0.9310 - precision: 0.8750 - recall: 0.9545 - auc: 0.9691 - prc: 0.9353 - val_loss: 0.5983 - val_tp: 6.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 3.0000 - val_accuracy: 0.7083 - val_precision: 0.6000 - val_recall: 0.6667 - val_auc: 0.7815 - val_prc: 0.5590
</span></span><span class=line><span class=cl>    Epoch 142/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.2707 - tp: 17.0000 - fp: 2.0000 - tn: 34.0000 - fn: 5.0000 - accuracy: 0.8793 - precision: 0.8947 - recall: 0.7727 - auc: 0.9672 - prc: 0.9555 - val_loss: 0.8502 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7741 - val_prc: 0.5509
</span></span><span class=line><span class=cl>    Epoch 143/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.2451 - tp: 16.0000 - fp: 2.0000 - tn: 34.0000 - fn: 6.0000 - accuracy: 0.8621 - precision: 0.8889 - recall: 0.7273 - auc: 0.9602 - prc: 0.9489 - val_loss: 0.7822 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.8407 - val_prc: 0.5990
</span></span><span class=line><span class=cl>    Epoch 144/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.4054 - tp: 16.0000 - fp: 8.0000 - tn: 28.0000 - fn: 6.0000 - accuracy: 0.7586 - precision: 0.6667 - recall: 0.7273 - auc: 0.8838 - prc: 0.8657 - val_loss: 0.6807 - val_tp: 6.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 3.0000 - val_accuracy: 0.5833 - val_precision: 0.4615 - val_recall: 0.6667 - val_auc: 0.6593 - val_prc: 0.5073
</span></span><span class=line><span class=cl>    Epoch 145/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.3129 - tp: 16.0000 - fp: 6.0000 - tn: 30.0000 - fn: 6.0000 - accuracy: 0.7931 - precision: 0.7273 - recall: 0.7273 - auc: 0.9318 - prc: 0.9062 - val_loss: 1.0719 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7741 - val_prc: 0.5227
</span></span><span class=line><span class=cl>    Epoch 146/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.2956 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9527 - prc: 0.9343 - val_loss: 0.8674 - val_tp: 9.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6667 - val_precision: 0.5294 - val_recall: 1.0000 - val_auc: 0.7519 - val_prc: 0.5146
</span></span><span class=line><span class=cl>    Epoch 147/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.3469 - tp: 16.0000 - fp: 4.0000 - tn: 32.0000 - fn: 6.0000 - accuracy: 0.8276 - precision: 0.8000 - recall: 0.7273 - auc: 0.9167 - prc: 0.8675 - val_loss: 1.3816 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.7630 - val_prc: 0.5416
</span></span><span class=line><span class=cl>    Epoch 148/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.2680 - tp: 18.0000 - fp: 4.0000 - tn: 32.0000 - fn: 4.0000 - accuracy: 0.8621 - precision: 0.8182 - recall: 0.8182 - auc: 0.9552 - prc: 0.9417 - val_loss: 0.6550 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.7704 - val_prc: 0.5871
</span></span><span class=line><span class=cl>    Epoch 149/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.2699 - tp: 19.0000 - fp: 4.0000 - tn: 32.0000 - fn: 3.0000 - accuracy: 0.8793 - precision: 0.8261 - recall: 0.8636 - auc: 0.9640 - prc: 0.9416 - val_loss: 1.2333 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.7778 - val_prc: 0.5428
</span></span><span class=line><span class=cl>    Epoch 150/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.3789 - tp: 13.0000 - fp: 3.0000 - tn: 33.0000 - fn: 9.0000 - accuracy: 0.7931 - precision: 0.8125 - recall: 0.5909 - auc: 0.8977 - prc: 0.8600 - val_loss: 0.9867 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.8185 - val_prc: 0.5882
</span></span></code></pre></div></div><h3 id=advanced-augmentation>Advanced augmentation</h3><p>The advanced approach is more aggressive since it includes zoom and even shear augmentation. As already specified, the latter also introduces an image distortion.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>build_model</span><span class=p>(</span><span class=n>augmentation</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>rotation</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>flip</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>shift</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>zoom</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>shear</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>brightness</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>contrast</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>performance</span><span class=p>[</span><span class=s2>&#34;advanced&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=n>train_model</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>training_dataset</span><span class=p>,</span> <span class=n>validation_dataset</span><span class=p>)</span>
</span></span></code></pre></div><div class=scrollable-output><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>    WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
</span></span><span class=line><span class=cl>    WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    Epoch 1/150
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
</span></span><span class=line><span class=cl>    WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
</span></span><span class=line><span class=cl>    WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
</span></span><span class=line><span class=cl>    WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    29/29 [==============================] - 12s 203ms/step - loss: 0.7046 - tp: 14.0000 - fp: 22.0000 - tn: 29.0000 - fn: 17.0000 - accuracy: 0.5244 - precision: 0.3889 - recall: 0.4516 - auc: 0.5427 - prc: 0.4471 - val_loss: 0.6764 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4222 - val_prc: 0.3302
</span></span><span class=line><span class=cl>    Epoch 2/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.6903 - tp: 2.0000 - fp: 7.0000 - tn: 29.0000 - fn: 20.0000 - accuracy: 0.5345 - precision: 0.2222 - recall: 0.0909 - auc: 0.4848 - prc: 0.3495 - val_loss: 0.7282 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5778 - val_prc: 0.4324
</span></span><span class=line><span class=cl>    Epoch 3/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.6244 - tp: 7.0000 - fp: 7.0000 - tn: 29.0000 - fn: 15.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.3182 - auc: 0.6578 - prc: 0.5596 - val_loss: 0.7974 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.3481 - val_prc: 0.3063
</span></span><span class=line><span class=cl>    Epoch 4/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6840 - tp: 8.0000 - fp: 13.0000 - tn: 23.0000 - fn: 14.0000 - accuracy: 0.5345 - precision: 0.3810 - recall: 0.3636 - auc: 0.5644 - prc: 0.3948 - val_loss: 0.9454 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.3750
</span></span><span class=line><span class=cl>    Epoch 5/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.7390 - tp: 5.0000 - fp: 14.0000 - tn: 22.0000 - fn: 17.0000 - accuracy: 0.4655 - precision: 0.2632 - recall: 0.2273 - auc: 0.3977 - prc: 0.3196 - val_loss: 0.7560 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5926 - val_prc: 0.5165
</span></span><span class=line><span class=cl>    Epoch 6/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.6541 - tp: 6.0000 - fp: 2.0000 - tn: 34.0000 - fn: 16.0000 - accuracy: 0.6897 - precision: 0.7500 - recall: 0.2727 - auc: 0.6168 - prc: 0.5517 - val_loss: 0.8246 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6370 - val_prc: 0.5326
</span></span><span class=line><span class=cl>    Epoch 7/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.7085 - tp: 6.0000 - fp: 13.0000 - tn: 23.0000 - fn: 16.0000 - accuracy: 0.5000 - precision: 0.3158 - recall: 0.2727 - auc: 0.4217 - prc: 0.3568 - val_loss: 0.6744 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6000 - val_prc: 0.5026
</span></span><span class=line><span class=cl>    Epoch 8/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 205ms/step - loss: 0.6690 - tp: 2.0000 - fp: 4.0000 - tn: 32.0000 - fn: 20.0000 - accuracy: 0.5862 - precision: 0.3333 - recall: 0.0909 - auc: 0.5025 - prc: 0.3570 - val_loss: 0.7372 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.3063
</span></span><span class=line><span class=cl>    Epoch 9/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6826 - tp: 2.0000 - fp: 2.0000 - tn: 34.0000 - fn: 20.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.0909 - auc: 0.4413 - prc: 0.4079 - val_loss: 0.6816 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5630 - val_prc: 0.5217
</span></span><span class=line><span class=cl>    Epoch 10/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.6951 - tp: 3.0000 - fp: 5.0000 - tn: 31.0000 - fn: 19.0000 - accuracy: 0.5862 - precision: 0.3750 - recall: 0.1364 - auc: 0.4463 - prc: 0.3494 - val_loss: 0.6639 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5926 - val_prc: 0.5852
</span></span><span class=line><span class=cl>    Epoch 11/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 204ms/step - loss: 0.6829 - tp: 7.0000 - fp: 10.0000 - tn: 26.0000 - fn: 15.0000 - accuracy: 0.5690 - precision: 0.4118 - recall: 0.3182 - auc: 0.4943 - prc: 0.4054 - val_loss: 0.8546 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6037 - val_prc: 0.5473
</span></span><span class=line><span class=cl>    Epoch 12/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.6517 - tp: 2.0000 - fp: 3.0000 - tn: 33.0000 - fn: 20.0000 - accuracy: 0.6034 - precision: 0.4000 - recall: 0.0909 - auc: 0.5909 - prc: 0.4719 - val_loss: 0.8066 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5667 - val_prc: 0.5399
</span></span><span class=line><span class=cl>    Epoch 13/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.6674 - tp: 4.0000 - fp: 3.0000 - tn: 33.0000 - fn: 18.0000 - accuracy: 0.6379 - precision: 0.5714 - recall: 0.1818 - auc: 0.5366 - prc: 0.4593 - val_loss: 0.7085 - val_tp: 7.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 2.0000 - val_accuracy: 0.3750 - val_precision: 0.3500 - val_recall: 0.7778 - val_auc: 0.5111 - val_prc: 0.4115
</span></span><span class=line><span class=cl>    Epoch 14/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.6801 - tp: 4.0000 - fp: 3.0000 - tn: 33.0000 - fn: 18.0000 - accuracy: 0.6379 - precision: 0.5714 - recall: 0.1818 - auc: 0.4747 - prc: 0.3952 - val_loss: 0.6619 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5481 - val_prc: 0.4855
</span></span><span class=line><span class=cl>    Epoch 15/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6520 - tp: 3.0000 - fp: 5.0000 - tn: 31.0000 - fn: 19.0000 - accuracy: 0.5862 - precision: 0.3750 - recall: 0.1364 - auc: 0.5846 - prc: 0.4373 - val_loss: 0.6975 - val_tp: 4.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 5.0000 - val_accuracy: 0.5000 - val_precision: 0.3636 - val_recall: 0.4444 - val_auc: 0.4741 - val_prc: 0.3648
</span></span><span class=line><span class=cl>    Epoch 16/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 208ms/step - loss: 0.6187 - tp: 4.0000 - fp: 2.0000 - tn: 34.0000 - fn: 18.0000 - accuracy: 0.6552 - precision: 0.6667 - recall: 0.1818 - auc: 0.6926 - prc: 0.5912 - val_loss: 0.7353 - val_tp: 7.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 2.0000 - val_accuracy: 0.3333 - val_precision: 0.3333 - val_recall: 0.7778 - val_auc: 0.4667 - val_prc: 0.3716
</span></span><span class=line><span class=cl>    Epoch 17/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 205ms/step - loss: 0.6701 - tp: 3.0000 - fp: 9.0000 - tn: 27.0000 - fn: 19.0000 - accuracy: 0.5172 - precision: 0.2500 - recall: 0.1364 - auc: 0.5297 - prc: 0.3845 - val_loss: 0.6876 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5519 - val_prc: 0.4178
</span></span><span class=line><span class=cl>    Epoch 18/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 205ms/step - loss: 0.6775 - tp: 6.0000 - fp: 7.0000 - tn: 29.0000 - fn: 16.0000 - accuracy: 0.6034 - precision: 0.4615 - recall: 0.2727 - auc: 0.5638 - prc: 0.4825 - val_loss: 0.6814 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.5481 - val_prc: 0.4884
</span></span><span class=line><span class=cl>    Epoch 19/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.6564 - tp: 7.0000 - fp: 6.0000 - tn: 30.0000 - fn: 15.0000 - accuracy: 0.6379 - precision: 0.5385 - recall: 0.3182 - auc: 0.5909 - prc: 0.4990 - val_loss: 0.7657 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5481 - val_prc: 0.4780
</span></span><span class=line><span class=cl>    Epoch 20/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.6924 - tp: 8.0000 - fp: 12.0000 - tn: 24.0000 - fn: 14.0000 - accuracy: 0.5517 - precision: 0.4000 - recall: 0.3636 - auc: 0.5259 - prc: 0.4359 - val_loss: 0.7146 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5593 - val_prc: 0.4812
</span></span><span class=line><span class=cl>    Epoch 21/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.6663 - tp: 2.0000 - fp: 3.0000 - tn: 33.0000 - fn: 20.0000 - accuracy: 0.6034 - precision: 0.4000 - recall: 0.0909 - auc: 0.5114 - prc: 0.4048 - val_loss: 0.6704 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.5370 - val_prc: 0.4039
</span></span><span class=line><span class=cl>    Epoch 22/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 179ms/step - loss: 0.6685 - tp: 3.0000 - fp: 5.0000 - tn: 31.0000 - fn: 19.0000 - accuracy: 0.5862 - precision: 0.3750 - recall: 0.1364 - auc: 0.5739 - prc: 0.4351 - val_loss: 0.7108 - val_tp: 5.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 4.0000 - val_accuracy: 0.4583 - val_precision: 0.3571 - val_recall: 0.5556 - val_auc: 0.5037 - val_prc: 0.3629
</span></span><span class=line><span class=cl>    Epoch 23/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.6624 - tp: 2.0000 - fp: 3.0000 - tn: 33.0000 - fn: 20.0000 - accuracy: 0.6034 - precision: 0.4000 - recall: 0.0909 - auc: 0.5404 - prc: 0.4075 - val_loss: 0.7205 - val_tp: 5.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 4.0000 - val_accuracy: 0.4167 - val_precision: 0.3333 - val_recall: 0.5556 - val_auc: 0.3963 - val_prc: 0.2977
</span></span><span class=line><span class=cl>    Epoch 24/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 204ms/step - loss: 0.6372 - tp: 3.0000 - fp: 7.0000 - tn: 29.0000 - fn: 19.0000 - accuracy: 0.5517 - precision: 0.3000 - recall: 0.1364 - auc: 0.6288 - prc: 0.5001 - val_loss: 0.8073 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6815 - val_prc: 0.6517
</span></span><span class=line><span class=cl>    Epoch 25/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6473 - tp: 9.0000 - fp: 6.0000 - tn: 30.0000 - fn: 13.0000 - accuracy: 0.6724 - precision: 0.6000 - recall: 0.4091 - auc: 0.6288 - prc: 0.5083 - val_loss: 0.7682 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6963 - val_prc: 0.6363
</span></span><span class=line><span class=cl>    Epoch 26/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 186ms/step - loss: 0.6004 - tp: 5.0000 - fp: 5.0000 - tn: 31.0000 - fn: 17.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2273 - auc: 0.7027 - prc: 0.5617 - val_loss: 0.7955 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.7296 - val_prc: 0.6976
</span></span><span class=line><span class=cl>    Epoch 27/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6501 - tp: 6.0000 - fp: 6.0000 - tn: 30.0000 - fn: 16.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2727 - auc: 0.6111 - prc: 0.4957 - val_loss: 1.1787 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.7259 - val_prc: 0.7172
</span></span><span class=line><span class=cl>    Epoch 28/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 186ms/step - loss: 0.6617 - tp: 3.0000 - fp: 5.0000 - tn: 31.0000 - fn: 19.0000 - accuracy: 0.5862 - precision: 0.3750 - recall: 0.1364 - auc: 0.6080 - prc: 0.4269 - val_loss: 0.8681 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.7889 - val_prc: 0.7475
</span></span><span class=line><span class=cl>    Epoch 29/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6911 - tp: 6.0000 - fp: 5.0000 - tn: 31.0000 - fn: 16.0000 - accuracy: 0.6379 - precision: 0.5455 - recall: 0.2727 - auc: 0.4918 - prc: 0.4204 - val_loss: 0.6744 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.7074 - val_prc: 0.6566
</span></span><span class=line><span class=cl>    Epoch 30/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.6421 - tp: 6.0000 - fp: 5.0000 - tn: 31.0000 - fn: 16.0000 - accuracy: 0.6379 - precision: 0.5455 - recall: 0.2727 - auc: 0.6263 - prc: 0.5563 - val_loss: 0.7569 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7148 - val_prc: 0.6154
</span></span><span class=line><span class=cl>    Epoch 31/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6879 - tp: 2.0000 - fp: 3.0000 - tn: 33.0000 - fn: 20.0000 - accuracy: 0.6034 - precision: 0.4000 - recall: 0.0909 - auc: 0.4729 - prc: 0.3863 - val_loss: 0.6015 - val_tp: 5.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 4.0000 - val_accuracy: 0.6667 - val_precision: 0.5556 - val_recall: 0.5556 - val_auc: 0.7185 - val_prc: 0.6091
</span></span><span class=line><span class=cl>    Epoch 32/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6516 - tp: 2.0000 - fp: 4.0000 - tn: 32.0000 - fn: 20.0000 - accuracy: 0.5862 - precision: 0.3333 - recall: 0.0909 - auc: 0.5884 - prc: 0.4562 - val_loss: 0.5953 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 8.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.1111 - val_auc: 0.7333 - val_prc: 0.6369
</span></span><span class=line><span class=cl>    Epoch 33/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.6394 - tp: 8.0000 - fp: 9.0000 - tn: 27.0000 - fn: 14.0000 - accuracy: 0.6034 - precision: 0.4706 - recall: 0.3636 - auc: 0.6187 - prc: 0.5052 - val_loss: 0.6376 - val_tp: 5.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 4.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.5556 - val_auc: 0.6926 - val_prc: 0.6676
</span></span><span class=line><span class=cl>    Epoch 34/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.7035 - tp: 6.0000 - fp: 13.0000 - tn: 23.0000 - fn: 16.0000 - accuracy: 0.5000 - precision: 0.3158 - recall: 0.2727 - auc: 0.5322 - prc: 0.3737 - val_loss: 0.6689 - val_tp: 5.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 4.0000 - val_accuracy: 0.5000 - val_precision: 0.3846 - val_recall: 0.5556 - val_auc: 0.6704 - val_prc: 0.6534
</span></span><span class=line><span class=cl>    Epoch 35/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 206ms/step - loss: 0.6712 - tp: 1.0000 - fp: 2.0000 - tn: 34.0000 - fn: 21.0000 - accuracy: 0.6034 - precision: 0.3333 - recall: 0.0455 - auc: 0.5840 - prc: 0.4860 - val_loss: 0.6611 - val_tp: 6.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 3.0000 - val_accuracy: 0.5833 - val_precision: 0.4615 - val_recall: 0.6667 - val_auc: 0.7074 - val_prc: 0.6201
</span></span><span class=line><span class=cl>    Epoch 36/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6275 - tp: 5.0000 - fp: 5.0000 - tn: 31.0000 - fn: 17.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2273 - auc: 0.6591 - prc: 0.4538 - val_loss: 0.6931 - val_tp: 8.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4167 - val_precision: 0.3810 - val_recall: 0.8889 - val_auc: 0.6963 - val_prc: 0.6599
</span></span><span class=line><span class=cl>    Epoch 37/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.6712 - tp: 6.0000 - fp: 5.0000 - tn: 31.0000 - fn: 16.0000 - accuracy: 0.6379 - precision: 0.5455 - recall: 0.2727 - auc: 0.5404 - prc: 0.4800 - val_loss: 0.6658 - val_tp: 7.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 2.0000 - val_accuracy: 0.5833 - val_precision: 0.4667 - val_recall: 0.7778 - val_auc: 0.7222 - val_prc: 0.6967
</span></span><span class=line><span class=cl>    Epoch 38/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6676 - tp: 4.0000 - fp: 5.0000 - tn: 31.0000 - fn: 18.0000 - accuracy: 0.6034 - precision: 0.4444 - recall: 0.1818 - auc: 0.5486 - prc: 0.4141 - val_loss: 0.6029 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 8.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.1111 - val_auc: 0.7000 - val_prc: 0.5160
</span></span><span class=line><span class=cl>    Epoch 39/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 186ms/step - loss: 0.6224 - tp: 4.0000 - fp: 2.0000 - tn: 34.0000 - fn: 18.0000 - accuracy: 0.6552 - precision: 0.6667 - recall: 0.1818 - auc: 0.6578 - prc: 0.6070 - val_loss: 0.6108 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.6704 - val_prc: 0.4683
</span></span><span class=line><span class=cl>    Epoch 40/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6676 - tp: 6.0000 - fp: 8.0000 - tn: 28.0000 - fn: 16.0000 - accuracy: 0.5862 - precision: 0.4286 - recall: 0.2727 - auc: 0.5726 - prc: 0.4630 - val_loss: 0.6539 - val_tp: 7.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.7778 - val_auc: 0.7185 - val_prc: 0.6816
</span></span><span class=line><span class=cl>    Epoch 41/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.7080 - tp: 1.0000 - fp: 3.0000 - tn: 33.0000 - fn: 21.0000 - accuracy: 0.5862 - precision: 0.2500 - recall: 0.0455 - auc: 0.4028 - prc: 0.3391 - val_loss: 0.6216 - val_tp: 4.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 5.0000 - val_accuracy: 0.5833 - val_precision: 0.4444 - val_recall: 0.4444 - val_auc: 0.7481 - val_prc: 0.7127
</span></span><span class=line><span class=cl>    Epoch 42/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6574 - tp: 4.0000 - fp: 5.0000 - tn: 31.0000 - fn: 18.0000 - accuracy: 0.6034 - precision: 0.4444 - recall: 0.1818 - auc: 0.6010 - prc: 0.4143 - val_loss: 0.6158 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7259 - val_prc: 0.6933
</span></span><span class=line><span class=cl>    Epoch 43/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6293 - tp: 5.0000 - fp: 3.0000 - tn: 33.0000 - fn: 17.0000 - accuracy: 0.6552 - precision: 0.6250 - recall: 0.2273 - auc: 0.6692 - prc: 0.5125 - val_loss: 0.6061 - val_tp: 5.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 4.0000 - val_accuracy: 0.6667 - val_precision: 0.5556 - val_recall: 0.5556 - val_auc: 0.7111 - val_prc: 0.4929
</span></span><span class=line><span class=cl>    Epoch 44/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.7083 - tp: 3.0000 - fp: 6.0000 - tn: 30.0000 - fn: 19.0000 - accuracy: 0.5690 - precision: 0.3333 - recall: 0.1364 - auc: 0.4476 - prc: 0.4012 - val_loss: 0.6599 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 8.0000 - val_accuracy: 0.5833 - val_precision: 0.3333 - val_recall: 0.1111 - val_auc: 0.6444 - val_prc: 0.4695
</span></span><span class=line><span class=cl>    Epoch 45/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 206ms/step - loss: 0.6447 - tp: 7.0000 - fp: 4.0000 - tn: 32.0000 - fn: 15.0000 - accuracy: 0.6724 - precision: 0.6364 - recall: 0.3182 - auc: 0.6111 - prc: 0.5782 - val_loss: 0.6556 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 8.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.1111 - val_auc: 0.6889 - val_prc: 0.4995
</span></span><span class=line><span class=cl>    Epoch 46/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.6695 - tp: 4.0000 - fp: 4.0000 - tn: 32.0000 - fn: 18.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.1818 - auc: 0.5234 - prc: 0.4325 - val_loss: 0.6279 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 8.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.1111 - val_auc: 0.6741 - val_prc: 0.4755
</span></span><span class=line><span class=cl>    Epoch 47/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.6543 - tp: 2.0000 - fp: 2.0000 - tn: 34.0000 - fn: 20.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.0909 - auc: 0.5726 - prc: 0.4613 - val_loss: 0.6232 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 6.0000 - val_accuracy: 0.6667 - val_precision: 0.6000 - val_recall: 0.3333 - val_auc: 0.6630 - val_prc: 0.5356
</span></span><span class=line><span class=cl>    Epoch 48/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.6752 - tp: 2.0000 - fp: 4.0000 - tn: 32.0000 - fn: 20.0000 - accuracy: 0.5862 - precision: 0.3333 - recall: 0.0909 - auc: 0.5069 - prc: 0.3705 - val_loss: 0.6255 - val_tp: 5.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 4.0000 - val_accuracy: 0.6667 - val_precision: 0.5556 - val_recall: 0.5556 - val_auc: 0.7259 - val_prc: 0.6719
</span></span><span class=line><span class=cl>    Epoch 49/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.6410 - tp: 6.0000 - fp: 3.0000 - tn: 33.0000 - fn: 16.0000 - accuracy: 0.6724 - precision: 0.6667 - recall: 0.2727 - auc: 0.6477 - prc: 0.5384 - val_loss: 0.7278 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.6259 - val_prc: 0.4578
</span></span><span class=line><span class=cl>    Epoch 50/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 205ms/step - loss: 0.6456 - tp: 5.0000 - fp: 5.0000 - tn: 31.0000 - fn: 17.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2273 - auc: 0.6073 - prc: 0.4832 - val_loss: 0.5857 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.7074 - val_prc: 0.6049
</span></span><span class=line><span class=cl>    Epoch 51/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 180ms/step - loss: 0.7014 - tp: 4.0000 - fp: 9.0000 - tn: 27.0000 - fn: 18.0000 - accuracy: 0.5345 - precision: 0.3077 - recall: 0.1818 - auc: 0.4905 - prc: 0.4029 - val_loss: 0.6040 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.6037 - val_prc: 0.4975
</span></span><span class=line><span class=cl>    Epoch 52/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.5984 - tp: 10.0000 - fp: 2.0000 - tn: 34.0000 - fn: 12.0000 - accuracy: 0.7586 - precision: 0.8333 - recall: 0.4545 - auc: 0.7367 - prc: 0.7033 - val_loss: 0.5748 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.7296 - val_prc: 0.5922
</span></span><span class=line><span class=cl>    Epoch 53/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.6348 - tp: 8.0000 - fp: 5.0000 - tn: 31.0000 - fn: 14.0000 - accuracy: 0.6724 - precision: 0.6154 - recall: 0.3636 - auc: 0.6402 - prc: 0.5631 - val_loss: 0.5882 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.7926 - val_prc: 0.7050
</span></span><span class=line><span class=cl>    Epoch 54/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6085 - tp: 5.0000 - fp: 4.0000 - tn: 32.0000 - fn: 17.0000 - accuracy: 0.6379 - precision: 0.5556 - recall: 0.2273 - auc: 0.7241 - prc: 0.5583 - val_loss: 0.5641 - val_tp: 4.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 5.0000 - val_accuracy: 0.7500 - val_precision: 0.8000 - val_recall: 0.4444 - val_auc: 0.7556 - val_prc: 0.7083
</span></span><span class=line><span class=cl>    Epoch 55/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 206ms/step - loss: 0.7480 - tp: 3.0000 - fp: 10.0000 - tn: 26.0000 - fn: 19.0000 - accuracy: 0.5000 - precision: 0.2308 - recall: 0.1364 - auc: 0.4116 - prc: 0.3103 - val_loss: 0.6614 - val_tp: 8.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 1.0000 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.8889 - val_auc: 0.7519 - val_prc: 0.6442
</span></span><span class=line><span class=cl>    Epoch 56/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6687 - tp: 2.0000 - fp: 7.0000 - tn: 29.0000 - fn: 20.0000 - accuracy: 0.5345 - precision: 0.2222 - recall: 0.0909 - auc: 0.5461 - prc: 0.3720 - val_loss: 0.6286 - val_tp: 2.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.5417 - val_precision: 0.3333 - val_recall: 0.2222 - val_auc: 0.6333 - val_prc: 0.5093
</span></span><span class=line><span class=cl>    Epoch 57/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.6409 - tp: 8.0000 - fp: 3.0000 - tn: 33.0000 - fn: 14.0000 - accuracy: 0.7069 - precision: 0.7273 - recall: 0.3636 - auc: 0.6439 - prc: 0.5363 - val_loss: 0.5970 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7111 - val_prc: 0.4876
</span></span><span class=line><span class=cl>    Epoch 58/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.5910 - tp: 10.0000 - fp: 4.0000 - tn: 32.0000 - fn: 12.0000 - accuracy: 0.7241 - precision: 0.7143 - recall: 0.4545 - auc: 0.7506 - prc: 0.6676 - val_loss: 0.5880 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 9.0000 - val_accuracy: 0.5833 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7222 - val_prc: 0.5002
</span></span><span class=line><span class=cl>    Epoch 59/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 204ms/step - loss: 0.6581 - tp: 9.0000 - fp: 5.0000 - tn: 31.0000 - fn: 13.0000 - accuracy: 0.6897 - precision: 0.6429 - recall: 0.4091 - auc: 0.5808 - prc: 0.5330 - val_loss: 0.7256 - val_tp: 8.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4167 - val_precision: 0.3810 - val_recall: 0.8889 - val_auc: 0.6407 - val_prc: 0.4802
</span></span><span class=line><span class=cl>    Epoch 60/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6269 - tp: 7.0000 - fp: 7.0000 - tn: 29.0000 - fn: 15.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.3182 - auc: 0.6566 - prc: 0.5440 - val_loss: 0.5785 - val_tp: 3.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.7083 - val_precision: 0.7500 - val_recall: 0.3333 - val_auc: 0.7444 - val_prc: 0.6829
</span></span><span class=line><span class=cl>    Epoch 61/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 207ms/step - loss: 0.5986 - tp: 7.0000 - fp: 3.0000 - tn: 33.0000 - fn: 15.0000 - accuracy: 0.6897 - precision: 0.7000 - recall: 0.3182 - auc: 0.7071 - prc: 0.6466 - val_loss: 0.5624 - val_tp: 5.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 4.0000 - val_accuracy: 0.7083 - val_precision: 0.6250 - val_recall: 0.5556 - val_auc: 0.7778 - val_prc: 0.7414
</span></span><span class=line><span class=cl>    Epoch 62/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6476 - tp: 8.0000 - fp: 4.0000 - tn: 32.0000 - fn: 14.0000 - accuracy: 0.6897 - precision: 0.6667 - recall: 0.3636 - auc: 0.6080 - prc: 0.5822 - val_loss: 0.6408 - val_tp: 8.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 1.0000 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.8889 - val_auc: 0.7519 - val_prc: 0.6329
</span></span><span class=line><span class=cl>    Epoch 63/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6191 - tp: 9.0000 - fp: 4.0000 - tn: 32.0000 - fn: 13.0000 - accuracy: 0.7069 - precision: 0.6923 - recall: 0.4091 - auc: 0.6736 - prc: 0.5997 - val_loss: 0.5931 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.7519 - val_prc: 0.6941
</span></span><span class=line><span class=cl>    Epoch 64/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.5364 - tp: 10.0000 - fp: 3.0000 - tn: 33.0000 - fn: 12.0000 - accuracy: 0.7414 - precision: 0.7692 - recall: 0.4545 - auc: 0.8125 - prc: 0.7487 - val_loss: 0.7057 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7370 - val_prc: 0.5976
</span></span><span class=line><span class=cl>    Epoch 65/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.6301 - tp: 5.0000 - fp: 3.0000 - tn: 33.0000 - fn: 17.0000 - accuracy: 0.6552 - precision: 0.6250 - recall: 0.2273 - auc: 0.6376 - prc: 0.5758 - val_loss: 0.5733 - val_tp: 7.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 2.0000 - val_accuracy: 0.7500 - val_precision: 0.6364 - val_recall: 0.7778 - val_auc: 0.7963 - val_prc: 0.7514
</span></span><span class=line><span class=cl>    Epoch 66/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6038 - tp: 8.0000 - fp: 7.0000 - tn: 29.0000 - fn: 14.0000 - accuracy: 0.6379 - precision: 0.5333 - recall: 0.3636 - auc: 0.7014 - prc: 0.5630 - val_loss: 0.6188 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.8074 - val_prc: 0.7480
</span></span><span class=line><span class=cl>    Epoch 67/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.5997 - tp: 7.0000 - fp: 5.0000 - tn: 31.0000 - fn: 15.0000 - accuracy: 0.6552 - precision: 0.5833 - recall: 0.3182 - auc: 0.6812 - prc: 0.5390 - val_loss: 0.5888 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.7185 - val_prc: 0.6326
</span></span><span class=line><span class=cl>    Epoch 68/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.5919 - tp: 9.0000 - fp: 7.0000 - tn: 29.0000 - fn: 13.0000 - accuracy: 0.6552 - precision: 0.5625 - recall: 0.4091 - auc: 0.7348 - prc: 0.6161 - val_loss: 0.7248 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.6630 - val_prc: 0.5743
</span></span><span class=line><span class=cl>    Epoch 69/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.6469 - tp: 11.0000 - fp: 11.0000 - tn: 25.0000 - fn: 11.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.5000 - auc: 0.6364 - prc: 0.5145 - val_loss: 0.8186 - val_tp: 8.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4211 - val_recall: 0.8889 - val_auc: 0.5963 - val_prc: 0.5537
</span></span><span class=line><span class=cl>    Epoch 70/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6409 - tp: 5.0000 - fp: 6.0000 - tn: 30.0000 - fn: 17.0000 - accuracy: 0.6034 - precision: 0.4545 - recall: 0.2273 - auc: 0.6231 - prc: 0.4339 - val_loss: 0.7859 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.5407 - val_prc: 0.5091
</span></span><span class=line><span class=cl>    Epoch 71/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 205ms/step - loss: 0.6128 - tp: 11.0000 - fp: 6.0000 - tn: 30.0000 - fn: 11.0000 - accuracy: 0.7069 - precision: 0.6471 - recall: 0.5000 - auc: 0.7083 - prc: 0.6678 - val_loss: 0.9675 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6259 - val_prc: 0.5440
</span></span><span class=line><span class=cl>    Epoch 72/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6540 - tp: 9.0000 - fp: 7.0000 - tn: 29.0000 - fn: 13.0000 - accuracy: 0.6552 - precision: 0.5625 - recall: 0.4091 - auc: 0.5694 - prc: 0.5458 - val_loss: 1.0076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7148 - val_prc: 0.5536
</span></span><span class=line><span class=cl>    Epoch 73/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.6401 - tp: 9.0000 - fp: 9.0000 - tn: 27.0000 - fn: 13.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.4091 - auc: 0.6414 - prc: 0.5230 - val_loss: 0.7720 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6852 - val_prc: 0.5312
</span></span><span class=line><span class=cl>    Epoch 74/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.6105 - tp: 6.0000 - fp: 4.0000 - tn: 32.0000 - fn: 16.0000 - accuracy: 0.6552 - precision: 0.6000 - recall: 0.2727 - auc: 0.6837 - prc: 0.5591 - val_loss: 0.6210 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7148 - val_prc: 0.5004
</span></span><span class=line><span class=cl>    Epoch 75/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6179 - tp: 9.0000 - fp: 7.0000 - tn: 29.0000 - fn: 13.0000 - accuracy: 0.6552 - precision: 0.5625 - recall: 0.4091 - auc: 0.6856 - prc: 0.5644 - val_loss: 0.9179 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7000 - val_prc: 0.5459
</span></span><span class=line><span class=cl>    Epoch 76/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 207ms/step - loss: 0.5325 - tp: 11.0000 - fp: 8.0000 - tn: 28.0000 - fn: 11.0000 - accuracy: 0.6724 - precision: 0.5789 - recall: 0.5000 - auc: 0.7942 - prc: 0.6587 - val_loss: 1.1924 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.5667 - val_prc: 0.5299
</span></span><span class=line><span class=cl>    Epoch 77/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.6737 - tp: 8.0000 - fp: 7.0000 - tn: 29.0000 - fn: 14.0000 - accuracy: 0.6379 - precision: 0.5333 - recall: 0.3636 - auc: 0.5972 - prc: 0.4402 - val_loss: 0.7186 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6148 - val_prc: 0.5530
</span></span><span class=line><span class=cl>    Epoch 78/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 207ms/step - loss: 0.6254 - tp: 6.0000 - fp: 4.0000 - tn: 32.0000 - fn: 16.0000 - accuracy: 0.6552 - precision: 0.6000 - recall: 0.2727 - auc: 0.6610 - prc: 0.5580 - val_loss: 0.7345 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.6259 - val_prc: 0.5359
</span></span><span class=line><span class=cl>    Epoch 79/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6034 - tp: 6.0000 - fp: 5.0000 - tn: 31.0000 - fn: 16.0000 - accuracy: 0.6379 - precision: 0.5455 - recall: 0.2727 - auc: 0.7083 - prc: 0.6006 - val_loss: 0.6372 - val_tp: 7.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 2.0000 - val_accuracy: 0.6667 - val_precision: 0.5385 - val_recall: 0.7778 - val_auc: 0.6444 - val_prc: 0.5230
</span></span><span class=line><span class=cl>    Epoch 80/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.5715 - tp: 12.0000 - fp: 4.0000 - tn: 32.0000 - fn: 10.0000 - accuracy: 0.7586 - precision: 0.7500 - recall: 0.5455 - auc: 0.7393 - prc: 0.6489 - val_loss: 1.0162 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5407 - val_prc: 0.4858
</span></span><span class=line><span class=cl>    Epoch 81/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.5576 - tp: 12.0000 - fp: 8.0000 - tn: 28.0000 - fn: 10.0000 - accuracy: 0.6897 - precision: 0.6000 - recall: 0.5455 - auc: 0.7727 - prc: 0.6753 - val_loss: 0.8449 - val_tp: 8.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 1.0000 - val_accuracy: 0.4583 - val_precision: 0.4000 - val_recall: 0.8889 - val_auc: 0.5296 - val_prc: 0.4704
</span></span><span class=line><span class=cl>    Epoch 82/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 186ms/step - loss: 0.6260 - tp: 7.0000 - fp: 9.0000 - tn: 27.0000 - fn: 15.0000 - accuracy: 0.5862 - precision: 0.4375 - recall: 0.3182 - auc: 0.6705 - prc: 0.5344 - val_loss: 0.7249 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7333 - val_prc: 0.6488
</span></span><span class=line><span class=cl>    Epoch 83/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.6625 - tp: 9.0000 - fp: 7.0000 - tn: 29.0000 - fn: 13.0000 - accuracy: 0.6552 - precision: 0.5625 - recall: 0.4091 - auc: 0.5934 - prc: 0.5237 - val_loss: 0.6239 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6815 - val_prc: 0.4929
</span></span><span class=line><span class=cl>    Epoch 84/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 207ms/step - loss: 0.6588 - tp: 7.0000 - fp: 8.0000 - tn: 28.0000 - fn: 15.0000 - accuracy: 0.6034 - precision: 0.4667 - recall: 0.3182 - auc: 0.6136 - prc: 0.4304 - val_loss: 0.5812 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.6889 - val_prc: 0.5560
</span></span><span class=line><span class=cl>    Epoch 85/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.5769 - tp: 7.0000 - fp: 4.0000 - tn: 32.0000 - fn: 15.0000 - accuracy: 0.6724 - precision: 0.6364 - recall: 0.3182 - auc: 0.7923 - prc: 0.6225 - val_loss: 0.6539 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7815 - val_prc: 0.6941
</span></span><span class=line><span class=cl>    Epoch 86/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.6371 - tp: 10.0000 - fp: 8.0000 - tn: 28.0000 - fn: 12.0000 - accuracy: 0.6552 - precision: 0.5556 - recall: 0.4545 - auc: 0.6553 - prc: 0.4990 - val_loss: 0.5598 - val_tp: 5.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 4.0000 - val_accuracy: 0.5833 - val_precision: 0.4545 - val_recall: 0.5556 - val_auc: 0.7111 - val_prc: 0.6067
</span></span><span class=line><span class=cl>    Epoch 87/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.6124 - tp: 11.0000 - fp: 8.0000 - tn: 28.0000 - fn: 11.0000 - accuracy: 0.6724 - precision: 0.5789 - recall: 0.5000 - auc: 0.7071 - prc: 0.5848 - val_loss: 0.7889 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.6926 - val_prc: 0.5178
</span></span><span class=line><span class=cl>    Epoch 88/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.5571 - tp: 13.0000 - fp: 7.0000 - tn: 29.0000 - fn: 9.0000 - accuracy: 0.7241 - precision: 0.6500 - recall: 0.5909 - auc: 0.7588 - prc: 0.6341 - val_loss: 0.9594 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.6667 - val_prc: 0.5001
</span></span><span class=line><span class=cl>    Epoch 89/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 206ms/step - loss: 0.5916 - tp: 11.0000 - fp: 10.0000 - tn: 26.0000 - fn: 11.0000 - accuracy: 0.6379 - precision: 0.5238 - recall: 0.5000 - auc: 0.7083 - prc: 0.6126 - val_loss: 0.6811 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7481 - val_prc: 0.7207
</span></span><span class=line><span class=cl>    Epoch 90/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.5792 - tp: 13.0000 - fp: 7.0000 - tn: 29.0000 - fn: 9.0000 - accuracy: 0.7241 - precision: 0.6500 - recall: 0.5909 - auc: 0.7468 - prc: 0.6888 - val_loss: 0.5624 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.7407 - val_prc: 0.6354
</span></span><span class=line><span class=cl>    Epoch 91/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.6174 - tp: 8.0000 - fp: 7.0000 - tn: 29.0000 - fn: 14.0000 - accuracy: 0.6379 - precision: 0.5333 - recall: 0.3636 - auc: 0.6679 - prc: 0.5753 - val_loss: 0.6009 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7741 - val_prc: 0.6963
</span></span><span class=line><span class=cl>    Epoch 92/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.6138 - tp: 8.0000 - fp: 7.0000 - tn: 29.0000 - fn: 14.0000 - accuracy: 0.6379 - precision: 0.5333 - recall: 0.3636 - auc: 0.6774 - prc: 0.5170 - val_loss: 0.5624 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.7148 - val_prc: 0.6135
</span></span><span class=line><span class=cl>    Epoch 93/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.6290 - tp: 13.0000 - fp: 9.0000 - tn: 27.0000 - fn: 9.0000 - accuracy: 0.6897 - precision: 0.5909 - recall: 0.5909 - auc: 0.6806 - prc: 0.5072 - val_loss: 0.5822 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.7074 - val_prc: 0.5435
</span></span><span class=line><span class=cl>    Epoch 94/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 206ms/step - loss: 0.6012 - tp: 10.0000 - fp: 5.0000 - tn: 31.0000 - fn: 12.0000 - accuracy: 0.7069 - precision: 0.6667 - recall: 0.4545 - auc: 0.7115 - prc: 0.5411 - val_loss: 0.5738 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.7296 - val_prc: 0.6240
</span></span><span class=line><span class=cl>    Epoch 95/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.6244 - tp: 8.0000 - fp: 9.0000 - tn: 27.0000 - fn: 14.0000 - accuracy: 0.6034 - precision: 0.4706 - recall: 0.3636 - auc: 0.6742 - prc: 0.5485 - val_loss: 0.5757 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.7111 - val_prc: 0.5901
</span></span><span class=line><span class=cl>    Epoch 96/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.6106 - tp: 6.0000 - fp: 3.0000 - tn: 33.0000 - fn: 16.0000 - accuracy: 0.6724 - precision: 0.6667 - recall: 0.2727 - auc: 0.7033 - prc: 0.6131 - val_loss: 0.5921 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.6519 - val_prc: 0.5283
</span></span><span class=line><span class=cl>    Epoch 97/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 187ms/step - loss: 0.6145 - tp: 9.0000 - fp: 7.0000 - tn: 29.0000 - fn: 13.0000 - accuracy: 0.6552 - precision: 0.5625 - recall: 0.4091 - auc: 0.6806 - prc: 0.5688 - val_loss: 0.6388 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 6.0000 - val_accuracy: 0.5833 - val_precision: 0.4286 - val_recall: 0.3333 - val_auc: 0.5630 - val_prc: 0.4780
</span></span><span class=line><span class=cl>    Epoch 98/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.6289 - tp: 5.0000 - fp: 8.0000 - tn: 28.0000 - fn: 17.0000 - accuracy: 0.5690 - precision: 0.3846 - recall: 0.2273 - auc: 0.6244 - prc: 0.4785 - val_loss: 0.7110 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6556 - val_prc: 0.6244
</span></span><span class=line><span class=cl>    Epoch 99/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 207ms/step - loss: 0.5653 - tp: 9.0000 - fp: 2.0000 - tn: 34.0000 - fn: 13.0000 - accuracy: 0.7414 - precision: 0.8182 - recall: 0.4091 - auc: 0.7765 - prc: 0.7518 - val_loss: 0.5964 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.6704 - val_prc: 0.5604
</span></span><span class=line><span class=cl>    Epoch 100/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.6159 - tp: 7.0000 - fp: 6.0000 - tn: 30.0000 - fn: 15.0000 - accuracy: 0.6379 - precision: 0.5385 - recall: 0.3182 - auc: 0.6856 - prc: 0.4980 - val_loss: 0.5476 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 6.0000 - val_accuracy: 0.6667 - val_precision: 0.6000 - val_recall: 0.3333 - val_auc: 0.7778 - val_prc: 0.7039
</span></span><span class=line><span class=cl>    Epoch 101/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.5697 - tp: 9.0000 - fp: 4.0000 - tn: 32.0000 - fn: 13.0000 - accuracy: 0.7069 - precision: 0.6923 - recall: 0.4091 - auc: 0.7494 - prc: 0.6223 - val_loss: 0.5477 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.7926 - val_prc: 0.6801
</span></span><span class=line><span class=cl>    Epoch 102/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.6199 - tp: 7.0000 - fp: 7.0000 - tn: 29.0000 - fn: 15.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.3182 - auc: 0.6660 - prc: 0.4526 - val_loss: 0.6044 - val_tp: 9.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6667 - val_precision: 0.5294 - val_recall: 1.0000 - val_auc: 0.6667 - val_prc: 0.5210
</span></span><span class=line><span class=cl>    Epoch 103/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.5188 - tp: 13.0000 - fp: 1.0000 - tn: 35.0000 - fn: 9.0000 - accuracy: 0.8276 - precision: 0.9286 - recall: 0.5909 - auc: 0.8365 - prc: 0.8287 - val_loss: 0.5609 - val_tp: 7.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 2.0000 - val_accuracy: 0.6667 - val_precision: 0.5385 - val_recall: 0.7778 - val_auc: 0.7481 - val_prc: 0.5854
</span></span><span class=line><span class=cl>    Epoch 104/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 207ms/step - loss: 0.5498 - tp: 10.0000 - fp: 6.0000 - tn: 30.0000 - fn: 12.0000 - accuracy: 0.6897 - precision: 0.6250 - recall: 0.4545 - auc: 0.7803 - prc: 0.6850 - val_loss: 0.5660 - val_tp: 7.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 2.0000 - val_accuracy: 0.6667 - val_precision: 0.5385 - val_recall: 0.7778 - val_auc: 0.7370 - val_prc: 0.5807
</span></span><span class=line><span class=cl>    Epoch 105/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.6338 - tp: 8.0000 - fp: 7.0000 - tn: 29.0000 - fn: 14.0000 - accuracy: 0.6379 - precision: 0.5333 - recall: 0.3636 - auc: 0.6313 - prc: 0.5414 - val_loss: 0.6451 - val_tp: 8.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.5417 - val_precision: 0.4444 - val_recall: 0.8889 - val_auc: 0.6778 - val_prc: 0.5501
</span></span><span class=line><span class=cl>    Epoch 106/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.5249 - tp: 12.0000 - fp: 6.0000 - tn: 30.0000 - fn: 10.0000 - accuracy: 0.7241 - precision: 0.6667 - recall: 0.5455 - auc: 0.8138 - prc: 0.7819 - val_loss: 0.5430 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.6852 - val_prc: 0.5312
</span></span><span class=line><span class=cl>    Epoch 107/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 186ms/step - loss: 0.5815 - tp: 15.0000 - fp: 10.0000 - tn: 26.0000 - fn: 7.0000 - accuracy: 0.7069 - precision: 0.6000 - recall: 0.6818 - auc: 0.7216 - prc: 0.5448 - val_loss: 0.8003 - val_tp: 8.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.5417 - val_precision: 0.4444 - val_recall: 0.8889 - val_auc: 0.6222 - val_prc: 0.5369
</span></span><span class=line><span class=cl>    Epoch 108/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.5578 - tp: 12.0000 - fp: 6.0000 - tn: 30.0000 - fn: 10.0000 - accuracy: 0.7241 - precision: 0.6667 - recall: 0.5455 - auc: 0.7620 - prc: 0.6217 - val_loss: 0.8668 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7333 - val_prc: 0.5797
</span></span><span class=line><span class=cl>    Epoch 109/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 208ms/step - loss: 0.5450 - tp: 14.0000 - fp: 6.0000 - tn: 30.0000 - fn: 8.0000 - accuracy: 0.7586 - precision: 0.7000 - recall: 0.6364 - auc: 0.7847 - prc: 0.7347 - val_loss: 0.5321 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.7630 - val_prc: 0.5972
</span></span><span class=line><span class=cl>    Epoch 110/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.5715 - tp: 14.0000 - fp: 7.0000 - tn: 29.0000 - fn: 8.0000 - accuracy: 0.7414 - precision: 0.6667 - recall: 0.6364 - auc: 0.7582 - prc: 0.6544 - val_loss: 0.5747 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.7148 - val_prc: 0.5994
</span></span><span class=line><span class=cl>    Epoch 111/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 186ms/step - loss: 0.5356 - tp: 14.0000 - fp: 5.0000 - tn: 31.0000 - fn: 8.0000 - accuracy: 0.7759 - precision: 0.7368 - recall: 0.6364 - auc: 0.8087 - prc: 0.7395 - val_loss: 0.5713 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.7037 - val_prc: 0.6061
</span></span><span class=line><span class=cl>    Epoch 112/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.5344 - tp: 11.0000 - fp: 4.0000 - tn: 32.0000 - fn: 11.0000 - accuracy: 0.7414 - precision: 0.7333 - recall: 0.5000 - auc: 0.7923 - prc: 0.7589 - val_loss: 0.5548 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 6.0000 - val_accuracy: 0.6667 - val_precision: 0.6000 - val_recall: 0.3333 - val_auc: 0.7148 - val_prc: 0.5722
</span></span><span class=line><span class=cl>    Epoch 113/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 186ms/step - loss: 0.4920 - tp: 16.0000 - fp: 6.0000 - tn: 30.0000 - fn: 6.0000 - accuracy: 0.7931 - precision: 0.7273 - recall: 0.7273 - auc: 0.8586 - prc: 0.8224 - val_loss: 0.5397 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.7370 - val_prc: 0.5998
</span></span><span class=line><span class=cl>    Epoch 114/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.6154 - tp: 8.0000 - fp: 5.0000 - tn: 31.0000 - fn: 14.0000 - accuracy: 0.6724 - precision: 0.6154 - recall: 0.3636 - auc: 0.6888 - prc: 0.5479 - val_loss: 0.9068 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.6407 - val_prc: 0.5192
</span></span><span class=line><span class=cl>    Epoch 115/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 207ms/step - loss: 0.5012 - tp: 14.0000 - fp: 5.0000 - tn: 31.0000 - fn: 8.0000 - accuracy: 0.7759 - precision: 0.7368 - recall: 0.6364 - auc: 0.8750 - prc: 0.8653 - val_loss: 0.7173 - val_tp: 8.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.5417 - val_precision: 0.4444 - val_recall: 0.8889 - val_auc: 0.6741 - val_prc: 0.5405
</span></span><span class=line><span class=cl>    Epoch 116/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 207ms/step - loss: 0.5362 - tp: 13.0000 - fp: 5.0000 - tn: 31.0000 - fn: 9.0000 - accuracy: 0.7586 - precision: 0.7222 - recall: 0.5909 - auc: 0.7746 - prc: 0.7763 - val_loss: 0.6689 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.6889 - val_prc: 0.5579
</span></span><span class=line><span class=cl>    Epoch 117/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 206ms/step - loss: 0.5471 - tp: 14.0000 - fp: 7.0000 - tn: 29.0000 - fn: 8.0000 - accuracy: 0.7414 - precision: 0.6667 - recall: 0.6364 - auc: 0.7929 - prc: 0.6062 - val_loss: 0.9950 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6704 - val_prc: 0.5921
</span></span><span class=line><span class=cl>    Epoch 118/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.5357 - tp: 13.0000 - fp: 8.0000 - tn: 28.0000 - fn: 9.0000 - accuracy: 0.7069 - precision: 0.6190 - recall: 0.5909 - auc: 0.8087 - prc: 0.7147 - val_loss: 0.6493 - val_tp: 9.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6667 - val_precision: 0.5294 - val_recall: 1.0000 - val_auc: 0.6963 - val_prc: 0.5473
</span></span><span class=line><span class=cl>    Epoch 119/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.4701 - tp: 15.0000 - fp: 5.0000 - tn: 31.0000 - fn: 7.0000 - accuracy: 0.7931 - precision: 0.7500 - recall: 0.6818 - auc: 0.8725 - prc: 0.8120 - val_loss: 0.5653 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.7407 - val_prc: 0.6079
</span></span><span class=line><span class=cl>    Epoch 120/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.5085 - tp: 15.0000 - fp: 9.0000 - tn: 27.0000 - fn: 7.0000 - accuracy: 0.7241 - precision: 0.6250 - recall: 0.6818 - auc: 0.8277 - prc: 0.8029 - val_loss: 0.7471 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7259 - val_prc: 0.6723
</span></span><span class=line><span class=cl>    Epoch 121/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.4898 - tp: 16.0000 - fp: 4.0000 - tn: 32.0000 - fn: 6.0000 - accuracy: 0.8276 - precision: 0.8000 - recall: 0.7273 - auc: 0.8371 - prc: 0.7237 - val_loss: 0.6696 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7333 - val_prc: 0.6027
</span></span><span class=line><span class=cl>    Epoch 122/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.5793 - tp: 12.0000 - fp: 9.0000 - tn: 27.0000 - fn: 10.0000 - accuracy: 0.6724 - precision: 0.5714 - recall: 0.5455 - auc: 0.7330 - prc: 0.5865 - val_loss: 0.5316 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.7519 - val_prc: 0.6179
</span></span><span class=line><span class=cl>    Epoch 123/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 208ms/step - loss: 0.5606 - tp: 11.0000 - fp: 5.0000 - tn: 31.0000 - fn: 11.0000 - accuracy: 0.7241 - precision: 0.6875 - recall: 0.5000 - auc: 0.7481 - prc: 0.6783 - val_loss: 0.5416 - val_tp: 7.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.7778 - val_auc: 0.7667 - val_prc: 0.6311
</span></span><span class=line><span class=cl>    Epoch 124/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.5782 - tp: 11.0000 - fp: 8.0000 - tn: 28.0000 - fn: 11.0000 - accuracy: 0.6724 - precision: 0.5789 - recall: 0.5000 - auc: 0.7424 - prc: 0.6540 - val_loss: 0.5523 - val_tp: 4.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 5.0000 - val_accuracy: 0.5833 - val_precision: 0.4444 - val_recall: 0.4444 - val_auc: 0.6963 - val_prc: 0.5483
</span></span><span class=line><span class=cl>    Epoch 125/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 187ms/step - loss: 0.5540 - tp: 15.0000 - fp: 5.0000 - tn: 31.0000 - fn: 7.0000 - accuracy: 0.7931 - precision: 0.7500 - recall: 0.6818 - auc: 0.7664 - prc: 0.6315 - val_loss: 0.6888 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.7185 - val_prc: 0.6165
</span></span><span class=line><span class=cl>    Epoch 126/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 186ms/step - loss: 0.4999 - tp: 16.0000 - fp: 5.0000 - tn: 31.0000 - fn: 6.0000 - accuracy: 0.8103 - precision: 0.7619 - recall: 0.7273 - auc: 0.8359 - prc: 0.8347 - val_loss: 0.6917 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7370 - val_prc: 0.6028
</span></span><span class=line><span class=cl>    Epoch 127/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.5091 - tp: 14.0000 - fp: 8.0000 - tn: 28.0000 - fn: 8.0000 - accuracy: 0.7241 - precision: 0.6364 - recall: 0.6364 - auc: 0.8182 - prc: 0.7421 - val_loss: 0.5726 - val_tp: 7.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.7778 - val_auc: 0.7630 - val_prc: 0.6269
</span></span><span class=line><span class=cl>    Epoch 128/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 186ms/step - loss: 0.5261 - tp: 12.0000 - fp: 8.0000 - tn: 28.0000 - fn: 10.0000 - accuracy: 0.6897 - precision: 0.6000 - recall: 0.5455 - auc: 0.8011 - prc: 0.6893 - val_loss: 0.5381 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.7407 - val_prc: 0.5803
</span></span><span class=line><span class=cl>    Epoch 129/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.5419 - tp: 10.0000 - fp: 6.0000 - tn: 30.0000 - fn: 12.0000 - accuracy: 0.6897 - precision: 0.6250 - recall: 0.4545 - auc: 0.7866 - prc: 0.7089 - val_loss: 0.6339 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.7148 - val_prc: 0.5883
</span></span><span class=line><span class=cl>    Epoch 130/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 189ms/step - loss: 0.5201 - tp: 14.0000 - fp: 6.0000 - tn: 30.0000 - fn: 8.0000 - accuracy: 0.7586 - precision: 0.7000 - recall: 0.6364 - auc: 0.8150 - prc: 0.7406 - val_loss: 0.7827 - val_tp: 8.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.5417 - val_precision: 0.4444 - val_recall: 0.8889 - val_auc: 0.6963 - val_prc: 0.5670
</span></span><span class=line><span class=cl>    Epoch 131/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.5769 - tp: 10.0000 - fp: 8.0000 - tn: 28.0000 - fn: 12.0000 - accuracy: 0.6552 - precision: 0.5556 - recall: 0.4545 - auc: 0.7393 - prc: 0.5730 - val_loss: 0.7029 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7556 - val_prc: 0.5191
</span></span><span class=line><span class=cl>    Epoch 132/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 211ms/step - loss: 0.4640 - tp: 16.0000 - fp: 6.0000 - tn: 30.0000 - fn: 6.0000 - accuracy: 0.7931 - precision: 0.7273 - recall: 0.7273 - auc: 0.8592 - prc: 0.7727 - val_loss: 0.6821 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7296 - val_prc: 0.5268
</span></span><span class=line><span class=cl>    Epoch 133/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.4724 - tp: 15.0000 - fp: 4.0000 - tn: 32.0000 - fn: 7.0000 - accuracy: 0.8103 - precision: 0.7895 - recall: 0.6818 - auc: 0.8567 - prc: 0.8352 - val_loss: 0.9136 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6778 - val_prc: 0.5550
</span></span><span class=line><span class=cl>    Epoch 134/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 206ms/step - loss: 0.4977 - tp: 12.0000 - fp: 4.0000 - tn: 32.0000 - fn: 10.0000 - accuracy: 0.7586 - precision: 0.7500 - recall: 0.5455 - auc: 0.8232 - prc: 0.7806 - val_loss: 0.7380 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.6444 - val_prc: 0.4939
</span></span><span class=line><span class=cl>    Epoch 135/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.4914 - tp: 13.0000 - fp: 5.0000 - tn: 31.0000 - fn: 9.0000 - accuracy: 0.7586 - precision: 0.7222 - recall: 0.5909 - auc: 0.8295 - prc: 0.8147 - val_loss: 0.7016 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.6741 - val_prc: 0.4743
</span></span><span class=line><span class=cl>    Epoch 136/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.4006 - tp: 18.0000 - fp: 6.0000 - tn: 30.0000 - fn: 4.0000 - accuracy: 0.8276 - precision: 0.7500 - recall: 0.8182 - auc: 0.9160 - prc: 0.8728 - val_loss: 0.8513 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 2.0000 - val_accuracy: 0.5417 - val_precision: 0.4375 - val_recall: 0.7778 - val_auc: 0.6704 - val_prc: 0.4851
</span></span><span class=line><span class=cl>    Epoch 137/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 185ms/step - loss: 0.4486 - tp: 14.0000 - fp: 5.0000 - tn: 31.0000 - fn: 8.0000 - accuracy: 0.7759 - precision: 0.7368 - recall: 0.6364 - auc: 0.8586 - prc: 0.8096 - val_loss: 0.9344 - val_tp: 6.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 3.0000 - val_accuracy: 0.4583 - val_precision: 0.3750 - val_recall: 0.6667 - val_auc: 0.5889 - val_prc: 0.4850
</span></span><span class=line><span class=cl>    Epoch 138/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.5557 - tp: 13.0000 - fp: 7.0000 - tn: 29.0000 - fn: 9.0000 - accuracy: 0.7241 - precision: 0.6500 - recall: 0.5909 - auc: 0.7740 - prc: 0.7189 - val_loss: 0.7317 - val_tp: 6.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 3.0000 - val_accuracy: 0.5000 - val_precision: 0.4000 - val_recall: 0.6667 - val_auc: 0.6185 - val_prc: 0.5282
</span></span><span class=line><span class=cl>    Epoch 139/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 208ms/step - loss: 0.5169 - tp: 12.0000 - fp: 5.0000 - tn: 31.0000 - fn: 10.0000 - accuracy: 0.7414 - precision: 0.7059 - recall: 0.5455 - auc: 0.7955 - prc: 0.7069 - val_loss: 0.5705 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 6.0000 - val_accuracy: 0.5833 - val_precision: 0.4286 - val_recall: 0.3333 - val_auc: 0.7296 - val_prc: 0.6653
</span></span><span class=line><span class=cl>    Epoch 140/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.4208 - tp: 16.0000 - fp: 4.0000 - tn: 32.0000 - fn: 6.0000 - accuracy: 0.8276 - precision: 0.8000 - recall: 0.7273 - auc: 0.8902 - prc: 0.8377 - val_loss: 0.7661 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.7111 - val_prc: 0.6723
</span></span><span class=line><span class=cl>    Epoch 141/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.4170 - tp: 17.0000 - fp: 6.0000 - tn: 30.0000 - fn: 5.0000 - accuracy: 0.8103 - precision: 0.7391 - recall: 0.7727 - auc: 0.8996 - prc: 0.8173 - val_loss: 1.0633 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.6667 - val_prc: 0.4958
</span></span><span class=line><span class=cl>    Epoch 142/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 186ms/step - loss: 0.4598 - tp: 13.0000 - fp: 4.0000 - tn: 32.0000 - fn: 9.0000 - accuracy: 0.7759 - precision: 0.7647 - recall: 0.5909 - auc: 0.8504 - prc: 0.8274 - val_loss: 0.9489 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6185 - val_prc: 0.4544
</span></span><span class=line><span class=cl>    Epoch 143/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 183ms/step - loss: 0.4329 - tp: 16.0000 - fp: 6.0000 - tn: 30.0000 - fn: 6.0000 - accuracy: 0.7931 - precision: 0.7273 - recall: 0.7273 - auc: 0.8782 - prc: 0.8446 - val_loss: 0.9654 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.6778 - val_prc: 0.5528
</span></span><span class=line><span class=cl>    Epoch 144/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 200ms/step - loss: 0.4520 - tp: 16.0000 - fp: 4.0000 - tn: 32.0000 - fn: 6.0000 - accuracy: 0.8276 - precision: 0.8000 - recall: 0.7273 - auc: 0.8611 - prc: 0.7639 - val_loss: 1.3029 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.6185 - val_prc: 0.5865
</span></span><span class=line><span class=cl>    Epoch 145/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 198ms/step - loss: 0.4697 - tp: 18.0000 - fp: 9.0000 - tn: 27.0000 - fn: 4.0000 - accuracy: 0.7759 - precision: 0.6667 - recall: 0.8182 - auc: 0.8409 - prc: 0.7420 - val_loss: 0.8416 - val_tp: 8.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4211 - val_recall: 0.8889 - val_auc: 0.6000 - val_prc: 0.5343
</span></span><span class=line><span class=cl>    Epoch 146/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 6s 216ms/step - loss: 0.4762 - tp: 13.0000 - fp: 4.0000 - tn: 32.0000 - fn: 9.0000 - accuracy: 0.7759 - precision: 0.7647 - recall: 0.5909 - auc: 0.8396 - prc: 0.7806 - val_loss: 0.7761 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.6889 - val_prc: 0.5789
</span></span><span class=line><span class=cl>    Epoch 147/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.3946 - tp: 16.0000 - fp: 3.0000 - tn: 33.0000 - fn: 6.0000 - accuracy: 0.8448 - precision: 0.8421 - recall: 0.7273 - auc: 0.9091 - prc: 0.8527 - val_loss: 0.5931 - val_tp: 6.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.6667 - val_auc: 0.7111 - val_prc: 0.5656
</span></span><span class=line><span class=cl>    Epoch 148/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 182ms/step - loss: 0.4193 - tp: 18.0000 - fp: 3.0000 - tn: 33.0000 - fn: 4.0000 - accuracy: 0.8793 - precision: 0.8571 - recall: 0.8182 - auc: 0.9003 - prc: 0.9016 - val_loss: 0.6307 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 5.0000 - val_accuracy: 0.6667 - val_precision: 0.5714 - val_recall: 0.4444 - val_auc: 0.6815 - val_prc: 0.6220
</span></span><span class=line><span class=cl>    Epoch 149/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 181ms/step - loss: 0.5422 - tp: 14.0000 - fp: 9.0000 - tn: 27.0000 - fn: 8.0000 - accuracy: 0.7069 - precision: 0.6087 - recall: 0.6364 - auc: 0.7734 - prc: 0.7439 - val_loss: 0.6075 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6778 - val_prc: 0.4324
</span></span><span class=line><span class=cl>    Epoch 150/150
</span></span><span class=line><span class=cl>    29/29 [==============================] - 5s 184ms/step - loss: 0.4843 - tp: 13.0000 - fp: 4.0000 - tn: 32.0000 - fn: 9.0000 - accuracy: 0.7759 - precision: 0.7647 - recall: 0.5909 - auc: 0.8308 - prc: 0.7820 - val_loss: 0.7802 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.7185 - val_prc: 0.6671
</span></span></code></pre></div></div><h2 id=performance-evaluation>Performance evaluation</h2><p>Once the training is completed, the model performance can be plotted. Since the validation set is unbalanced, as already specified, the ROC AUC is used to provide a representation of the model&rsquo;s performance.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>20</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>ax</span> <span class=o>=</span> <span class=n>ax</span><span class=o>.</span><span class=n>ravel</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>metric</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>([</span><span class=s2>&#34;auc&#34;</span><span class=p>,</span> <span class=s2>&#34;val_auc&#34;</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>label</span><span class=p>,</span> <span class=n>history</span> <span class=ow>in</span> <span class=n>performance</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=n>metric</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s2>&#34;Model </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>metric</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s2>&#34;epochs&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=n>metric</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylim</span><span class=p>([</span><span class=mf>0.2</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>(</span><span class=n>performance</span><span class=o>.</span><span class=n>keys</span><span class=p>())</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_88_0_hu16f3f076f57d40a685396504a44d4f91_212619_7fc740f4e4be3a7b85746f9b9a43e89c.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_88_0_hu16f3f076f57d40a685396504a44d4f91_212619_b8e5a4b358dcad1685b63f51d6bf2a59.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_88_0_hu16f3f076f57d40a685396504a44d4f91_212619_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_88_0_hu16f3f076f57d40a685396504a44d4f91_212619_7fc740f4e4be3a7b85746f9b9a43e89c.webp width=760 height=220 loading=lazy data-zoomable></div></div></figure></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>20</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>ax</span> <span class=o>=</span> <span class=n>ax</span><span class=o>.</span><span class=n>ravel</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>metric</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>([</span><span class=s2>&#34;loss&#34;</span><span class=p>,</span> <span class=s2>&#34;val_loss&#34;</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>label</span><span class=p>,</span> <span class=n>history</span> <span class=ow>in</span> <span class=n>performance</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=n>metric</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s2>&#34;Model </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>metric</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>set_xlabel</span><span class=p>(</span><span class=s2>&#34;epochs&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>set_ylabel</span><span class=p>(</span><span class=n>metric</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>legend</span><span class=p>(</span><span class=n>performance</span><span class=o>.</span><span class=n>keys</span><span class=p>())</span>
</span></span></code></pre></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt=png srcset="/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_89_0_hu57839307438c9e5612cb6a4f785a90df_220283_db09dbdeec224cef75b871fd263271ec.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_89_0_hu57839307438c9e5612cb6a4f785a90df_220283_c1f88533282770954ddef347df459a74.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_89_0_hu57839307438c9e5612cb6a4f785a90df_220283_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_89_0_hu57839307438c9e5612cb6a4f785a90df_220283_db09dbdeec224cef75b871fd263271ec.webp width=760 height=220 loading=lazy data-zoomable></div></div></figure></p><h2 id=references>References</h2><ul><li><a href=https://keras.io/examples/vision/3D_image_classification/ target=_blank rel=noopener>3D image classification from CT scans</a></li><li><a href=https://vincentblog.xyz/posts/medical-images-in-python-computed-tomography target=_blank rel=noopener>Medical Images In python (Computed Tomography)</a></li><li><a href=https://www.imaios.com/en/resources/blog/ai-for-medical-imaging-data-augmentation target=_blank rel=noopener>Data augmentation for medical image analysis in deep learning</a></li></ul></div><div class=article-tags><a class="badge badge-light" href=/tag/image-processing/>Image Processing</a>
<a class="badge badge-light" href=/tag/deep-learning/>Deep Learning</a>
<a class="badge badge-light" href=/tag/medical/>Medical</a>
<a class="badge badge-light" href=/tag/dicom/>DICOM</a>
<a class="badge badge-light" href=/tag/python/>Python</a></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fwww.peco602.com%2Fpost%2F0100-brain-stroke-detection-3d-cnn%2F&amp;text=Brain+stroke+detection+from+CT+scans+via+3D+Convolutional+Neural+Network" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fwww.peco602.com%2Fpost%2F0100-brain-stroke-detection-3d-cnn%2F&amp;t=Brain+stroke+detection+from+CT+scans+via+3D+Convolutional+Neural+Network" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Brain%20stroke%20detection%20from%20CT%20scans%20via%203D%20Convolutional%20Neural%20Network&amp;body=https%3A%2F%2Fwww.peco602.com%2Fpost%2F0100-brain-stroke-detection-3d-cnn%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fwww.peco602.com%2Fpost%2F0100-brain-stroke-detection-3d-cnn%2F&amp;title=Brain+stroke+detection+from+CT+scans+via+3D+Convolutional+Neural+Network" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Brain+stroke+detection+from+CT+scans+via+3D+Convolutional+Neural+Network%20https%3A%2F%2Fwww.peco602.com%2Fpost%2F0100-brain-stroke-detection-3d-cnn%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Fwww.peco602.com%2Fpost%2F0100-brain-stroke-detection-3d-cnn%2F&amp;title=Brain+stroke+detection+from+CT+scans+via+3D+Convolutional+Neural+Network" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=https://www.peco602.com/><img class="avatar mr-3 avatar-circle" src=/authors/admin/avatar_huf4f2a9d771509e6e0b947acc7d389632_627121_270x270_fill_q75_lanczos_center.jpg alt="Giovanni Pecoraro"></a><div class=media-body><h5 class=card-title><a href=https://www.peco602.com/>Giovanni Pecoraro</a></h5><h6 class=card-subtitle>Senior Security Engineer</h6><p class=card-text>My research interests include space systems, cyber security, signal processing and artificial intelligence.</p><ul class=network-icon aria-hidden=true><li><a href=/#contact><i class="fas fa-envelope"></i></a></li><li><a href=https://twitter.com/Peco602 target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a href="https://scholar.google.com/citations?user=JSM2EcoAAAAJ" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://www.researchgate.net/profile/Giovanni-Pecoraro target=_blank rel=noopener><i class="fab fa-researchgate"></i></a></li><li><a href=https://github.com/Peco602 target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://it.linkedin.com/in/giovanni-pecoraro-078500155 target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=/uploads/resume.pdf><i class="ai ai-cv"></i></a></li></ul></div></div><script src=https://utteranc.es/client.js repo=Peco602/peco602.github.io issue-term=pathname label=comment theme=github-light crossorigin=anonymous async></script></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text"> 2023 Me. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a>  the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script>
<script src=/en/js/wowchemy.min.e8ee06ba8371980ffde659871dd593b0.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>