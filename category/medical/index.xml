<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Medical | Giovanni Pecoraro</title><link>https://www.peco602.com/category/medical/</link><atom:link href="https://www.peco602.com/category/medical/index.xml" rel="self" type="application/rss+xml"/><description>Medical</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 21 Apr 2023 00:00:00 +0000</lastBuildDate><image><url>https://www.peco602.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Medical</title><link>https://www.peco602.com/category/medical/</link></image><item><title>Brain stroke detection from CT scans via 3D Convolutional Neural Network</title><link>https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/</link><pubDate>Fri, 21 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/</guid><description>&lt;!-- CSS for scrollable code output -->
&lt;style>
.scrollable-output .highlight .chroma {
max-height: 1000px;
overflow-y: auto;
background-color: #23252f !important;
border-color: #23252f !important;
}
&lt;/style>
&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>The &lt;a href="https://www.kaggle.com/datasets/afridirahman/brain-stroke-ct-image-dataset" target="_blank" rel="noopener">Brain Stroke CT Image Dataset&lt;/a> from Kaggle provides normal and stroke brain Computer Tomography (CT) scans. The dataset presents very low activity even though it has been uploaded more than 2 years ago. It may be probably due to its quite low usability (3.13). The challenge is to get some interesting result, i.e., to try to perform brain stroke detection, even from this low-quality CT scans dataset. The followed approach is based on the usage of a 3D Convolutional Neural Network (CNN) in place of a standard 2D one. 2D CNNs are commonly used to process both grayscale (1 channel) and RGB images (3 channels), while a 3D CNN represents the 3D equivalent since it takes as input a 3D volume or a sequence of 2D frames, e.g. slices in a CT scan.
The provided example takes inspiration from the great work &lt;a href="https://keras.io/examples/vision/3D_image_classification/" target="_blank" rel="noopener">3D image classification from CT scans&lt;/a> done by &lt;a href="https://twitter.com/hasibzunair" target="_blank" rel="noopener">Hasib Zunair&lt;/a> who clearly demonstrated how to use a 3D CNN to predict the presence of viral pneumonia from CT scans.&lt;/p>
&lt;h2 id="dataset-exploration">Dataset exploration&lt;/h2>
&lt;p>The CT scans dataset is public available on Kaggle, but for the sake of simplicy it has been made available also on my Github profile so it can be easily downloaded without the need of an API key and additional Python packages.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">os&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">zipfile&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">tensorflow&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">tf&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Download dataset from Github&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">url&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;https://github.com/Peco602/brain-stroke-detection-3d-cnn/releases/download/v0.0.1/brain_ct_data.zip&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">filename&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">join&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getcwd&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="s2">&amp;#34;brain_ct_data.zip&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">utils&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_file&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">filename&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">url&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Unzip dataset&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">with&lt;/span> &lt;span class="n">zipfile&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ZipFile&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;brain_ct_data.zip&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;r&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">z_fp&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">z_fp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">extractall&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;.&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>Downloading data from https://github.com/Peco602/brain-stroke-detection-3d-cnn/releases/download/v0.0.1/brain_ct_data.zip
63160014/63160014 [==============================] - 1s 0us/step
&lt;/code>&lt;/pre>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="err">!&lt;/span>&lt;span class="n">ls&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="n">al&lt;/span> &lt;span class="n">brain_ct_data&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>total 92
drwxr-xr-x 4 root root 4096 Apr 21 07:03 .
drwxr-xr-x 1 root root 4096 Apr 21 07:03 ..
drwxr-xr-x 2 root root 49152 Apr 21 07:03 Normal
drwxr-xr-x 2 root root 32768 Apr 21 07:03 Stroke
&lt;/code>&lt;/pre>
&lt;p>The dataset contains both normal and stroke images respectively in the &lt;code>Normal&lt;/code> and &lt;code>Stroke&lt;/code> folders.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="err">!&lt;/span>&lt;span class="n">ls&lt;/span> &lt;span class="n">brain_ct_data&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">Normal&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">head&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>100 (10).jpg
100 (11).jpg
100 (12).jpg
100 (13).jpg
100 (14).jpg
100 (15).jpg
100 (16).jpg
100 (17).jpg
100 (18).jpg
100 (19).jpg
&lt;/code>&lt;/pre>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="err">!&lt;/span>&lt;span class="n">ls&lt;/span> &lt;span class="n">brain_ct_data&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">Stroke&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="n">head&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>58 (10).jpg
58 (11).jpg
58 (12).jpg
58 (13).jpg
58 (15).jpg
58 (17).jpg
58 (18).jpg
58 (19).jpg
58 (1).jpg
58 (20).jpg
&lt;/code>&lt;/pre>
&lt;p>It is important to clarify the dataset does not contain CT scans, which are usually provided as DICOM or NIfTI files, but the CT scan slices in JPEG format (most probably extracted from DICOM or NIfTI files). A previous &lt;a href="https://www.peco602.com/post/0090-python-dicom/" target="_blank" rel="noopener">post&lt;/a> clearly explains how to extract slice images from a DICOM file. Giving a further look to the slice images it is easy to understand the naming convention &lt;code>PATIENT_ID (SLICE_ID).jpg&lt;/code>, e.g. &lt;code>49 (1).jpg&lt;/code>, &lt;code>49 (2).jpg&lt;/code> and for each patient ID several slices are available. The following function is able to plot up to 40 slices (if available) for a specific patient ID.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">matplotlib.pyplot&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">plt&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">imageio.v2&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">imageio&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">plot_scan_from_path&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">slices_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">patient_id&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Plot 40 slices for a patient ID&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">num_rows&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">4&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">num_columns&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">10&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">factor&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">1.2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">f&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">axarr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">subplots&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">num_rows&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">num_columns&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">figsize&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">num_columns&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">factor&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">num_rows&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="n">factor&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">f&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">suptitle&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;Patient &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">patient_id&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">1.1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">image_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">num_rows&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">j&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">num_columns&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">img&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">imageio&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imread&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">slices_path&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">/&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">patient_id&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1"> (&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">image_id&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">).jpg&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">except&lt;/span> &lt;span class="ne">Exception&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">e&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">img&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zeros&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">finally&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">axarr&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">j&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">img&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;gray&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">axarr&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">j&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">axis&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;off&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">image_id&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">subplots_adjust&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">wspace&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">hspace&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">left&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">right&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">bottom&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">top&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">show&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Let&amp;rsquo;s start with patient 49:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_path&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">slices_path&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;brain_ct_data/Normal&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">patient_id&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">49&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>No such file: '/content/brain_ct_data/Normal/49 (34).jpg'
No such file: '/content/brain_ct_data/Normal/49 (35).jpg'
No such file: '/content/brain_ct_data/Normal/49 (36).jpg'
No such file: '/content/brain_ct_data/Normal/49 (37).jpg'
No such file: '/content/brain_ct_data/Normal/49 (38).jpg'
No such file: '/content/brain_ct_data/Normal/49 (39).jpg'
No such file: '/content/brain_ct_data/Normal/49 (40).jpg'
&lt;/code>&lt;/pre>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_12_1_huc963a19fa5ec2ba52755c9d2ef9de032_461685_3f7106727f0c2778f8e21b0eb6afd6c0.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_12_1_huc963a19fa5ec2ba52755c9d2ef9de032_461685_c6fe155206152789e6d5ee9ddd210bf8.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_12_1_huc963a19fa5ec2ba52755c9d2ef9de032_461685_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_12_1_huc963a19fa5ec2ba52755c9d2ef9de032_461685_3f7106727f0c2778f8e21b0eb6afd6c0.webp"
width="760"
height="341"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Patient 49 has 33 slices, but it is fundamental to underline the slices are not correctly sorted. It seems the slices go from the middle of the head to the top, but then they suddenly start back from the bottom. This may be among the reasons the dataset usability is low. This may not be an issue for a 2D CNN since it takes single images as input, but is a big obstacle for a 3D CNN where the volumetric representation of the brain is needed.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_path&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">slices_path&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;brain_ct_data/Normal&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">patient_id&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">50&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>No such file: '/content/brain_ct_data/Normal/50 (13).jpg'
No such file: '/content/brain_ct_data/Normal/50 (15).jpg'
No such file: '/content/brain_ct_data/Normal/50 (17).jpg'
No such file: '/content/brain_ct_data/Normal/50 (19).jpg'
No such file: '/content/brain_ct_data/Normal/50 (21).jpg'
No such file: '/content/brain_ct_data/Normal/50 (23).jpg'
No such file: '/content/brain_ct_data/Normal/50 (25).jpg'
No such file: '/content/brain_ct_data/Normal/50 (27).jpg'
No such file: '/content/brain_ct_data/Normal/50 (29).jpg'
No such file: '/content/brain_ct_data/Normal/50 (31).jpg'
No such file: '/content/brain_ct_data/Normal/50 (33).jpg'
No such file: '/content/brain_ct_data/Normal/50 (35).jpg'
No such file: '/content/brain_ct_data/Normal/50 (39).jpg'
No such file: '/content/brain_ct_data/Normal/50 (40).jpg'
&lt;/code>&lt;/pre>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_14_1_hua93f85e75ba7dbad122c7ea96b652984_280958_dc1ecbaf713a0954b5fb12763c9fdae4.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_14_1_hua93f85e75ba7dbad122c7ea96b652984_280958_ac03d8b9be67e9f5a82fdc76eab4ebfd.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_14_1_hua93f85e75ba7dbad122c7ea96b652984_280958_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_14_1_hua93f85e75ba7dbad122c7ea96b652984_280958_dc1ecbaf713a0954b5fb12763c9fdae4.webp"
width="760"
height="341"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>For patient 50 the situation is even worse: there are holes in slice sequence, which makes dataset importing even more difficult.&lt;/p>
&lt;h2 id="dataset-fixing">Dataset fixing&lt;/h2>
&lt;p>Before going deeper into modeling it is necessary to try to fix the dataset otherwise it is quite difficult to expect good results. If you are not interested in this section you can skip it and directly jump to the next one since the fixed dataset is also already available on my Github profile.&lt;/p>
&lt;p>The fixing consists of correctly sorting the slices and removing the existing holes. The idea is to create a dictionary where each key represents a patient ID, while the value is the list of correctly sorted images. The creation of such a dictionary was quite demanding since it required to visually analyze the entire dataset to try to determine the correct sequence for each patient.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">INPUT_PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;brain_ct_data&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">OUTPUT_PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;brain_ct_data_fixed&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">NORMAL_INPUT_PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">INPUT_PATH&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">/Normal&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">NORMAL_OUTPUT_PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">OUTPUT_PATH&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">/Normal&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">STROKE_INPUT_PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">INPUT_PATH&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">/Stroke&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">STROKE_OUTPUT_PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">OUTPUT_PATH&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">/Stroke&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">NORMAL_SORTING_CONFIG&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">49&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">50&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">51&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">42&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">44&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">46&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">48&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">50&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">52&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">53&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">41&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">43&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">55&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">56&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">57&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">59&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">60&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">61&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">62&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">63&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">64&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">65&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">95&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">96&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">98&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">99&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">100&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">101&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">102&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">103&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">104&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">105&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">106&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">107&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">108&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">109&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">110&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">111&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">112&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">113&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">114&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">115&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">116&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">117&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">118&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">119&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">120&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">121&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">122&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">123&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">124&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">125&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">126&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">127&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">128&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">129&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">130&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">STROKE_SORTING_CONFIG&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">58&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">66&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">41&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">67&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">68&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">69&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">70&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">41&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">42&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">43&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">44&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">45&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">46&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">47&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">48&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">71&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">48&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">42&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">44&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">46&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">72&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">73&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">74&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">41&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">42&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">43&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">44&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">45&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">46&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">75&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">42&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">44&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">46&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">48&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">49&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">76&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">41&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">42&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">43&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">77&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">41&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">42&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">43&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">78&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">41&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">42&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">79&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">80&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">81&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">41&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">43&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">44&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">82&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">83&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">84&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">85&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">86&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">87&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">41&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">42&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">43&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">44&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">88&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">89&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">41&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">42&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">43&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">90&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">91&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">92&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">42&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">93&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">94&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">17&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">19&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">21&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">23&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">27&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">29&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">31&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">33&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">41&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">43&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">44&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">45&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">46&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="mi">97&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">8&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">9&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">11&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">12&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">13&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">14&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">18&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">24&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">26&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">30&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">34&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">35&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">36&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">37&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">38&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">39&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">40&lt;/span>&lt;span class="p">],&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Given both the &lt;code>NORMAL_SORTING_CONFIG&lt;/code> and &lt;code>STROKE_SORTING_CONFIG&lt;/code> it is just a matter of copying all the slices in the correct order to a different path, i.e., &lt;code>brain_ct_data_fixed&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">os&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">shutil&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">sort_slices&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">input_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">output_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">patient_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">order&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Copy the slices in the correct order&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Create output folder for sorted images (if it does not exist)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">exists&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">output_path&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">makedirs&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">output_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">exist_ok&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Move the image to the output path with a name based on the correct sorting order&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">new_id&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">order&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">old_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">order&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">new_id&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">shutil&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">copyfile&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">input_path&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sep&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">patient_id&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1"> (&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">old_id&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">).jpg&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="sa">f&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">output_path&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sep&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">patient_id&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1"> (&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">new_id&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">).jpg&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Normal slices sorting&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">patient_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">order&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">NORMAL_SORTING_CONFIG&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">items&lt;/span>&lt;span class="p">():&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sort_slices&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">input_path&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">NORMAL_INPUT_PATH&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">output_path&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">NORMAL_OUTPUT_PATH&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">patient_id&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">patient_id&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">order&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">order&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Stroke slices sorting&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">patient_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">order&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">STROKE_SORTING_CONFIG&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">items&lt;/span>&lt;span class="p">():&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sort_slices&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">input_path&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">STROKE_INPUT_PATH&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">output_path&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">STROKE_OUTPUT_PATH&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">patient_id&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">patient_id&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">order&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">order&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Let&amp;rsquo;s try to plot again CT slices for both patients 49 and 50:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_path&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">slices_path&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">NORMAL_OUTPUT_PATH&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">patient_id&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">49&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>No such file: '/content/brain_ct_data_fixed/Normal/49 (34).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/49 (35).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/49 (36).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/49 (37).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/49 (38).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/49 (39).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/49 (40).jpg'
&lt;/code>&lt;/pre>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_23_1_hue7baffb15e2b06ed500a09d7e814e006_457306_5a1a31fd2f83adb87428afa381a425b6.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_23_1_hue7baffb15e2b06ed500a09d7e814e006_457306_85195e1f0bc019970566c46c7cac0ce1.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_23_1_hue7baffb15e2b06ed500a09d7e814e006_457306_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_23_1_hue7baffb15e2b06ed500a09d7e814e006_457306_5a1a31fd2f83adb87428afa381a425b6.webp"
width="760"
height="341"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_path&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">slices_path&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">NORMAL_OUTPUT_PATH&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">patient_id&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">50&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>No such file: '/content/brain_ct_data_fixed/Normal/50 (27).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (28).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (29).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (30).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (31).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (32).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (33).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (34).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (35).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (36).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (37).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (38).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (39).jpg'
No such file: '/content/brain_ct_data_fixed/Normal/50 (40).jpg'
&lt;/code>&lt;/pre>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_24_1_hud597068fbe2ffaf25f9d80b7e7f9023e_269313_89af5f95a5d6c36dbb15e8dcfc680651.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_24_1_hud597068fbe2ffaf25f9d80b7e7f9023e_269313_cfc8367cabdca8aa5d123000be5426a9.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_24_1_hud597068fbe2ffaf25f9d80b7e7f9023e_269313_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_24_1_hud597068fbe2ffaf25f9d80b7e7f9023e_269313_89af5f95a5d6c36dbb15e8dcfc680651.webp"
width="760"
height="341"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Hopefully, the dataset should be fixed now. The fixed dataset is publicly available &lt;a href="https://github.com/Peco602/brain-stroke-detection-3d-cnn/releases/download/v0.0.1/brain_ct_data_fixed.zip" target="_blank" rel="noopener">here&lt;/a>.&lt;/p>
&lt;h2 id="dataset-loading-and-preprocessing">Dataset loading and preprocessing&lt;/h2>
&lt;p>In case the previous section has been skipped, it is possible to directly download the fixed dataset:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">os&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">zipfile&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">tensorflow&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">tf&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Download dataset from Github&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">url&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;https://github.com/Peco602/brain-stroke-detection-3d-cnn/releases/download/v0.0.1/brain_ct_data_fixed.zip&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">filename&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">join&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getcwd&lt;/span>&lt;span class="p">(),&lt;/span> &lt;span class="s2">&amp;#34;brain_ct_data_fixed.zip&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">utils&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_file&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">filename&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">url&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Unzip dataset&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">with&lt;/span> &lt;span class="n">zipfile&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ZipFile&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;brain_ct_data_fixed.zip&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;r&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">z_fp&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">z_fp&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">extractall&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;.&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">NORMAL_PATH&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;/content/brain_ct_data_fixed/Normal&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">STROKE_PATH&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;/content/brain_ct_data_fixed/Stroke&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Before going deeper into data loading it can be interesting to give a look to a single CT slice.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">imageio.v2&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">imageio&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">matplotlib.pyplot&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">plt&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">imageio&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imread&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">STROKE_PATH&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">/67 (15).jpg&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">image&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;gray&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>&amp;lt;matplotlib.image.AxesImage at 0x7fa302346580&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_33_1_hu6da8c0fe3b25fbfa39434b0c715dccc7_68014_f27d4e0683adc9b564964c00c667f76d.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_33_1_hu6da8c0fe3b25fbfa39434b0c715dccc7_68014_af54b659c6ed639b0bd7ff80c03d2d53.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_33_1_hu6da8c0fe3b25fbfa39434b0c715dccc7_68014_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_33_1_hu6da8c0fe3b25fbfa39434b0c715dccc7_68014_f27d4e0683adc9b564964c00c667f76d.webp"
width="425"
height="418"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>As it is possible to see, the image presents some artifacts that may hinder the CNN training process. &lt;a href="https://vincentblog.xyz/posts/medical-images-in-python-computed-tomography" target="_blank" rel="noopener">Vicente Rodrguez&lt;/a> provided a nice example of CT image denoising that lead to the creation of the following &lt;code>remove_noise&lt;/code> function:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">scipy&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">ndimage&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">skimage&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">morphology&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">remove_noise&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">image&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">display&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Remove slice noise&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># morphology.dilation creates a segmentation of the image&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># If one pixel is between the origin and the edge of a square of size&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># 3x3, the pixel belongs to the same class&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">segmentation&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">morphology&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dilation&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">image&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ones&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">segmentation&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">segmentation&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">segmentation&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">segmentation&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="mi">25&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">labels&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">label_nb&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ndimage&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">label&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">segmentation&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">label_count&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bincount&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">labels&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ravel&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">astype&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">int&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># The size of label_count is the number of classes/segmentations found.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># The first class is not used since it&amp;#39;s the background.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">label_count&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># A mask with the class with more pixels is created&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># since it should represent the brain&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">mask&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">labels&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="n">label_count&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">argmax&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Improve the brain mask&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">mask&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">morphology&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dilation&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mask&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ones&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">mask&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ndimage&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">binary_fill_holes&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mask&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">mask&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">morphology&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dilation&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mask&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ones&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Since the pixels in the mask are zeros and ones,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># it is possible to multiple the original image to only keep the brain region&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">masked_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">mask&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">image&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">display&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">figure&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">figsize&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">2.5&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">subplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">141&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">image&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bone&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">title&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Original Image&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">axis&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;off&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">subplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">142&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mask&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bone&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">title&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Mask&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">axis&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;off&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">subplot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">143&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">masked_image&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bone&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">title&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Clean Image&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">axis&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;off&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">masked_image&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>So, let&amp;rsquo;s try to remove the background artifacts from the image:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">denoised_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">remove_noise&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">image&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">display&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_37_0_hu71a993d8bd84808ac3773613cf8720b6_33679_a2dd6492daff2eae4b74b9b3168c4196.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_37_0_hu71a993d8bd84808ac3773613cf8720b6_33679_76f74d80e418c4fd1a719eedbf282976.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_37_0_hu71a993d8bd84808ac3773613cf8720b6_33679_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_37_0_hu71a993d8bd84808ac3773613cf8720b6_33679_a2dd6492daff2eae4b74b9b3168c4196.webp"
width="592"
height="210"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>As expected, the CT artifacts are not present anymore.&lt;/p>
&lt;p>It is worth noting despite the CT slices have been correctly sorted and there are no holes in slice sequences anymore, the dataset is still not so straightforward to import since the number of slices per patient is not
always the same. The &lt;code>load_dataset&lt;/code> function appears quite complex because it has to execute in sequence multiple steps to load and pre-process the entire image dataset:&lt;/p>
&lt;ol>
&lt;li>&lt;code>count_slices&lt;/code>: counts the number of slices per patient&lt;/li>
&lt;li>&lt;code>merge_slices&lt;/code>: denoises (optionally) and merges all patient slices into a single scan&lt;/li>
&lt;li>&lt;code>normalize_scan&lt;/code>: normalizes the scan values to the interval &lt;code>[0, 1]&lt;/code>&lt;/li>
&lt;li>&lt;code>resize_scan&lt;/code>: resizes the scan across x, y and z axis to uniform the scan sizes to fixed values&lt;/li>
&lt;/ol>
&lt;p>Finally, the returned dataset is a 4D array, i.e., an array of scans (3D images).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">tqdm&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">tqdm&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">resize_scan&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">scan&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Resize the CT scan to a desired uniform size across all axis&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Set the desired depth&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">desired_depth&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">64&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">desired_width&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">128&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">desired_height&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">128&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Get current depth&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">current_depth&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">scan&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">current_width&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">scan&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">current_height&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">scan&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Compute depth factor&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">depth&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">current_depth&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">desired_depth&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">width&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">current_width&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">desired_width&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">height&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">current_height&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">desired_height&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">depth_factor&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">depth&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">width_factor&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">width&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">height_factor&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">height&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Rotate&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">scan&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ndimage&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">rotate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">scan&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">90&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">reshape&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Resize across z-axis&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">scan&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ndimage&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zoom&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">scan&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">width_factor&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">height_factor&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">depth_factor&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">order&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">scan&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">normalize_scan&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">scan&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Normalize the scan to the interval [0, 1]&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">min&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">max&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">255&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">scan&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">scan&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">min&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">scan&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">scan&lt;/span> &lt;span class="o">&amp;gt;&lt;/span> &lt;span class="nb">max&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">max&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">scan&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">scan&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nb">max&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="nb">min&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">scan&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">scan&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">astype&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;float32&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">scan&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">merge_slices&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">patient_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">slice_count&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">denoise&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Merge all the slices for a patient into a scan&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">denoise&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">scan&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">tuple&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">remove_noise&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">imageio&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imread&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">/&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">patient_id&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1"> (&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">slice_id&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">).jpg&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">slice_id&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">slice_count&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">scan&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">tuple&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">imageio&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imread&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s1">&amp;#39;&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">/&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">patient_id&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1"> (&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">slice_id&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s1">).jpg&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">slice_id&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">slice_count&lt;/span>&lt;span class="o">+&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dstack&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">scan&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">count_slices&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Analyze the slices path and returns a dictionary with the slices count associated to each patient&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">slice_dict&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">dirname&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">_&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">filenames&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">walk&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">filename&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">filenames&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">patient_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">int&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">filename&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">()[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">patient_id&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">slice_dict&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">slice_dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">patient_id&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">slice_dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">patient_id&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">slice_dict&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">patient_id&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">slice_dict&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">collect_scan&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">patient_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">slice_count&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Collect a scan for a patient id&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Get a single CT scan by merging all the slices from a single patient&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Before getting merged the slices are also denoised&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">scan&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">merge_slices&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">patient_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">slice_count&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">denoise&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Normalize the CT scan to the interval [0, 1]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">scan&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">normalize_scan&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">scan&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Resize the CT scan to uniform the size&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">scan&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">resize_scan&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">scan&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">scan&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">load_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Return the scans dataset as a 4D array&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Get a dictionary with patient IDs and slice count per patient&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">slices_dict&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">count_slices&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Collect scans for each patient id&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dataset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">collect_scan&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">patient_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">slice_count&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">patient_id&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">slice_count&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">tqdm&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">slices_dict&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">items&lt;/span>&lt;span class="p">())])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">dataset&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Both the normal and stroke datasets are imported from the respective paths. Since the process can take some minutes the &lt;code>tqdm&lt;/code> library can help to check the progress in realtime.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">normal_dataset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">load_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">NORMAL_PATH&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">stroke_dataset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">load_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">path&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">STROKE_PATH&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>100%|| 51/51 [02:55&amp;lt;00:00, 3.44s/it]
100%|| 31/31 [01:41&amp;lt;00:00, 3.27s/it]
&lt;/code>&lt;/pre>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">normal_dataset&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">stroke_dataset&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>((51, 128, 128, 64), (31, 128, 128, 64))
&lt;/code>&lt;/pre>
&lt;p>The normal and stroke datasets are represented by rank-3 tensors of shape &lt;code>(samples, height, width, depth)&lt;/code>. There are 51 normal and 31 stroke CT scans so the dataset is quite unbalanced.&lt;/p>
&lt;p>The function &lt;code>plot_slices_from_dataset&lt;/code> can be used to plot an entire CT scan from the loaded dataset.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">num_rows&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">num_columns&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">width&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">height&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">data&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">title&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Plot a scan from dataset&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">transpose&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">data&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">reshape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">data&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">num_rows&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">num_columns&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">width&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">height&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">rows_data&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">columns_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">heights&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">slc&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">slc&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">data&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">widths&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="n">slc&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">slc&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">data&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">fig_width&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">12.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">fig_height&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">fig_width&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">heights&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="nb">sum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">widths&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">f&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">axarr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">subplots&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">rows_data&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">columns_data&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">figsize&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fig_width&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fig_height&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">gridspec_kw&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="s2">&amp;#34;height_ratios&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">heights&lt;/span>&lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">f&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">suptitle&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">title&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">1.1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">rows_data&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">j&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">columns_data&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">axarr&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">j&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">data&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">][&lt;/span>&lt;span class="n">j&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;gray&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">axarr&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">j&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">axis&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;off&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">subplots_adjust&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">wspace&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">hspace&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">left&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">right&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">bottom&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">top&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">show&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The first scan from both the normal and stroke datasets is shown hereafter.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">normal_dataset&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:],&lt;/span> &lt;span class="s2">&amp;#34;Normal CT scan&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_48_0_huaf6266c585d299ca05fdc57077781f89_285227_7166f948faf3249230e2de8af6c976e0.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_48_0_huaf6266c585d299ca05fdc57077781f89_285227_3b4cd910e4799c61b19be8ce51aae928.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_48_0_huaf6266c585d299ca05fdc57077781f89_285227_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_48_0_huaf6266c585d299ca05fdc57077781f89_285227_7166f948faf3249230e2de8af6c976e0.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">stroke_dataset&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:],&lt;/span> &lt;span class="s2">&amp;#34;Stroke CT scan&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_49_0_huf6a37d4a6ead960cadcc6717609e4865_287423_d719ee2f988cc8a0e696d1d0244622e3.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_49_0_huf6a37d4a6ead960cadcc6717609e4865_287423_e21288fe975de4d607cdbb449efd05e3.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_49_0_huf6a37d4a6ead960cadcc6717609e4865_287423_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_49_0_huf6a37d4a6ead960cadcc6717609e4865_287423_d719ee2f988cc8a0e696d1d0244622e3.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Both the datasets are now splitted and merged into &lt;code>training&lt;/code> and &lt;code>validation&lt;/code> datasets with a ratio of 70% and 30%.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># For the CT scans having presence of stroke assign 1 otherwise 0.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">normal_labels&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">0&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">normal_dataset&lt;/span>&lt;span class="p">))])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">stroke_labels&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mi">1&lt;/span> &lt;span class="k">for&lt;/span> &lt;span class="n">_&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">stroke_dataset&lt;/span>&lt;span class="p">))])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Split data in the ratio 70%-30% for training and validation.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">math&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">VALIDATION_SPLIT&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.7&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">normal_train_len&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">math&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ceil&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">VALIDATION_SPLIT&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">normal_labels&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">stroke_train_len&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">math&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ceil&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">VALIDATION_SPLIT&lt;/span>&lt;span class="o">*&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">stroke_labels&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x_train&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">concatenate&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="n">normal_dataset&lt;/span>&lt;span class="p">[:&lt;/span>&lt;span class="n">normal_train_len&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">stroke_dataset&lt;/span>&lt;span class="p">[:&lt;/span>&lt;span class="n">stroke_train_len&lt;/span>&lt;span class="p">]),&lt;/span> &lt;span class="n">axis&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">y_train&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">concatenate&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="n">normal_labels&lt;/span>&lt;span class="p">[:&lt;/span>&lt;span class="n">normal_train_len&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">stroke_labels&lt;/span>&lt;span class="p">[:&lt;/span>&lt;span class="n">stroke_train_len&lt;/span>&lt;span class="p">]),&lt;/span> &lt;span class="n">axis&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">x_val&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">concatenate&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="n">normal_dataset&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">normal_train_len&lt;/span>&lt;span class="p">:],&lt;/span> &lt;span class="n">stroke_dataset&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">stroke_train_len&lt;/span>&lt;span class="p">:]),&lt;/span> &lt;span class="n">axis&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">y_val&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">concatenate&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="n">normal_labels&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">normal_train_len&lt;/span>&lt;span class="p">:],&lt;/span> &lt;span class="n">stroke_labels&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">stroke_train_len&lt;/span>&lt;span class="p">:]),&lt;/span> &lt;span class="n">axis&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;Training samples&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;Normal: &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">normal_train_len&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;Stroke: &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">stroke_train_len&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;Total: &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;Validation samples&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;Normal: &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">normal_dataset&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">normal_train_len&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;Stroke: &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">stroke_dataset&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">stroke_train_len&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;Total: &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">x_val&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>Training samples
Normal: 36
Stroke: 22
Total: 58
Validation samples
Normal: 15
Stroke: 9
Total: 24
&lt;/code>&lt;/pre>
&lt;h2 id="dataset-augmentation">Dataset augmentation&lt;/h2>
&lt;p>A machine learning model performs better and is more accurate when the dataset is rich and sufficient. Deep learning in general, but particularly in medical imaging, requires a large amount of training data in order to obtain good performance and avoid overfitting. To meet these challenges, increasing the quantity of training data is a common solution. Data augmentation is a common approach to enhance the performance and the results of machine learning models. It allows a small dataset to be rebalanced or enriched for any reason (time-consuming manual annotations, lack of accessible data&amp;hellip;). The augmentation techniques must make sense with respect to the type of analysis desired and therefore positively influence the performance of the model during the learning phase: by applying a large number of augmentations, the performance will not necessarily be better. There are several types of transformations for medical images, but few examples which can be seen as good starting point for CT scans are provided in the following.&lt;/p>
&lt;h3 id="rotation">Rotation&lt;/h3>
&lt;p>This transformation consists of rotating the original image according to a desired angle. In medical image analysis, this represents a common augmentation technique. In this case the scan is rotated around z-axis by a random angle in the interval &lt;code>[-45, 45]&lt;/code> degrees.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">rotation_layer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomRotation&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">factor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mf">0.125&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.125&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">fill_mode&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;constant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fill_value&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x_train&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:],&lt;/span> &lt;span class="s2">&amp;#34;Original CT Scan&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">rotation_layer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:]),&lt;/span> &lt;span class="s2">&amp;#34;Rotated CT Scan&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_55_0_hu22903692c92ba947c6626019f1a7bc4e_285512_2f2da998956062c586358f4ae7449404.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_55_0_hu22903692c92ba947c6626019f1a7bc4e_285512_86ae2abfb6e86dd2f05a5530d260ccca.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_55_0_hu22903692c92ba947c6626019f1a7bc4e_285512_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_55_0_hu22903692c92ba947c6626019f1a7bc4e_285512_2f2da998956062c586358f4ae7449404.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_55_1_huaf2b83aedc344bf80c0cc99ce801171e_291673_e97c24760429b0d3794f5acf81fbbf0b.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_55_1_huaf2b83aedc344bf80c0cc99ce801171e_291673_7095368e3302d95d5a2bc3d92c417f30.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_55_1_huaf2b83aedc344bf80c0cc99ce801171e_291673_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_55_1_huaf2b83aedc344bf80c0cc99ce801171e_291673_e97c24760429b0d3794f5acf81fbbf0b.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="flip">Flip&lt;/h3>
&lt;p>The image flips are performed along an axis of symmetry. For medical image enhancement, they can be performed vertically as well as horizontally, because images can be acquired in supine or prone position, and contain anatomical variations (e.g., situs inversus). An organ, whatever its location in the body, will always be the same organ.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">flipping_layer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomFlip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mode&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;vertical&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x_train&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:],&lt;/span> &lt;span class="s2">&amp;#34;Original CT Scan&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">flipping_layer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:]),&lt;/span> &lt;span class="s2">&amp;#34;Flipped CT Scan&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_57_0_hu22903692c92ba947c6626019f1a7bc4e_285512_ddc72c38641cdcb6b3fe84c6c42ac0a4.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_57_0_hu22903692c92ba947c6626019f1a7bc4e_285512_398e9915f05652c5206f23b26b1d9a0c.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_57_0_hu22903692c92ba947c6626019f1a7bc4e_285512_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_57_0_hu22903692c92ba947c6626019f1a7bc4e_285512_ddc72c38641cdcb6b3fe84c6c42ac0a4.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_57_1_hueca98666ee82f894096eece0713b0fa9_285107_cf203246c6e90eae406f934869c51b9a.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_57_1_hueca98666ee82f894096eece0713b0fa9_285107_fac8678409a0108a02958221191751a9.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_57_1_hueca98666ee82f894096eece0713b0fa9_285107_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_57_1_hueca98666ee82f894096eece0713b0fa9_285107_cf203246c6e90eae406f934869c51b9a.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="shift">Shift&lt;/h3>
&lt;p>This transformation can be performed along the x and/or y axis randomly. The transformed image keeps the same size and orientation as the original image, but is moved in the applied direction. The added pixels are filled with zeros.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">shifting_layer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomTranslation&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">height_factor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">width_factor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fill_mode&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;constant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fill_value&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x_train&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:],&lt;/span> &lt;span class="s2">&amp;#34;Original CT Scan&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shifting_layer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:]),&lt;/span> &lt;span class="s2">&amp;#34;Shifted CT Scan&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_59_0_hu22903692c92ba947c6626019f1a7bc4e_285512_59bc9af92e53090d956d6649cb32438c.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_59_0_hu22903692c92ba947c6626019f1a7bc4e_285512_7a9f3e8a54dc523ad03aa0e721b8050b.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_59_0_hu22903692c92ba947c6626019f1a7bc4e_285512_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_59_0_hu22903692c92ba947c6626019f1a7bc4e_285512_59bc9af92e53090d956d6649cb32438c.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_59_1_huf672c62cdba27bb464119ac172f1cada_281281_0cfc199dfa28d2f49f4b4477ac8f5268.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_59_1_huf672c62cdba27bb464119ac172f1cada_281281_261e461b8503f5007c75d6abc4274cfc.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_59_1_huf672c62cdba27bb464119ac172f1cada_281281_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_59_1_huf672c62cdba27bb464119ac172f1cada_281281_0cfc199dfa28d2f49f4b4477ac8f5268.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="zoom">Zoom&lt;/h3>
&lt;p>A zoom augmentation randomly zooms the image in or out. The zoomed image keeps the same size and orientation as the original image.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">zoom_layer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomZoom&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">height_factor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fill_mode&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;constant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fill_value&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x_train&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:],&lt;/span> &lt;span class="s2">&amp;#34;Original CT Scan&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">zoom_layer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:]),&lt;/span> &lt;span class="s2">&amp;#34;Zoomed CT Scan&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_61_0_hu22903692c92ba947c6626019f1a7bc4e_285512_23536e2483cd66332d9c1e2fbb4b8e8a.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_61_0_hu22903692c92ba947c6626019f1a7bc4e_285512_9203dab1e5943e6896c13538226a4743.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_61_0_hu22903692c92ba947c6626019f1a7bc4e_285512_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_61_0_hu22903692c92ba947c6626019f1a7bc4e_285512_23536e2483cd66332d9c1e2fbb4b8e8a.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_61_1_hu9f1ae8879943d1c1eec206fe4390ff57_289066_81ce815dafb86ae0e3036d3afbd5659f.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_61_1_hu9f1ae8879943d1c1eec206fe4390ff57_289066_2e7a12272af8d4c510cc2e0739da1fe1.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_61_1_hu9f1ae8879943d1c1eec206fe4390ff57_289066_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_61_1_hu9f1ae8879943d1c1eec206fe4390ff57_289066_81ce815dafb86ae0e3036d3afbd5659f.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="shear">Shear&lt;/h3>
&lt;p>Shearing is an affine transformation that consists of shifting in opposite directions the top and bottom of the image (horizontal shearing) or the right and left of the image (vertical shearing). Unlike the previous methods, the image is distorted. Shear augmentation is not available in &lt;code>tensorflow&lt;/code> so the &lt;code>keras_cv&lt;/code> package must be installed.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="err">!&lt;/span>&lt;span class="n">pip&lt;/span> &lt;span class="n">install&lt;/span> &lt;span class="n">keras_cv&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting keras_cv
Downloading keras_cv-0.4.2-py3-none-any.whl (634 kB)
[2K [90m[0m [32m634.9/634.9 kB[0m [31m13.2 MB/s[0m eta [36m0:00:00[0m
[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from keras_cv) (23.1)
Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from keras_cv) (1.4.0)
Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.9/dist-packages (from keras_cv) (4.8.3)
Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from keras_cv) (2022.10.31)
Requirement already satisfied: promise in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&amp;gt;keras_cv) (2.3)
Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&amp;gt;keras_cv) (1.13.1)
Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&amp;gt;keras_cv) (4.65.0)
Requirement already satisfied: protobuf&amp;gt;=3.12.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&amp;gt;keras_cv) (3.20.3)
Requirement already satisfied: toml in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&amp;gt;keras_cv) (0.10.2)
Requirement already satisfied: requests&amp;gt;=2.19.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&amp;gt;keras_cv) (2.27.1)
Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&amp;gt;keras_cv) (8.1.3)
Requirement already satisfied: etils[enp,epath]&amp;gt;=0.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&amp;gt;keras_cv) (1.2.0)
Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&amp;gt;keras_cv) (2.2.0)
Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&amp;gt;keras_cv) (1.22.4)
Requirement already satisfied: wrapt in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&amp;gt;keras_cv) (1.14.1)
Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&amp;gt;keras_cv) (5.9.5)
Requirement already satisfied: dm-tree in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets-&amp;gt;keras_cv) (0.1.8)
Requirement already satisfied: importlib_resources in /usr/local/lib/python3.9/dist-packages (from etils[enp,epath]&amp;gt;=0.9.0-&amp;gt;tensorflow-datasets-&amp;gt;keras_cv) (5.12.0)
Requirement already satisfied: zipp in /usr/local/lib/python3.9/dist-packages (from etils[enp,epath]&amp;gt;=0.9.0-&amp;gt;tensorflow-datasets-&amp;gt;keras_cv) (3.15.0)
Requirement already satisfied: typing_extensions in /usr/local/lib/python3.9/dist-packages (from etils[enp,epath]&amp;gt;=0.9.0-&amp;gt;tensorflow-datasets-&amp;gt;keras_cv) (4.5.0)
Requirement already satisfied: idna&amp;lt;4,&amp;gt;=2.5 in /usr/local/lib/python3.9/dist-packages (from requests&amp;gt;=2.19.0-&amp;gt;tensorflow-datasets-&amp;gt;keras_cv) (3.4)
Requirement already satisfied: certifi&amp;gt;=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests&amp;gt;=2.19.0-&amp;gt;tensorflow-datasets-&amp;gt;keras_cv) (2022.12.7)
Requirement already satisfied: urllib3&amp;lt;1.27,&amp;gt;=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests&amp;gt;=2.19.0-&amp;gt;tensorflow-datasets-&amp;gt;keras_cv) (1.26.15)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests&amp;gt;=2.19.0-&amp;gt;tensorflow-datasets-&amp;gt;keras_cv) (2.0.12)
Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from promise-&amp;gt;tensorflow-datasets-&amp;gt;keras_cv) (1.16.0)
Requirement already satisfied: googleapis-common-protos&amp;lt;2,&amp;gt;=1.52.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-metadata-&amp;gt;tensorflow-datasets-&amp;gt;keras_cv) (1.59.0)
Installing collected packages: keras_cv
Successfully installed keras_cv-0.4.2
&lt;/code>&lt;/pre>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">keras_cv&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">shear_layer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">keras_cv&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomShear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_factor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.3&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">y_factor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.3&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">interpolation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;bilinear&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fill_mode&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;nearest&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fill_value&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x_train&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:],&lt;/span> &lt;span class="s2">&amp;#34;Original CT Scan&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shear_layer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:]),&lt;/span> &lt;span class="s2">&amp;#34;Sheared CT Scan&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>You do not have Waymo Open Dataset installed, so KerasCV Waymo metrics are not available.
&lt;/code>&lt;/pre>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_64_1_hu22903692c92ba947c6626019f1a7bc4e_285512_d84f082c02e398644a6c684284720b0e.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_64_1_hu22903692c92ba947c6626019f1a7bc4e_285512_206de1e447c7320d395b8235a13cd366.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_64_1_hu22903692c92ba947c6626019f1a7bc4e_285512_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_64_1_hu22903692c92ba947c6626019f1a7bc4e_285512_d84f082c02e398644a6c684284720b0e.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_64_2_hufe7c3f52a905b1de42d643254255b8f5_270799_d5daecaad9fef1be7ae698a0962eb017.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_64_2_hufe7c3f52a905b1de42d643254255b8f5_270799_bc850dd67ed6a037027dfd8681149b66.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_64_2_hufe7c3f52a905b1de42d643254255b8f5_270799_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_64_2_hufe7c3f52a905b1de42d643254255b8f5_270799_d5daecaad9fef1be7ae698a0962eb017.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="brightness">Brightness&lt;/h3>
&lt;p>The higher the value of the brighteness, the lighter is the image. In order to increase the size of the data set in medical imaging, brightness variations belonging to the interval &lt;code>[-0.1; 0.1]&lt;/code> are randomly applied.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">brighteness_layer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomBrightness&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">factor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">value_range&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mf">0.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">1.0&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x_train&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:],&lt;/span> &lt;span class="s2">&amp;#34;Original CT Scan&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">brighteness_layer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:]),&lt;/span> &lt;span class="s2">&amp;#34;Brightened CT Scan&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_66_0_hu22903692c92ba947c6626019f1a7bc4e_285512_255c2fc8ba503f51c2dd6f4540695b9e.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_66_0_hu22903692c92ba947c6626019f1a7bc4e_285512_a269f5441f3542d4391fbcd947d2503e.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_66_0_hu22903692c92ba947c6626019f1a7bc4e_285512_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_66_0_hu22903692c92ba947c6626019f1a7bc4e_285512_255c2fc8ba503f51c2dd6f4540695b9e.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_66_1_hu281aff6f463048ccdeda96e47fa9648b_284934_4aa41e22a06c69d0338574057328ece9.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_66_1_hu281aff6f463048ccdeda96e47fa9648b_284934_744c8a2ebcb5c5214fc5252fbb85095f.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_66_1_hu281aff6f463048ccdeda96e47fa9648b_284934_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_66_1_hu281aff6f463048ccdeda96e47fa9648b_284934_4aa41e22a06c69d0338574057328ece9.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h2 id="contrast">Contrast&lt;/h2>
&lt;p>The contrast of an image is increased when the darker pixels are darkened and the lighter pixels are lightened: a contrasted image will therefore contain a greater quantity of black and white. The contrast increase is clearly visible on image histogram, because the gap between the brightest and the darkest pixels is greater, i.e., the histogram is more spread out.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">contrast_layer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomContrast&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">factor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">1.2&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">x_train&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:],&lt;/span> &lt;span class="s2">&amp;#34;Original CT Scan&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plot_scan_from_dataset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">16&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">contrast_layer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:,&lt;/span> &lt;span class="p">:]),&lt;/span> &lt;span class="s2">&amp;#34;Contrasted CT Scan&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_68_0_hu22903692c92ba947c6626019f1a7bc4e_285512_6d03d99d673f097bfca993d70b027f74.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_68_0_hu22903692c92ba947c6626019f1a7bc4e_285512_8f367ad0a7e4fd35f9fcaa645f13bf0a.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_68_0_hu22903692c92ba947c6626019f1a7bc4e_285512_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_68_0_hu22903692c92ba947c6626019f1a7bc4e_285512_6d03d99d673f097bfca993d70b027f74.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_68_1_huec02491918b2062da692f16d5b5c9b8a_286684_fb2884c24223943b0329c61df1a9ddc1.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_68_1_huec02491918b2062da692f16d5b5c9b8a_286684_65ce2c19f4bb5c5e2558baa8c8f9f728.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_68_1_huec02491918b2062da692f16d5b5c9b8a_286684_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_68_1_huec02491918b2062da692f16d5b5c9b8a_286684_fb2884c24223943b0329c61df1a9ddc1.webp"
width="760"
height="218"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>The training and validation data loaders must be defined. In this case, data augmentation is not applied through the data loader but directly on the CNN by adding the related augmentation layers.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Set TensorFlow random seed&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_seed&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">42&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Define data loaders&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">training_loader&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Dataset&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">from_tensor_slices&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_train&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">validation_loader&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Dataset&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">from_tensor_slices&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="n">x_val&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">y_val&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Define batch size&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">batch_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Training dataset&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">training_dataset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">training_loader&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shuffle&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_train&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="n">batch&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="n">prefetch&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Validation dataset&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">validation_dataset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">validation_loader&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shuffle&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_val&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="n">batch&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">batch_size&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="n">prefetch&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="model-definition">Model definition&lt;/h2>
&lt;p>The architecture of the 3D CNN is the same used &lt;a href="https://keras.io/examples/vision/3D_image_classification/" target="_blank" rel="noopener">here&lt;/a>, but, as already said, the CT scans are optionally augmented by passing them through some augmentation layers which have been directly embedded into the model. A reshape layer has also been added since the data is stored in rank-3 tensors of shape (samples, height, width, depth), a dimension of size 1 at axis 4 is needed in order to be able to perform 3D convolutions on the data. The additional dimension is needed to take into account the number of image channel which in this case is just 1.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">tensorflow&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">keras&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">tensorflow.keras&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">layers&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Default arguments&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">WIDTH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">128&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">HEIGHT&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">128&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">DEPTH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">64&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">INITIAL_LEARNING_RATE&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.0001&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">DECAY_STEPS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">100000&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">DECAY_RATE&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.96&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Performance metrics&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">METRICS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">metrics&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TruePositives&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;tp&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">metrics&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FalsePositives&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;fp&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">metrics&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TrueNegatives&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;tn&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">metrics&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">FalseNegatives&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;fn&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">metrics&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BinaryAccuracy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;accuracy&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">metrics&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Precision&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;precision&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">metrics&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Recall&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;recall&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">metrics&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AUC&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;auc&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">metrics&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">AUC&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;prc&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">curve&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;PR&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="c1"># precision-recall curve&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">build_model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">width&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">WIDTH&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">height&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">HEIGHT&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">depth&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">DEPTH&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">initial_learning_rate&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">INITIAL_LEARNING_RATE&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">decay_steps&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">DECAY_STEPS&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">decay_rate&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">DECAY_RATE&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">metrics&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">METRICS&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">augmentation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">rotation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">flip&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">shift&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">zoom&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">shear&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">brightness&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">contrast&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Build a 3D convolutional neural network model with augmentation layers&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Define the model&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Sequential&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Input&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="n">width&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">height&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">depth&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># (Optionally) Add augmentation layers&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">augmentation&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">rotation&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomRotation&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">factor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mf">0.125&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.125&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">fill_mode&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;constant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fill_value&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">flip&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomFlip&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">mode&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;vertical&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">shift&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomTranslation&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">height_factor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">width_factor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fill_mode&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;constant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fill_value&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">zoom&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomZoom&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">height_factor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.15&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fill_mode&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;constant&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fill_value&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">shear&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">keras_cv&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomShear&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">x_factor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.3&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">y_factor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">0.3&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">interpolation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;bilinear&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fill_mode&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;nearest&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">fill_value&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.0&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">brightness&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomBrightness&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">factor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">value_range&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mf">0.0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">1.0&lt;/span>&lt;span class="p">]))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">contrast&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">RandomContrast&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">factor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mf">1.2&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Add a dimension to perform 3D convolutions&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Reshape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">target_shape&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">width&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">height&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">depth&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Conv3D&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">filters&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">64&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">kernel_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">activation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;relu&amp;#34;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MaxPool3D&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">pool_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BatchNormalization&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Conv3D&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">filters&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">64&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">kernel_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">activation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;relu&amp;#34;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MaxPool3D&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">pool_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BatchNormalization&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Conv3D&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">filters&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">128&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">kernel_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">activation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;relu&amp;#34;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MaxPool3D&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">pool_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BatchNormalization&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Conv3D&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">filters&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">256&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">kernel_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">activation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;relu&amp;#34;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">MaxPool3D&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">pool_size&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">BatchNormalization&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">GlobalAveragePooling3D&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Dense&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">units&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">512&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">activation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;relu&amp;#34;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Dropout&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mf">0.3&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Dense&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">units&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">activation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;sigmoid&amp;#34;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Define the optimizer&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">lr_schedule&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">optimizers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">schedules&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ExponentialDecay&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">initial_learning_rate&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">decay_steps&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">decay_steps&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">decay_rate&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">decay_rate&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">staircase&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Compile the model&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">compile&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">loss&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;binary_crossentropy&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">optimizers&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Adam&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">learning_rate&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">lr_schedule&lt;/span>&lt;span class="p">),&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">metrics&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">metrics&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">model&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Build the model with default parameters&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">build_model&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Print the model summary&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">summary&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type) Output Shape Param #
=================================================================
reshape (Reshape) (None, 128, 128, 64, 1) 0
conv3d (Conv3D) (None, 126, 126, 62, 64) 1792
max_pooling3d (MaxPooling3D (None, 63, 63, 31, 64) 0
)
batch_normalization (BatchN (None, 63, 63, 31, 64) 256
ormalization)
conv3d_1 (Conv3D) (None, 61, 61, 29, 64) 110656
max_pooling3d_1 (MaxPooling (None, 30, 30, 14, 64) 0
3D)
batch_normalization_1 (Batc (None, 30, 30, 14, 64) 256
hNormalization)
conv3d_2 (Conv3D) (None, 28, 28, 12, 128) 221312
max_pooling3d_2 (MaxPooling (None, 14, 14, 6, 128) 0
3D)
batch_normalization_2 (Batc (None, 14, 14, 6, 128) 512
hNormalization)
conv3d_3 (Conv3D) (None, 12, 12, 4, 256) 884992
max_pooling3d_3 (MaxPooling (None, 6, 6, 2, 256) 0
3D)
batch_normalization_3 (Batc (None, 6, 6, 2, 256) 1024
hNormalization)
global_average_pooling3d (G (None, 256) 0
lobalAveragePooling3D)
dense (Dense) (None, 512) 131584
dropout (Dropout) (None, 512) 0
dense_1 (Dense) (None, 1) 513
=================================================================
Total params: 1,352,897
Trainable params: 1,351,873
Non-trainable params: 1,024
_________________________________________________________________
&lt;/code>&lt;/pre>
&lt;h2 id="model-training">Model training&lt;/h2>
&lt;p>The proposed model will be trained by default for 150 epochs in 4 different conditions:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Absent augmentation&lt;/strong>: all augmentation layers disabled&lt;/li>
&lt;li>&lt;strong>Basic augmentation&lt;/strong>: brightness and contrast layers enabled&lt;/li>
&lt;li>&lt;strong>Intermediate augmentation&lt;/strong>: brightness, contrast, rotation, flip and shift layers enabled&lt;/li>
&lt;li>&lt;strong>Advanced augmentation&lt;/strong>: all augmentation layers enabled&lt;/li>
&lt;/ul>
&lt;p>It is worth noting a &lt;strong>Checkpoint callback&lt;/strong> is also defined to automatically save the model in &lt;code>h5&lt;/code> format based on the validation Receiver Operating Characteristics Area Under Curve (ROC AUC) value. Please note the ROC AUC is preferred to the standard classification accuracy since the dataset is not balanced.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Default epochs number&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">EPOCHS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">150&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Callback&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">CHECKPOINT_CB&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">keras&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">callbacks&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ModelCheckpoint&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;ct-scan-brain-stroke-detection-&lt;/span>&lt;span class="si">{epoch:03d}&lt;/span>&lt;span class="s2">-&lt;/span>&lt;span class="si">{val_auc:.4f}&lt;/span>&lt;span class="s2">.h5&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">save_best_only&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">monitor&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;val_auc&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">mode&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;max&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Model training function&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">def&lt;/span> &lt;span class="nf">train_model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">training_dataset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">validation_dataset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">epochs&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">EPOCHS&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">callbacks&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">CHECKPOINT_CB&lt;/span>&lt;span class="p">]):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s2">&amp;#34;&amp;#34;&amp;#34;Train a model doing validation at the end of each epoch&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">history&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">fit&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">training_dataset&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">validation_data&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">validation_dataset&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">epochs&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">epochs&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">shuffle&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">verbose&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">callbacks&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">callbacks&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">history&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>An empty dictionary to store model metrics is also created to store all the metrics.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">performance&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="absent-augmentation">Absent augmentation&lt;/h3>
&lt;p>In this case the data augmentation is completely disabled. The model will be trained by using only the CT scans already available in the training dataset.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">build_model&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">performance&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;absent&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">train_model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">training_dataset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">validation_dataset&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="scrollable-output">
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> Epoch 1/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 27s 197ms/step - loss: 0.7002 - tp: 6.0000 - fp: 14.0000 - tn: 22.0000 - fn: 16.0000 - accuracy: 0.4828 - precision: 0.3000 - recall: 0.2727 - auc: 0.4236 - prc: 0.3796 - val_loss: 0.6891 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6741 - val_prc: 0.5665
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 2/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 170ms/step - loss: 0.6772 - tp: 9.0000 - fp: 7.0000 - tn: 29.0000 - fn: 13.0000 - accuracy: 0.6552 - precision: 0.5625 - recall: 0.4091 - auc: 0.5852 - prc: 0.4299 - val_loss: 0.6758 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6556 - val_prc: 0.6161
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 3/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 172ms/step - loss: 0.6412 - tp: 13.0000 - fp: 8.0000 - tn: 28.0000 - fn: 9.0000 - accuracy: 0.7069 - precision: 0.6190 - recall: 0.5909 - auc: 0.7184 - prc: 0.6360 - val_loss: 0.9218 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6111 - val_prc: 0.4476
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 4/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 171ms/step - loss: 0.6143 - tp: 10.0000 - fp: 5.0000 - tn: 31.0000 - fn: 12.0000 - accuracy: 0.7069 - precision: 0.6667 - recall: 0.4545 - auc: 0.7279 - prc: 0.6874 - val_loss: 0.7125 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6259 - val_prc: 0.5567
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 5/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 175ms/step - loss: 0.6074 - tp: 10.0000 - fp: 3.0000 - tn: 33.0000 - fn: 12.0000 - accuracy: 0.7414 - precision: 0.7692 - recall: 0.4545 - auc: 0.7330 - prc: 0.5813 - val_loss: 0.7482 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6519 - val_prc: 0.5625
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 6/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 173ms/step - loss: 0.6351 - tp: 8.0000 - fp: 7.0000 - tn: 29.0000 - fn: 14.0000 - accuracy: 0.6379 - precision: 0.5333 - recall: 0.3636 - auc: 0.6938 - prc: 0.5982 - val_loss: 1.2574 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6481 - val_prc: 0.6029
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 7/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 173ms/step - loss: 0.6018 - tp: 10.0000 - fp: 7.0000 - tn: 29.0000 - fn: 12.0000 - accuracy: 0.6724 - precision: 0.5882 - recall: 0.4545 - auc: 0.7551 - prc: 0.5616 - val_loss: 0.8819 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6556 - val_prc: 0.6027
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 8/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 174ms/step - loss: 0.5746 - tp: 14.0000 - fp: 7.0000 - tn: 29.0000 - fn: 8.0000 - accuracy: 0.7414 - precision: 0.6667 - recall: 0.6364 - auc: 0.7696 - prc: 0.6991 - val_loss: 1.0019 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5889 - val_prc: 0.5081
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 9/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 174ms/step - loss: 0.5749 - tp: 12.0000 - fp: 3.0000 - tn: 33.0000 - fn: 10.0000 - accuracy: 0.7759 - precision: 0.8000 - recall: 0.5455 - auc: 0.7254 - prc: 0.6337 - val_loss: 1.4884 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6111 - val_prc: 0.5376
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 10/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 187ms/step - loss: 0.5709 - tp: 10.0000 - fp: 7.0000 - tn: 29.0000 - fn: 12.0000 - accuracy: 0.6724 - precision: 0.5882 - recall: 0.4545 - auc: 0.7557 - prc: 0.6680 - val_loss: 1.6774 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6593 - val_prc: 0.6106
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 11/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.5601 - tp: 12.0000 - fp: 7.0000 - tn: 29.0000 - fn: 10.0000 - accuracy: 0.7069 - precision: 0.6316 - recall: 0.5455 - auc: 0.7670 - prc: 0.6901 - val_loss: 2.4892 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6519 - val_prc: 0.4787
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 12/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.5151 - tp: 14.0000 - fp: 5.0000 - tn: 31.0000 - fn: 8.0000 - accuracy: 0.7759 - precision: 0.7368 - recall: 0.6364 - auc: 0.8396 - prc: 0.7432 - val_loss: 2.5274 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6222 - val_prc: 0.4381
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 13/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.4865 - tp: 14.0000 - fp: 5.0000 - tn: 31.0000 - fn: 8.0000 - accuracy: 0.7759 - precision: 0.7368 - recall: 0.6364 - auc: 0.8396 - prc: 0.8283 - val_loss: 3.3881 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4667 - val_prc: 0.3570
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 14/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.4484 - tp: 15.0000 - fp: 2.0000 - tn: 34.0000 - fn: 7.0000 - accuracy: 0.8448 - precision: 0.8824 - recall: 0.6818 - auc: 0.9198 - prc: 0.8888 - val_loss: 1.4274 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5889 - val_prc: 0.5541
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 15/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 201ms/step - loss: 0.4467 - tp: 15.0000 - fp: 5.0000 - tn: 31.0000 - fn: 7.0000 - accuracy: 0.7931 - precision: 0.7500 - recall: 0.6818 - auc: 0.8946 - prc: 0.8335 - val_loss: 2.2831 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5889 - val_prc: 0.5586
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 16/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.3943 - tp: 16.0000 - fp: 2.0000 - tn: 34.0000 - fn: 6.0000 - accuracy: 0.8621 - precision: 0.8889 - recall: 0.7273 - auc: 0.9192 - prc: 0.8970 - val_loss: 5.1814 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.3750
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 17/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 201ms/step - loss: 0.3981 - tp: 18.0000 - fp: 4.0000 - tn: 32.0000 - fn: 4.0000 - accuracy: 0.8621 - precision: 0.8182 - recall: 0.8182 - auc: 0.9072 - prc: 0.8860 - val_loss: 4.0833 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.3750
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 18/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.2982 - tp: 21.0000 - fp: 5.0000 - tn: 31.0000 - fn: 1.0000 - accuracy: 0.8966 - precision: 0.8077 - recall: 0.9545 - auc: 0.9760 - prc: 0.9722 - val_loss: 1.5026 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5741 - val_prc: 0.5433
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 19/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.4235 - tp: 15.0000 - fp: 5.0000 - tn: 31.0000 - fn: 7.0000 - accuracy: 0.7931 - precision: 0.7500 - recall: 0.6818 - auc: 0.8832 - prc: 0.7512 - val_loss: 2.1605 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4963 - val_prc: 0.4582
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 20/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.4055 - tp: 16.0000 - fp: 4.0000 - tn: 32.0000 - fn: 6.0000 - accuracy: 0.8276 - precision: 0.8000 - recall: 0.7273 - auc: 0.9129 - prc: 0.8750 - val_loss: 1.7596 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6481 - val_prc: 0.5424
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 21/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.3645 - tp: 16.0000 - fp: 2.0000 - tn: 34.0000 - fn: 6.0000 - accuracy: 0.8621 - precision: 0.8889 - recall: 0.7273 - auc: 0.9280 - prc: 0.8974 - val_loss: 1.9915 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6370 - val_prc: 0.5410
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 22/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.2712 - tp: 19.0000 - fp: 3.0000 - tn: 33.0000 - fn: 3.0000 - accuracy: 0.8966 - precision: 0.8636 - recall: 0.8636 - auc: 0.9672 - prc: 0.9585 - val_loss: 0.8103 - val_tp: 4.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 5.0000 - val_accuracy: 0.4583 - val_precision: 0.3333 - val_recall: 0.4444 - val_auc: 0.5926 - val_prc: 0.5532
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 23/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 175ms/step - loss: 0.3840 - tp: 15.0000 - fp: 4.0000 - tn: 32.0000 - fn: 7.0000 - accuracy: 0.8103 - precision: 0.7895 - recall: 0.6818 - auc: 0.8832 - prc: 0.8661 - val_loss: 1.5774 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6185 - val_prc: 0.5903
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 24/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.3379 - tp: 19.0000 - fp: 6.0000 - tn: 30.0000 - fn: 3.0000 - accuracy: 0.8448 - precision: 0.7600 - recall: 0.8636 - auc: 0.9501 - prc: 0.9453 - val_loss: 0.8694 - val_tp: 6.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 3.0000 - val_accuracy: 0.5833 - val_precision: 0.4615 - val_recall: 0.6667 - val_auc: 0.6074 - val_prc: 0.5338
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 25/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 175ms/step - loss: 0.2800 - tp: 21.0000 - fp: 2.0000 - tn: 34.0000 - fn: 1.0000 - accuracy: 0.9483 - precision: 0.9130 - recall: 0.9545 - auc: 0.9811 - prc: 0.9720 - val_loss: 2.4292 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6370 - val_prc: 0.4767
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 26/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 203ms/step - loss: 0.4072 - tp: 16.0000 - fp: 7.0000 - tn: 29.0000 - fn: 6.0000 - accuracy: 0.7759 - precision: 0.6957 - recall: 0.7273 - auc: 0.8876 - prc: 0.8567 - val_loss: 1.6198 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.6815 - val_prc: 0.4556
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 27/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.3483 - tp: 15.0000 - fp: 1.0000 - tn: 35.0000 - fn: 7.0000 - accuracy: 0.8621 - precision: 0.9375 - recall: 0.6818 - auc: 0.9337 - prc: 0.9232 - val_loss: 2.2016 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6963 - val_prc: 0.6890
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 28/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.2698 - tp: 17.0000 - fp: 2.0000 - tn: 34.0000 - fn: 5.0000 - accuracy: 0.8793 - precision: 0.8947 - recall: 0.7727 - auc: 0.9747 - prc: 0.9634 - val_loss: 0.8487 - val_tp: 5.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 4.0000 - val_accuracy: 0.5833 - val_precision: 0.4545 - val_recall: 0.5556 - val_auc: 0.6444 - val_prc: 0.5897
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 29/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.4407 - tp: 15.0000 - fp: 6.0000 - tn: 30.0000 - fn: 7.0000 - accuracy: 0.7759 - precision: 0.7143 - recall: 0.6818 - auc: 0.8611 - prc: 0.8201 - val_loss: 0.8850 - val_tp: 3.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.7083 - val_precision: 0.7500 - val_recall: 0.3333 - val_auc: 0.6741 - val_prc: 0.5209
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 30/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.2629 - tp: 16.0000 - fp: 1.0000 - tn: 35.0000 - fn: 6.0000 - accuracy: 0.8793 - precision: 0.9412 - recall: 0.7273 - auc: 0.9760 - prc: 0.9617 - val_loss: 1.5557 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.6852 - val_prc: 0.5492
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 31/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 201ms/step - loss: 0.1817 - tp: 21.0000 - fp: 3.0000 - tn: 33.0000 - fn: 1.0000 - accuracy: 0.9310 - precision: 0.8750 - recall: 0.9545 - auc: 0.9931 - prc: 0.9889 - val_loss: 1.0616 - val_tp: 6.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 3.0000 - val_accuracy: 0.5000 - val_precision: 0.4000 - val_recall: 0.6667 - val_auc: 0.6778 - val_prc: 0.5999
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 32/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.2270 - tp: 18.0000 - fp: 2.0000 - tn: 34.0000 - fn: 4.0000 - accuracy: 0.8966 - precision: 0.9000 - recall: 0.8182 - auc: 0.9729 - prc: 0.9623 - val_loss: 1.7977 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6148 - val_prc: 0.4962
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 33/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.2288 - tp: 21.0000 - fp: 2.0000 - tn: 34.0000 - fn: 1.0000 - accuracy: 0.9483 - precision: 0.9130 - recall: 0.9545 - auc: 0.9874 - prc: 0.9798 - val_loss: 1.0614 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 2.0000 - val_accuracy: 0.5417 - val_precision: 0.4375 - val_recall: 0.7778 - val_auc: 0.6222 - val_prc: 0.5203
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 34/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.2219 - tp: 20.0000 - fp: 2.0000 - tn: 34.0000 - fn: 2.0000 - accuracy: 0.9310 - precision: 0.9091 - recall: 0.9091 - auc: 0.9785 - prc: 0.9716 - val_loss: 0.8000 - val_tp: 5.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 4.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.5556 - val_auc: 0.6667 - val_prc: 0.5838
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 35/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.3234 - tp: 15.0000 - fp: 2.0000 - tn: 34.0000 - fn: 7.0000 - accuracy: 0.8448 - precision: 0.8824 - recall: 0.6818 - auc: 0.9306 - prc: 0.9080 - val_loss: 2.3090 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5741 - val_prc: 0.4023
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 36/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.2608 - tp: 19.0000 - fp: 2.0000 - tn: 34.0000 - fn: 3.0000 - accuracy: 0.9138 - precision: 0.9048 - recall: 0.8636 - auc: 0.9697 - prc: 0.9545 - val_loss: 0.9518 - val_tp: 6.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 3.0000 - val_accuracy: 0.5833 - val_precision: 0.4615 - val_recall: 0.6667 - val_auc: 0.7037 - val_prc: 0.6025
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 37/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.2390 - tp: 18.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 4.0000 - accuracy: 0.9310 - precision: 1.0000 - recall: 0.8182 - auc: 0.9634 - prc: 0.9554 - val_loss: 0.8774 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.5630 - val_prc: 0.5661
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 38/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 199ms/step - loss: 0.0959 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.9335 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.5704 - val_prc: 0.5011
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 39/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 175ms/step - loss: 0.1951 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9962 - prc: 0.9936 - val_loss: 2.5183 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5889 - val_prc: 0.3990
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 40/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1823 - tp: 21.0000 - fp: 2.0000 - tn: 34.0000 - fn: 1.0000 - accuracy: 0.9483 - precision: 0.9130 - recall: 0.9545 - auc: 0.9848 - prc: 0.9738 - val_loss: 1.6855 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.6037 - val_prc: 0.6092
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 41/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 175ms/step - loss: 0.2639 - tp: 18.0000 - fp: 2.0000 - tn: 34.0000 - fn: 4.0000 - accuracy: 0.8966 - precision: 0.9000 - recall: 0.8182 - auc: 0.9653 - prc: 0.9454 - val_loss: 1.5368 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.6741 - val_prc: 0.5285
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 42/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 199ms/step - loss: 0.2371 - tp: 18.0000 - fp: 2.0000 - tn: 34.0000 - fn: 4.0000 - accuracy: 0.8966 - precision: 0.9000 - recall: 0.8182 - auc: 0.9823 - prc: 0.9715 - val_loss: 1.2670 - val_tp: 8.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 1.0000 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.8889 - val_auc: 0.6852 - val_prc: 0.4862
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 43/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1463 - tp: 21.0000 - fp: 3.0000 - tn: 33.0000 - fn: 1.0000 - accuracy: 0.9310 - precision: 0.8750 - recall: 0.9545 - auc: 0.9937 - prc: 0.9914 - val_loss: 4.2052 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5519 - val_prc: 0.4005
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 44/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.2017 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9912 - prc: 0.9866 - val_loss: 1.6621 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.6778 - val_prc: 0.6399
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 45/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.1629 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9899 - prc: 0.9856 - val_loss: 0.9936 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6630 - val_prc: 0.5719
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 46/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.2487 - tp: 17.0000 - fp: 1.0000 - tn: 35.0000 - fn: 5.0000 - accuracy: 0.8966 - precision: 0.9444 - recall: 0.7727 - auc: 0.9697 - prc: 0.9577 - val_loss: 0.9438 - val_tp: 4.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 5.0000 - val_accuracy: 0.5417 - val_precision: 0.4000 - val_recall: 0.4444 - val_auc: 0.6407 - val_prc: 0.5744
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 47/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.1986 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9899 - prc: 0.9856 - val_loss: 0.9540 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.6148 - val_prc: 0.5791
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 48/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1564 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9975 - prc: 0.9961 - val_loss: 1.5473 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.6926 - val_prc: 0.6765
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 49/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 200ms/step - loss: 0.1103 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6924 - val_tp: 7.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 2.0000 - val_accuracy: 0.4583 - val_precision: 0.3889 - val_recall: 0.7778 - val_auc: 0.6074 - val_prc: 0.4373
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 50/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.2040 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9747 - prc: 0.9741 - val_loss: 1.6458 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.6000 - val_prc: 0.4968
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 51/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1739 - tp: 20.0000 - fp: 2.0000 - tn: 34.0000 - fn: 2.0000 - accuracy: 0.9310 - precision: 0.9091 - recall: 0.9091 - auc: 0.9842 - prc: 0.9797 - val_loss: 2.3496 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6444 - val_prc: 0.4245
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 52/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.1342 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 0.9955 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.7296 - val_prc: 0.5711
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 53/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.0941 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 0.9987 - prc: 0.9980 - val_loss: 1.0994 - val_tp: 6.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 3.0000 - val_accuracy: 0.5417 - val_precision: 0.4286 - val_recall: 0.6667 - val_auc: 0.6667 - val_prc: 0.5371
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 54/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.1554 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9949 - prc: 0.9913 - val_loss: 0.9879 - val_tp: 5.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 4.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.5556 - val_auc: 0.7074 - val_prc: 0.5396
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 55/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 175ms/step - loss: 0.2241 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9665 - prc: 0.9654 - val_loss: 1.3689 - val_tp: 3.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.7083 - val_precision: 0.7500 - val_recall: 0.3333 - val_auc: 0.6667 - val_prc: 0.6136
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 56/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 199ms/step - loss: 0.1488 - tp: 20.0000 - fp: 2.0000 - tn: 34.0000 - fn: 2.0000 - accuracy: 0.9310 - precision: 0.9091 - recall: 0.9091 - auc: 0.9912 - prc: 0.9871 - val_loss: 1.0276 - val_tp: 5.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 4.0000 - val_accuracy: 0.5417 - val_precision: 0.4167 - val_recall: 0.5556 - val_auc: 0.7074 - val_prc: 0.5311
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 57/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1302 - tp: 21.0000 - fp: 2.0000 - tn: 34.0000 - fn: 1.0000 - accuracy: 0.9483 - precision: 0.9130 - recall: 0.9545 - auc: 0.9924 - prc: 0.9882 - val_loss: 1.4677 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.6667 - val_prc: 0.4548
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 58/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 199ms/step - loss: 0.0934 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 0.9975 - prc: 0.9959 - val_loss: 1.1227 - val_tp: 5.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 4.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.5556 - val_auc: 0.6519 - val_prc: 0.4788
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 59/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.0896 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 1.2691 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6704 - val_prc: 0.5122
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 60/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.0990 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.2702 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6593 - val_prc: 0.4669
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 61/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.1886 - tp: 17.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 5.0000 - accuracy: 0.9138 - precision: 1.0000 - recall: 0.7727 - auc: 0.9886 - prc: 0.9814 - val_loss: 1.4041 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.6037 - val_prc: 0.5516
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 62/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1292 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9912 - prc: 0.9880 - val_loss: 1.7597 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 8.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.1111 - val_auc: 0.5481 - val_prc: 0.4779
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 63/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 199ms/step - loss: 0.1297 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9949 - prc: 0.9929 - val_loss: 2.6302 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.6444 - val_prc: 0.6408
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 64/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1330 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9937 - prc: 0.9889 - val_loss: 1.0390 - val_tp: 4.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 5.0000 - val_accuracy: 0.5000 - val_precision: 0.3636 - val_recall: 0.4444 - val_auc: 0.6630 - val_prc: 0.4934
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 65/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1245 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9937 - prc: 0.9914 - val_loss: 1.0608 - val_tp: 5.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 4.0000 - val_accuracy: 0.6667 - val_precision: 0.5556 - val_recall: 0.5556 - val_auc: 0.6481 - val_prc: 0.5704
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 66/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.1628 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9716 - prc: 0.9752 - val_loss: 2.2087 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.6000 - val_prc: 0.6069
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 67/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1194 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9962 - prc: 0.9944 - val_loss: 4.2144 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5556 - val_prc: 0.5004
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 68/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0941 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6846 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.6222 - val_prc: 0.6412
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 69/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1476 - tp: 21.0000 - fp: 2.0000 - tn: 34.0000 - fn: 1.0000 - accuracy: 0.9483 - precision: 0.9130 - recall: 0.9545 - auc: 0.9949 - prc: 0.9923 - val_loss: 1.7396 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.6444 - val_prc: 0.5999
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 70/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1227 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9962 - prc: 0.9940 - val_loss: 2.6796 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6815 - val_prc: 0.4732
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 71/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0697 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.4592 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.7296 - val_prc: 0.5296
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 72/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.1266 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9924 - prc: 0.9901 - val_loss: 3.2876 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6407 - val_prc: 0.4582
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 73/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 175ms/step - loss: 0.1239 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9975 - prc: 0.9961 - val_loss: 2.2804 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.6185 - val_prc: 0.4414
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 74/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 199ms/step - loss: 0.2016 - tp: 19.0000 - fp: 2.0000 - tn: 34.0000 - fn: 3.0000 - accuracy: 0.9138 - precision: 0.9048 - recall: 0.8636 - auc: 0.9798 - prc: 0.9700 - val_loss: 1.2627 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.6963 - val_prc: 0.6087
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 75/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.1060 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 1.3861 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.6926 - val_prc: 0.6100
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 76/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 199ms/step - loss: 0.1422 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9886 - prc: 0.9816 - val_loss: 1.2345 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 6.0000 - val_accuracy: 0.5833 - val_precision: 0.4286 - val_recall: 0.3333 - val_auc: 0.6296 - val_prc: 0.5761
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 77/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.1297 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9912 - prc: 0.9866 - val_loss: 1.2191 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6556 - val_prc: 0.4480
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 78/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.0902 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.1026 - val_tp: 4.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 5.0000 - val_accuracy: 0.5417 - val_precision: 0.4000 - val_recall: 0.4444 - val_auc: 0.6667 - val_prc: 0.5737
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 79/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0901 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9987 - prc: 0.9980 - val_loss: 1.1582 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 7.0000 - val_accuracy: 0.5833 - val_precision: 0.4000 - val_recall: 0.2222 - val_auc: 0.6556 - val_prc: 0.5782
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 80/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.0799 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5908 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.6444 - val_prc: 0.4394
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 81/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0732 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.1505 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6667 - val_prc: 0.4678
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 82/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.0690 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.0628 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6926 - val_prc: 0.5508
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 83/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.0638 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 6.1388 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5667 - val_prc: 0.4091
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 84/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0597 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.2742 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.6519 - val_prc: 0.4380
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 85/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.0775 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.1804 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6704 - val_prc: 0.5004
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 86/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 175ms/step - loss: 0.0678 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.1592 - val_tp: 2.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 7.0000 - val_accuracy: 0.5000 - val_precision: 0.2857 - val_recall: 0.2222 - val_auc: 0.6407 - val_prc: 0.5148
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 87/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 198ms/step - loss: 0.1512 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9798 - prc: 0.9763 - val_loss: 2.1435 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.6296 - val_prc: 0.4175
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 88/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1141 - tp: 21.0000 - fp: 2.0000 - tn: 34.0000 - fn: 1.0000 - accuracy: 0.9483 - precision: 0.9130 - recall: 0.9545 - auc: 0.9949 - prc: 0.9929 - val_loss: 2.9144 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6111 - val_prc: 0.5895
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 89/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.1031 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.3662 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.5630 - val_prc: 0.5318
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 90/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 200ms/step - loss: 0.2066 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9659 - prc: 0.9595 - val_loss: 1.1912 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.6741 - val_prc: 0.6291
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 91/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.1104 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9962 - prc: 0.9944 - val_loss: 1.2353 - val_tp: 7.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 2.0000 - val_accuracy: 0.7083 - val_precision: 0.5833 - val_recall: 0.7778 - val_auc: 0.6370 - val_prc: 0.5101
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 92/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0842 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9975 - prc: 0.9961 - val_loss: 1.3635 - val_tp: 7.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 2.0000 - val_accuracy: 0.6667 - val_precision: 0.5385 - val_recall: 0.7778 - val_auc: 0.6444 - val_prc: 0.4446
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 93/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.0366 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3471 - val_tp: 6.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 3.0000 - val_accuracy: 0.5833 - val_precision: 0.4615 - val_recall: 0.6667 - val_auc: 0.6481 - val_prc: 0.4888
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 94/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0423 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.1969 - val_tp: 5.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 4.0000 - val_accuracy: 0.5833 - val_precision: 0.4545 - val_recall: 0.5556 - val_auc: 0.6704 - val_prc: 0.5168
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 95/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0497 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.7935 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.5667 - val_prc: 0.5603
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 96/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.1108 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9962 - prc: 0.9936 - val_loss: 1.2713 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 6.0000 - val_accuracy: 0.5833 - val_precision: 0.4286 - val_recall: 0.3333 - val_auc: 0.6741 - val_prc: 0.5315
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 97/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.1410 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9855 - prc: 0.9805 - val_loss: 1.8814 - val_tp: 3.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.7083 - val_precision: 0.7500 - val_recall: 0.3333 - val_auc: 0.5667 - val_prc: 0.5949
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 98/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.1199 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9937 - prc: 0.9895 - val_loss: 1.6763 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6407 - val_prc: 0.4256
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 99/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0804 - tp: 22.0000 - fp: 2.0000 - tn: 34.0000 - fn: 0.0000e+00 - accuracy: 0.9655 - precision: 0.9167 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4800 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.5667 - val_prc: 0.4307
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 100/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.1267 - tp: 21.0000 - fp: 2.0000 - tn: 34.0000 - fn: 1.0000 - accuracy: 0.9483 - precision: 0.9130 - recall: 0.9545 - auc: 0.9899 - prc: 0.9838 - val_loss: 1.5902 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 7.0000 - val_accuracy: 0.5833 - val_precision: 0.4000 - val_recall: 0.2222 - val_auc: 0.6074 - val_prc: 0.4193
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 101/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0394 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5032 - val_tp: 4.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 5.0000 - val_accuracy: 0.5833 - val_precision: 0.4444 - val_recall: 0.4444 - val_auc: 0.6778 - val_prc: 0.4642
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 102/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0717 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3194 - val_tp: 5.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 4.0000 - val_accuracy: 0.5833 - val_precision: 0.4545 - val_recall: 0.5556 - val_auc: 0.6667 - val_prc: 0.4895
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 103/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0620 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9994 - prc: 0.9990 - val_loss: 1.3006 - val_tp: 4.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 5.0000 - val_accuracy: 0.5833 - val_precision: 0.4444 - val_recall: 0.4444 - val_auc: 0.6370 - val_prc: 0.4972
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 104/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 201ms/step - loss: 0.0364 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.2496 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.6519 - val_prc: 0.5683
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 105/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 175ms/step - loss: 0.0381 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5330 - val_tp: 6.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 3.0000 - val_accuracy: 0.5417 - val_precision: 0.4286 - val_recall: 0.6667 - val_auc: 0.6556 - val_prc: 0.4690
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 106/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.0475 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.8588 - val_tp: 9.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6667 - val_precision: 0.5294 - val_recall: 1.0000 - val_auc: 0.6370 - val_prc: 0.4340
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 107/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 201ms/step - loss: 0.0497 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6444 - val_tp: 8.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 1.0000 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.8889 - val_auc: 0.6481 - val_prc: 0.4369
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 108/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.0306 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5228 - val_tp: 5.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 4.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.5556 - val_auc: 0.6815 - val_prc: 0.4597
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 109/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0238 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5728 - val_tp: 6.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 3.0000 - val_accuracy: 0.5833 - val_precision: 0.4615 - val_recall: 0.6667 - val_auc: 0.6889 - val_prc: 0.4670
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 110/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0216 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.3391 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7148 - val_prc: 0.5073
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 111/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0164 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6520 - val_tp: 8.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 1.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.8889 - val_auc: 0.6593 - val_prc: 0.4373
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 112/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0236 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3961 - val_tp: 5.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 4.0000 - val_accuracy: 0.5833 - val_precision: 0.4545 - val_recall: 0.5556 - val_auc: 0.7000 - val_prc: 0.5038
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 113/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 202ms/step - loss: 0.0113 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.9034 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 2.0000 - val_accuracy: 0.5417 - val_precision: 0.4375 - val_recall: 0.7778 - val_auc: 0.6667 - val_prc: 0.4808
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 114/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0524 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5860 - val_tp: 4.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 5.0000 - val_accuracy: 0.5833 - val_precision: 0.4444 - val_recall: 0.4444 - val_auc: 0.6370 - val_prc: 0.4572
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 115/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 201ms/step - loss: 0.0723 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9975 - prc: 0.9959 - val_loss: 4.4519 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6111 - val_prc: 0.5895
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 116/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0839 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6600 - val_tp: 4.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 5.0000 - val_accuracy: 0.5833 - val_precision: 0.4444 - val_recall: 0.4444 - val_auc: 0.6370 - val_prc: 0.5225
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 117/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.1030 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9861 - prc: 0.9846 - val_loss: 2.1225 - val_tp: 9.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6667 - val_precision: 0.5294 - val_recall: 1.0000 - val_auc: 0.6519 - val_prc: 0.4370
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 118/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0572 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 0.9987 - prc: 0.9980 - val_loss: 2.9734 - val_tp: 8.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4211 - val_recall: 0.8889 - val_auc: 0.5000 - val_prc: 0.3483
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 119/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.0498 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.0978 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 7.0000 - val_accuracy: 0.5833 - val_precision: 0.4000 - val_recall: 0.2222 - val_auc: 0.6407 - val_prc: 0.5501
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 120/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 200ms/step - loss: 0.0777 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9962 - prc: 0.9944 - val_loss: 3.4611 - val_tp: 6.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 3.0000 - val_accuracy: 0.4167 - val_precision: 0.3529 - val_recall: 0.6667 - val_auc: 0.4259 - val_prc: 0.3369
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 121/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 175ms/step - loss: 0.0966 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 0.9949 - prc: 0.9913 - val_loss: 1.6355 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.6481 - val_prc: 0.4467
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 122/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 175ms/step - loss: 0.0975 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9924 - prc: 0.9901 - val_loss: 5.3627 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6667 - val_prc: 0.4737
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 123/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.0575 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4247 - val_tp: 7.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.7778 - val_auc: 0.6296 - val_prc: 0.4429
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 124/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 202ms/step - loss: 0.0508 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4254 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 6.0000 - val_accuracy: 0.5833 - val_precision: 0.4286 - val_recall: 0.3333 - val_auc: 0.5074 - val_prc: 0.4519
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 125/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 201ms/step - loss: 0.0282 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4721 - val_tp: 3.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 6.0000 - val_accuracy: 0.5000 - val_precision: 0.3333 - val_recall: 0.3333 - val_auc: 0.6148 - val_prc: 0.5433
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 126/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0435 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5210 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.6630 - val_prc: 0.5017
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 127/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.0587 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3495 - val_tp: 3.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 6.0000 - val_accuracy: 0.5417 - val_precision: 0.3750 - val_recall: 0.3333 - val_auc: 0.6741 - val_prc: 0.5087
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 128/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0341 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.7384 - val_tp: 7.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 2.0000 - val_accuracy: 0.5833 - val_precision: 0.4667 - val_recall: 0.7778 - val_auc: 0.6000 - val_prc: 0.4126
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 129/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0354 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5934 - val_tp: 8.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 1.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.8889 - val_auc: 0.6370 - val_prc: 0.4527
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 130/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0356 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6407 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 6.0000 - val_accuracy: 0.5833 - val_precision: 0.4286 - val_recall: 0.3333 - val_auc: 0.5963 - val_prc: 0.4800
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 131/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.0248 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.9388 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.6037 - val_prc: 0.5653
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 132/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0358 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6263 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.6370 - val_prc: 0.4450
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 133/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.0149 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.7919 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 6.0000 - val_accuracy: 0.5833 - val_precision: 0.4286 - val_recall: 0.3333 - val_auc: 0.6037 - val_prc: 0.5565
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 134/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0399 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.3672 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.6111 - val_prc: 0.5895
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 135/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.0111 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.8030 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.6111 - val_prc: 0.5895
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 136/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0055 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.9866 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.6407 - val_prc: 0.6022
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 137/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.0820 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9975 - prc: 0.9959 - val_loss: 1.8939 - val_tp: 8.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 1.0000 - val_accuracy: 0.7083 - val_precision: 0.5714 - val_recall: 0.8889 - val_auc: 0.7185 - val_prc: 0.4880
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 138/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.0297 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5812 - val_tp: 5.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 4.0000 - val_accuracy: 0.5417 - val_precision: 0.4167 - val_recall: 0.5556 - val_auc: 0.6296 - val_prc: 0.4863
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 139/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 201ms/step - loss: 0.0379 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4258 - val_tp: 5.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 4.0000 - val_accuracy: 0.5833 - val_precision: 0.4545 - val_recall: 0.5556 - val_auc: 0.5815 - val_prc: 0.4501
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 140/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0119 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3512 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 5.0000 - val_accuracy: 0.6667 - val_precision: 0.5714 - val_recall: 0.4444 - val_auc: 0.7000 - val_prc: 0.6010
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 141/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0464 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3362 - val_tp: 4.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 5.0000 - val_accuracy: 0.5417 - val_precision: 0.4000 - val_recall: 0.4444 - val_auc: 0.6593 - val_prc: 0.5819
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 142/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 202ms/step - loss: 0.0424 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4989 - val_tp: 8.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 1.0000 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.8889 - val_auc: 0.6556 - val_prc: 0.5460
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 143/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.0245 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.9789 - val_tp: 7.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.7778 - val_auc: 0.6185 - val_prc: 0.4106
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 144/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0889 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9949 - prc: 0.9929 - val_loss: 2.0951 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.6333 - val_prc: 0.4392
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 145/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0748 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.1505 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 3.0000 - val_accuracy: 0.3750 - val_precision: 0.3333 - val_recall: 0.6667 - val_auc: 0.4259 - val_prc: 0.3118
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 146/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.0888 - tp: 22.0000 - fp: 2.0000 - tn: 34.0000 - fn: 0.0000e+00 - accuracy: 0.9655 - precision: 0.9167 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3046 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 5.0000 - val_accuracy: 0.6667 - val_precision: 0.5714 - val_recall: 0.4444 - val_auc: 0.6481 - val_prc: 0.6198
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 147/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 202ms/step - loss: 0.1112 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9924 - prc: 0.9870 - val_loss: 3.0559 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5778 - val_prc: 0.5134
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 148/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1741 - tp: 18.0000 - fp: 2.0000 - tn: 34.0000 - fn: 4.0000 - accuracy: 0.8966 - precision: 0.9000 - recall: 0.8182 - auc: 0.9804 - prc: 0.9692 - val_loss: 2.1499 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 6.0000 - val_accuracy: 0.6667 - val_precision: 0.6000 - val_recall: 0.3333 - val_auc: 0.5815 - val_prc: 0.5663
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 149/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.1287 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9785 - prc: 0.9799 - val_loss: 2.6137 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.5926 - val_prc: 0.5749
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 150/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 203ms/step - loss: 0.0795 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4128 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 6.0000 - val_accuracy: 0.5833 - val_precision: 0.4286 - val_recall: 0.3333 - val_auc: 0.6593 - val_prc: 0.5844
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/div>
&lt;h3 id="basic-augmentation">Basic augmentation&lt;/h3>
&lt;p>The basic augmentation is very light since it just enables the brightness and contrast layers. The expected results are not much better with respect to the previous case.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">build_model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">augmentation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">rotation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">flip&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">shift&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">zoom&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">shear&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">brightness&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">contrast&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">performance&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;basic&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">train_model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">training_dataset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">validation_dataset&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="scrollable-output">
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> Epoch 1/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 10s 199ms/step - loss: 0.6830 - tp: 12.0000 - fp: 12.0000 - tn: 39.0000 - fn: 19.0000 - accuracy: 0.6220 - precision: 0.5000 - recall: 0.3871 - auc: 0.5569 - prc: 0.4748 - val_loss: 0.6913 - val_tp: 5.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 4.0000 - val_accuracy: 0.5833 - val_precision: 0.4545 - val_recall: 0.5556 - val_auc: 0.6296 - val_prc: 0.4677
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 2/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.6188 - tp: 10.0000 - fp: 4.0000 - tn: 32.0000 - fn: 12.0000 - accuracy: 0.7241 - precision: 0.7143 - recall: 0.4545 - auc: 0.7664 - prc: 0.7183 - val_loss: 0.7491 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6000 - val_prc: 0.5361
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 3/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.6501 - tp: 9.0000 - fp: 7.0000 - tn: 29.0000 - fn: 13.0000 - accuracy: 0.6552 - precision: 0.5625 - recall: 0.4091 - auc: 0.6237 - prc: 0.5183 - val_loss: 0.7112 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6222 - val_prc: 0.5844
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 4/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.5945 - tp: 12.0000 - fp: 5.0000 - tn: 31.0000 - fn: 10.0000 - accuracy: 0.7414 - precision: 0.7059 - recall: 0.5455 - auc: 0.7311 - prc: 0.6222 - val_loss: 0.8578 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5963 - val_prc: 0.5271
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 5/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6198 - tp: 4.0000 - fp: 2.0000 - tn: 34.0000 - fn: 18.0000 - accuracy: 0.6552 - precision: 0.6667 - recall: 0.1818 - auc: 0.6913 - prc: 0.6345 - val_loss: 0.6775 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6000 - val_prc: 0.5625
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 6/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.5820 - tp: 10.0000 - fp: 4.0000 - tn: 32.0000 - fn: 12.0000 - accuracy: 0.7241 - precision: 0.7143 - recall: 0.4545 - auc: 0.7620 - prc: 0.7166 - val_loss: 0.9705 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5963 - val_prc: 0.5628
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 7/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.5588 - tp: 10.0000 - fp: 4.0000 - tn: 32.0000 - fn: 12.0000 - accuracy: 0.7241 - precision: 0.7143 - recall: 0.4545 - auc: 0.7519 - prc: 0.7334 - val_loss: 1.0259 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5778 - val_prc: 0.5460
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 8/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.5384 - tp: 15.0000 - fp: 6.0000 - tn: 30.0000 - fn: 7.0000 - accuracy: 0.7759 - precision: 0.7143 - recall: 0.6818 - auc: 0.8030 - prc: 0.7375 - val_loss: 3.4091 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5333 - val_prc: 0.3913
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 9/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.5811 - tp: 12.0000 - fp: 12.0000 - tn: 24.0000 - fn: 10.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.5455 - auc: 0.7273 - prc: 0.6568 - val_loss: 0.8861 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5778 - val_prc: 0.5455
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 10/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 200ms/step - loss: 0.5691 - tp: 9.0000 - fp: 6.0000 - tn: 30.0000 - fn: 13.0000 - accuracy: 0.6724 - precision: 0.6000 - recall: 0.4091 - auc: 0.7727 - prc: 0.6987 - val_loss: 1.1090 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4630 - val_prc: 0.4555
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 11/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 175ms/step - loss: 0.6058 - tp: 11.0000 - fp: 8.0000 - tn: 28.0000 - fn: 11.0000 - accuracy: 0.6724 - precision: 0.5789 - recall: 0.5000 - auc: 0.7279 - prc: 0.6410 - val_loss: 2.1531 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6296 - val_prc: 0.5617
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 12/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.5140 - tp: 15.0000 - fp: 5.0000 - tn: 31.0000 - fn: 7.0000 - accuracy: 0.7931 - precision: 0.7500 - recall: 0.6818 - auc: 0.8220 - prc: 0.7629 - val_loss: 2.8898 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4556 - val_prc: 0.3475
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 13/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.4759 - tp: 14.0000 - fp: 2.0000 - tn: 34.0000 - fn: 8.0000 - accuracy: 0.8276 - precision: 0.8750 - recall: 0.6364 - auc: 0.8693 - prc: 0.8204 - val_loss: 1.1536 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5667 - val_prc: 0.5347
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 14/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.4612 - tp: 16.0000 - fp: 5.0000 - tn: 31.0000 - fn: 6.0000 - accuracy: 0.8103 - precision: 0.7619 - recall: 0.7273 - auc: 0.8668 - prc: 0.8601 - val_loss: 4.0509 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.3750
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 15/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.5514 - tp: 13.0000 - fp: 11.0000 - tn: 25.0000 - fn: 9.0000 - accuracy: 0.6552 - precision: 0.5417 - recall: 0.5909 - auc: 0.7734 - prc: 0.6824 - val_loss: 2.7095 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4815 - val_prc: 0.4583
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 16/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.5104 - tp: 15.0000 - fp: 6.0000 - tn: 30.0000 - fn: 7.0000 - accuracy: 0.7759 - precision: 0.7143 - recall: 0.6818 - auc: 0.8378 - prc: 0.7721 - val_loss: 3.3760 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6111 - val_prc: 0.4402
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 17/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.4790 - tp: 16.0000 - fp: 5.0000 - tn: 31.0000 - fn: 6.0000 - accuracy: 0.8103 - precision: 0.7619 - recall: 0.7273 - auc: 0.8422 - prc: 0.7598 - val_loss: 0.7231 - val_tp: 5.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 4.0000 - val_accuracy: 0.4583 - val_precision: 0.3571 - val_recall: 0.5556 - val_auc: 0.4778 - val_prc: 0.5576
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 18/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.4418 - tp: 15.0000 - fp: 5.0000 - tn: 31.0000 - fn: 7.0000 - accuracy: 0.7931 - precision: 0.7500 - recall: 0.6818 - auc: 0.8908 - prc: 0.8472 - val_loss: 0.8642 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.5148 - val_prc: 0.5184
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 19/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.4891 - tp: 10.0000 - fp: 1.0000 - tn: 35.0000 - fn: 12.0000 - accuracy: 0.7759 - precision: 0.9091 - recall: 0.4545 - auc: 0.8422 - prc: 0.8125 - val_loss: 1.3278 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5259 - val_prc: 0.5516
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 20/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.4552 - tp: 13.0000 - fp: 3.0000 - tn: 33.0000 - fn: 9.0000 - accuracy: 0.7931 - precision: 0.8125 - recall: 0.5909 - auc: 0.8586 - prc: 0.8386 - val_loss: 2.7479 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4778 - val_prc: 0.4492
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 21/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.3782 - tp: 16.0000 - fp: 3.0000 - tn: 33.0000 - fn: 6.0000 - accuracy: 0.8448 - precision: 0.8421 - recall: 0.7273 - auc: 0.9318 - prc: 0.9067 - val_loss: 1.4158 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6074 - val_prc: 0.5685
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 22/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.4321 - tp: 15.0000 - fp: 4.0000 - tn: 32.0000 - fn: 7.0000 - accuracy: 0.8103 - precision: 0.7895 - recall: 0.6818 - auc: 0.8643 - prc: 0.8522 - val_loss: 3.3259 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6111 - val_prc: 0.4476
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 23/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.3929 - tp: 16.0000 - fp: 4.0000 - tn: 32.0000 - fn: 6.0000 - accuracy: 0.8276 - precision: 0.8000 - recall: 0.7273 - auc: 0.9015 - prc: 0.8851 - val_loss: 1.3029 - val_tp: 8.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 1.0000 - val_accuracy: 0.3333 - val_precision: 0.3478 - val_recall: 0.8889 - val_auc: 0.4593 - val_prc: 0.5056
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 24/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.4009 - tp: 16.0000 - fp: 4.0000 - tn: 32.0000 - fn: 6.0000 - accuracy: 0.8276 - precision: 0.8000 - recall: 0.7273 - auc: 0.9040 - prc: 0.8784 - val_loss: 2.6127 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5630 - val_prc: 0.4837
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 25/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 201ms/step - loss: 0.3749 - tp: 17.0000 - fp: 4.0000 - tn: 32.0000 - fn: 5.0000 - accuracy: 0.8448 - precision: 0.8095 - recall: 0.7727 - auc: 0.9129 - prc: 0.9011 - val_loss: 1.5429 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4852 - val_prc: 0.5009
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 26/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.3584 - tp: 15.0000 - fp: 2.0000 - tn: 34.0000 - fn: 7.0000 - accuracy: 0.8448 - precision: 0.8824 - recall: 0.6818 - auc: 0.9236 - prc: 0.8998 - val_loss: 1.2788 - val_tp: 8.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4167 - val_precision: 0.3810 - val_recall: 0.8889 - val_auc: 0.5074 - val_prc: 0.5531
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 27/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 199ms/step - loss: 0.3122 - tp: 19.0000 - fp: 2.0000 - tn: 34.0000 - fn: 3.0000 - accuracy: 0.9138 - precision: 0.9048 - recall: 0.8636 - auc: 0.9665 - prc: 0.9604 - val_loss: 1.8011 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4963 - val_prc: 0.5184
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 28/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 175ms/step - loss: 0.4442 - tp: 15.0000 - fp: 3.0000 - tn: 33.0000 - fn: 7.0000 - accuracy: 0.8276 - precision: 0.8333 - recall: 0.6818 - auc: 0.8567 - prc: 0.8369 - val_loss: 1.3424 - val_tp: 8.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 1.0000 - val_accuracy: 0.3333 - val_precision: 0.3478 - val_recall: 0.8889 - val_auc: 0.4852 - val_prc: 0.4913
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 29/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.3409 - tp: 17.0000 - fp: 2.0000 - tn: 34.0000 - fn: 5.0000 - accuracy: 0.8793 - precision: 0.8947 - recall: 0.7727 - auc: 0.9362 - prc: 0.9189 - val_loss: 2.1606 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5037 - val_prc: 0.5351
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 30/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.3147 - tp: 17.0000 - fp: 3.0000 - tn: 33.0000 - fn: 5.0000 - accuracy: 0.8621 - precision: 0.8500 - recall: 0.7727 - auc: 0.9438 - prc: 0.9278 - val_loss: 1.0792 - val_tp: 8.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4211 - val_recall: 0.8889 - val_auc: 0.5889 - val_prc: 0.5584
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 31/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.3214 - tp: 17.0000 - fp: 4.0000 - tn: 32.0000 - fn: 5.0000 - accuracy: 0.8448 - precision: 0.8095 - recall: 0.7727 - auc: 0.9343 - prc: 0.9314 - val_loss: 3.0873 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6741 - val_prc: 0.4884
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 32/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.3385 - tp: 19.0000 - fp: 4.0000 - tn: 32.0000 - fn: 3.0000 - accuracy: 0.8793 - precision: 0.8261 - recall: 0.8636 - auc: 0.9476 - prc: 0.9213 - val_loss: 1.8834 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6519 - val_prc: 0.4720
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 33/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.2997 - tp: 18.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 4.0000 - accuracy: 0.9310 - precision: 1.0000 - recall: 0.8182 - auc: 0.9583 - prc: 0.9510 - val_loss: 1.0953 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.6111 - val_prc: 0.5667
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 34/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.2365 - tp: 18.0000 - fp: 2.0000 - tn: 34.0000 - fn: 4.0000 - accuracy: 0.8966 - precision: 0.9000 - recall: 0.8182 - auc: 0.9779 - prc: 0.9683 - val_loss: 1.1344 - val_tp: 6.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 3.0000 - val_accuracy: 0.3333 - val_precision: 0.3158 - val_recall: 0.6667 - val_auc: 0.5148 - val_prc: 0.5397
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 35/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.1734 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9899 - prc: 0.9856 - val_loss: 2.4849 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5296 - val_prc: 0.3963
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 36/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.2748 - tp: 17.0000 - fp: 1.0000 - tn: 35.0000 - fn: 5.0000 - accuracy: 0.8966 - precision: 0.9444 - recall: 0.7727 - auc: 0.9729 - prc: 0.9567 - val_loss: 2.0846 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5704 - val_prc: 0.4378
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 37/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.2393 - tp: 18.0000 - fp: 2.0000 - tn: 34.0000 - fn: 4.0000 - accuracy: 0.8966 - precision: 0.9000 - recall: 0.8182 - auc: 0.9792 - prc: 0.9694 - val_loss: 1.2777 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7074 - val_prc: 0.5293
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 38/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 201ms/step - loss: 0.1857 - tp: 20.0000 - fp: 2.0000 - tn: 34.0000 - fn: 2.0000 - accuracy: 0.9310 - precision: 0.9091 - recall: 0.9091 - auc: 0.9937 - prc: 0.9899 - val_loss: 1.1879 - val_tp: 8.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4167 - val_precision: 0.3810 - val_recall: 0.8889 - val_auc: 0.6037 - val_prc: 0.5722
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 39/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.1526 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9994 - prc: 0.9990 - val_loss: 1.7134 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6037 - val_prc: 0.5734
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 40/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.2425 - tp: 18.0000 - fp: 3.0000 - tn: 33.0000 - fn: 4.0000 - accuracy: 0.8793 - precision: 0.8571 - recall: 0.8182 - auc: 0.9646 - prc: 0.9552 - val_loss: 1.0025 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.5741 - val_prc: 0.5739
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 41/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.2049 - tp: 19.0000 - fp: 2.0000 - tn: 34.0000 - fn: 3.0000 - accuracy: 0.9138 - precision: 0.9048 - recall: 0.8636 - auc: 0.9867 - prc: 0.9788 - val_loss: 0.7786 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.6185 - val_prc: 0.5937
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 42/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.2102 - tp: 18.0000 - fp: 1.0000 - tn: 35.0000 - fn: 4.0000 - accuracy: 0.9138 - precision: 0.9474 - recall: 0.8182 - auc: 0.9697 - prc: 0.9607 - val_loss: 3.9611 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5556 - val_prc: 0.4016
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 43/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.2055 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9804 - prc: 0.9729 - val_loss: 0.8082 - val_tp: 7.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 2.0000 - val_accuracy: 0.7083 - val_precision: 0.5833 - val_recall: 0.7778 - val_auc: 0.6815 - val_prc: 0.6163
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 44/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.2180 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9880 - prc: 0.9789 - val_loss: 2.1966 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.4178
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 45/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.2158 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9760 - prc: 0.9684 - val_loss: 2.3301 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6444 - val_prc: 0.5369
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 46/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.1186 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 2.6398 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6370 - val_prc: 0.4977
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 47/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.2241 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9893 - prc: 0.9840 - val_loss: 0.9055 - val_tp: 3.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.7083 - val_precision: 0.7500 - val_recall: 0.3333 - val_auc: 0.5889 - val_prc: 0.5996
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 48/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 200ms/step - loss: 0.2135 - tp: 21.0000 - fp: 4.0000 - tn: 32.0000 - fn: 1.0000 - accuracy: 0.9138 - precision: 0.8400 - recall: 0.9545 - auc: 0.9798 - prc: 0.9763 - val_loss: 1.1924 - val_tp: 8.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 1.0000 - val_accuracy: 0.4583 - val_precision: 0.4000 - val_recall: 0.8889 - val_auc: 0.6815 - val_prc: 0.6382
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 49/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1642 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9975 - prc: 0.9959 - val_loss: 1.0873 - val_tp: 6.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 3.0000 - val_accuracy: 0.5000 - val_precision: 0.4000 - val_recall: 0.6667 - val_auc: 0.5926 - val_prc: 0.5676
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 50/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1233 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 2.4068 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6037 - val_prc: 0.4214
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 51/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.0946 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.2321 - val_tp: 8.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4211 - val_recall: 0.8889 - val_auc: 0.6593 - val_prc: 0.6299
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 52/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.1450 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9912 - prc: 0.9864 - val_loss: 3.7010 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6926 - val_prc: 0.4969
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 53/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 202ms/step - loss: 0.2643 - tp: 16.0000 - fp: 3.0000 - tn: 33.0000 - fn: 6.0000 - accuracy: 0.8448 - precision: 0.8421 - recall: 0.7273 - auc: 0.9571 - prc: 0.9395 - val_loss: 1.5267 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6296 - val_prc: 0.4843
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 54/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.2133 - tp: 21.0000 - fp: 3.0000 - tn: 33.0000 - fn: 1.0000 - accuracy: 0.9310 - precision: 0.8750 - recall: 0.9545 - auc: 0.9823 - prc: 0.9808 - val_loss: 1.6550 - val_tp: 5.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 4.0000 - val_accuracy: 0.2500 - val_precision: 0.2632 - val_recall: 0.5556 - val_auc: 0.4259 - val_prc: 0.4297
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 55/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.1688 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9975 - prc: 0.9961 - val_loss: 0.9434 - val_tp: 5.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 4.0000 - val_accuracy: 0.5417 - val_precision: 0.4167 - val_recall: 0.5556 - val_auc: 0.5926 - val_prc: 0.5287
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 56/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.1485 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9924 - prc: 0.9893 - val_loss: 1.1409 - val_tp: 7.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 2.0000 - val_accuracy: 0.5000 - val_precision: 0.4118 - val_recall: 0.7778 - val_auc: 0.6370 - val_prc: 0.5996
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 57/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.1526 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 0.9962 - prc: 0.9936 - val_loss: 2.1477 - val_tp: 8.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4167 - val_precision: 0.3810 - val_recall: 0.8889 - val_auc: 0.5704 - val_prc: 0.4882
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 58/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 200ms/step - loss: 0.1417 - tp: 20.0000 - fp: 2.0000 - tn: 34.0000 - fn: 2.0000 - accuracy: 0.9310 - precision: 0.9091 - recall: 0.9091 - auc: 0.9924 - prc: 0.9888 - val_loss: 1.6656 - val_tp: 7.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 2.0000 - val_accuracy: 0.3333 - val_precision: 0.3333 - val_recall: 0.7778 - val_auc: 0.5259 - val_prc: 0.5352
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 59/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.2337 - tp: 16.0000 - fp: 1.0000 - tn: 35.0000 - fn: 6.0000 - accuracy: 0.8793 - precision: 0.9412 - recall: 0.7273 - auc: 0.9672 - prc: 0.9556 - val_loss: 2.4534 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6370 - val_prc: 0.4575
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 60/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1521 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9912 - prc: 0.9864 - val_loss: 3.3470 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6296 - val_prc: 0.4461
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 61/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 176ms/step - loss: 0.1245 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9924 - prc: 0.9893 - val_loss: 1.4928 - val_tp: 8.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.5417 - val_precision: 0.4444 - val_recall: 0.8889 - val_auc: 0.6444 - val_prc: 0.5180
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 62/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 203ms/step - loss: 0.1665 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9937 - prc: 0.9889 - val_loss: 2.6169 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5852 - val_prc: 0.4785
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 63/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0910 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.0362 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5481 - val_prc: 0.4198
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 64/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 203ms/step - loss: 0.1491 - tp: 18.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 4.0000 - accuracy: 0.9310 - precision: 1.0000 - recall: 0.8182 - auc: 0.9918 - prc: 0.9882 - val_loss: 3.3631 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6259 - val_prc: 0.4418
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 65/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0948 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9962 - prc: 0.9940 - val_loss: 1.4223 - val_tp: 7.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 2.0000 - val_accuracy: 0.4583 - val_precision: 0.3889 - val_recall: 0.7778 - val_auc: 0.6259 - val_prc: 0.6189
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 66/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0844 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.5829 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5556 - val_prc: 0.4016
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 67/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.1120 - tp: 20.0000 - fp: 2.0000 - tn: 34.0000 - fn: 2.0000 - accuracy: 0.9310 - precision: 0.9091 - recall: 0.9091 - auc: 0.9937 - prc: 0.9904 - val_loss: 3.1984 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4889 - val_prc: 0.3933
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 68/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 201ms/step - loss: 0.2126 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 0.9646 - prc: 0.9588 - val_loss: 5.4056 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6000 - val_prc: 0.4286
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 69/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.2655 - tp: 16.0000 - fp: 2.0000 - tn: 34.0000 - fn: 6.0000 - accuracy: 0.8621 - precision: 0.8889 - recall: 0.7273 - auc: 0.9628 - prc: 0.9417 - val_loss: 1.1726 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 3.0000 - val_accuracy: 0.3750 - val_precision: 0.3333 - val_recall: 0.6667 - val_auc: 0.5704 - val_prc: 0.5607
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 70/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.1365 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9937 - prc: 0.9904 - val_loss: 3.3981 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5370 - val_prc: 0.3859
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 71/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.1574 - tp: 20.0000 - fp: 2.0000 - tn: 34.0000 - fn: 2.0000 - accuracy: 0.9310 - precision: 0.9091 - recall: 0.9091 - auc: 0.9861 - prc: 0.9806 - val_loss: 3.3246 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5444 - val_prc: 0.4212
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 72/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.1275 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.1590 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5556 - val_prc: 0.4016
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 73/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0838 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 1.9734 - val_tp: 8.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 1.0000 - val_accuracy: 0.3750 - val_precision: 0.3636 - val_recall: 0.8889 - val_auc: 0.5185 - val_prc: 0.4171
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 74/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.1088 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 0.9962 - prc: 0.9936 - val_loss: 4.0157 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4667 - val_prc: 0.3500
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 75/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.1446 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9899 - prc: 0.9837 - val_loss: 2.9612 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5778 - val_prc: 0.4154
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 76/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 203ms/step - loss: 0.0713 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 0.9987 - prc: 0.9980 - val_loss: 4.5733 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6000 - val_prc: 0.4286
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 77/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0964 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.7162 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5630 - val_prc: 0.3880
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 78/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.1358 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9874 - prc: 0.9827 - val_loss: 1.3227 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 2.0000 - val_accuracy: 0.5417 - val_precision: 0.4375 - val_recall: 0.7778 - val_auc: 0.6333 - val_prc: 0.4920
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 79/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.0856 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 2.6552 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5185 - val_prc: 0.4217
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 80/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.1499 - tp: 18.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 4.0000 - accuracy: 0.9310 - precision: 1.0000 - recall: 0.8182 - auc: 0.9912 - prc: 0.9862 - val_loss: 1.2554 - val_tp: 4.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 5.0000 - val_accuracy: 0.5417 - val_precision: 0.4000 - val_recall: 0.4444 - val_auc: 0.5296 - val_prc: 0.5386
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 81/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0599 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.0355 - val_tp: 7.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 2.0000 - val_accuracy: 0.3750 - val_precision: 0.3500 - val_recall: 0.7778 - val_auc: 0.5185 - val_prc: 0.4231
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 82/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0777 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9962 - prc: 0.9944 - val_loss: 1.7000 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 3.0000 - val_accuracy: 0.3750 - val_precision: 0.3333 - val_recall: 0.6667 - val_auc: 0.5333 - val_prc: 0.4734
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 83/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 201ms/step - loss: 0.0676 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.8261 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5407 - val_prc: 0.4026
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 84/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.0933 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.7199 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5296 - val_prc: 0.3871
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 85/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.0603 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 5.5722 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5667 - val_prc: 0.4091
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 86/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0923 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 2.8736 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6556 - val_prc: 0.4638
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 87/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 204ms/step - loss: 0.0645 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 1.7041 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 4.0000 - val_accuracy: 0.3750 - val_precision: 0.3125 - val_recall: 0.5556 - val_auc: 0.4741 - val_prc: 0.4138
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 88/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0570 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.4840 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5778 - val_prc: 0.4226
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 89/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0424 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.4750 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5407 - val_prc: 0.3916
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 90/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.1142 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9880 - prc: 0.9861 - val_loss: 3.5888 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4963 - val_prc: 0.3667
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 91/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0507 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.0560 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.3679
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 92/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 202ms/step - loss: 0.0612 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.2421 - val_tp: 7.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 2.0000 - val_accuracy: 0.4167 - val_precision: 0.3684 - val_recall: 0.7778 - val_auc: 0.5333 - val_prc: 0.4312
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 93/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.1112 - tp: 21.0000 - fp: 3.0000 - tn: 33.0000 - fn: 1.0000 - accuracy: 0.9310 - precision: 0.8750 - recall: 0.9545 - auc: 0.9937 - prc: 0.9914 - val_loss: 2.1516 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.7259 - val_prc: 0.6492
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 94/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.1179 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9937 - prc: 0.9914 - val_loss: 1.4414 - val_tp: 6.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 3.0000 - val_accuracy: 0.5000 - val_precision: 0.4000 - val_recall: 0.6667 - val_auc: 0.6259 - val_prc: 0.5550
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 95/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.1062 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9937 - prc: 0.9914 - val_loss: 2.7095 - val_tp: 8.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4167 - val_precision: 0.3810 - val_recall: 0.8889 - val_auc: 0.4815 - val_prc: 0.3770
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 96/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 202ms/step - loss: 0.0810 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.9633 - val_tp: 5.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 4.0000 - val_accuracy: 0.4167 - val_precision: 0.3333 - val_recall: 0.5556 - val_auc: 0.4704 - val_prc: 0.4114
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 97/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0859 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9994 - prc: 0.9990 - val_loss: 1.9116 - val_tp: 5.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 4.0000 - val_accuracy: 0.3333 - val_precision: 0.2941 - val_recall: 0.5556 - val_auc: 0.4630 - val_prc: 0.3964
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 98/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0968 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9886 - prc: 0.9866 - val_loss: 2.7720 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5778 - val_prc: 0.4204
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 99/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0579 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.6175 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5222 - val_prc: 0.3843
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 100/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.0369 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.2924 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4667 - val_prc: 0.3500
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 101/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0925 - tp: 22.0000 - fp: 2.0000 - tn: 34.0000 - fn: 0.0000e+00 - accuracy: 0.9655 - precision: 0.9167 - recall: 1.0000 - auc: 0.9962 - prc: 0.9936 - val_loss: 2.2516 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5259 - val_prc: 0.4097
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 102/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 203ms/step - loss: 0.0926 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9962 - prc: 0.9936 - val_loss: 2.0684 - val_tp: 8.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 1.0000 - val_accuracy: 0.3750 - val_precision: 0.3636 - val_recall: 0.8889 - val_auc: 0.5407 - val_prc: 0.4287
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 103/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0658 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.8156 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.4815 - val_prc: 0.3588
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 104/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 202ms/step - loss: 0.0603 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.3681 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.4667 - val_prc: 0.3429
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 105/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0254 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.4728 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4519 - val_prc: 0.3385
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 106/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0220 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.9446 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5185 - val_prc: 0.4030
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 107/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.0149 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.6206 - val_tp: 8.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 1.0000 - val_accuracy: 0.3750 - val_precision: 0.3636 - val_recall: 0.8889 - val_auc: 0.5037 - val_prc: 0.4005
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 108/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 202ms/step - loss: 0.0628 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.1908 - val_tp: 8.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4167 - val_precision: 0.3810 - val_recall: 0.8889 - val_auc: 0.6370 - val_prc: 0.5367
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 109/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0694 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.3011 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.4222 - val_prc: 0.3490
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 110/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0740 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.0451 - val_tp: 8.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4211 - val_recall: 0.8889 - val_auc: 0.6074 - val_prc: 0.4386
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 111/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0756 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9962 - prc: 0.9936 - val_loss: 3.3727 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.5852 - val_prc: 0.4179
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 112/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.1125 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9924 - prc: 0.9893 - val_loss: 1.3505 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6111 - val_prc: 0.5408
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 113/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0879 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9949 - prc: 0.9929 - val_loss: 6.0629 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5667 - val_prc: 0.4091
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 114/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.0532 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.3074 - val_tp: 5.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 4.0000 - val_accuracy: 0.3333 - val_precision: 0.2941 - val_recall: 0.5556 - val_auc: 0.4852 - val_prc: 0.4030
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 115/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 201ms/step - loss: 0.1137 - tp: 20.0000 - fp: 2.0000 - tn: 34.0000 - fn: 2.0000 - accuracy: 0.9310 - precision: 0.9091 - recall: 0.9091 - auc: 0.9924 - prc: 0.9886 - val_loss: 1.7581 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.4556 - val_prc: 0.4986
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 116/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0722 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.2569 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 3.0000 - val_accuracy: 0.3750 - val_precision: 0.3333 - val_recall: 0.6667 - val_auc: 0.4556 - val_prc: 0.3915
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 117/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0887 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 1.6542 - val_tp: 5.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 4.0000 - val_accuracy: 0.5833 - val_precision: 0.4545 - val_recall: 0.5556 - val_auc: 0.5111 - val_prc: 0.4582
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 118/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.0650 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3462 - val_tp: 5.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 4.0000 - val_accuracy: 0.5000 - val_precision: 0.3846 - val_recall: 0.5556 - val_auc: 0.5481 - val_prc: 0.5434
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 119/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0646 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.4556 - val_tp: 5.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 4.0000 - val_accuracy: 0.5417 - val_precision: 0.4167 - val_recall: 0.5556 - val_auc: 0.5185 - val_prc: 0.4586
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 120/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 204ms/step - loss: 0.0925 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9949 - prc: 0.9929 - val_loss: 1.4570 - val_tp: 4.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 5.0000 - val_accuracy: 0.5000 - val_precision: 0.3636 - val_recall: 0.4444 - val_auc: 0.5111 - val_prc: 0.5224
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 121/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0649 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5245 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 4.0000 - val_accuracy: 0.3750 - val_precision: 0.3125 - val_recall: 0.5556 - val_auc: 0.5185 - val_prc: 0.4232
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 122/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.0733 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 1.7170 - val_tp: 5.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 4.0000 - val_accuracy: 0.4167 - val_precision: 0.3333 - val_recall: 0.5556 - val_auc: 0.4926 - val_prc: 0.4044
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 123/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0667 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.8725 - val_tp: 7.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 2.0000 - val_accuracy: 0.4167 - val_precision: 0.3684 - val_recall: 0.7778 - val_auc: 0.5259 - val_prc: 0.3983
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 124/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.0969 - tp: 19.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 3.0000 - accuracy: 0.9483 - precision: 1.0000 - recall: 0.8636 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.0981 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.7259 - val_prc: 0.5298
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 125/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0381 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.9360 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.7000 - val_prc: 0.5000
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 126/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 203ms/step - loss: 0.0656 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9994 - prc: 0.9990 - val_loss: 4.9518 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6000 - val_prc: 0.4286
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 127/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0255 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.6203 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6481 - val_prc: 0.4632
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 128/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0593 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.5356 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5481 - val_prc: 0.4167
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 129/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.0628 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 0.9975 - prc: 0.9961 - val_loss: 2.4770 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7333 - val_prc: 0.5378
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 130/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0474 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.2094 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6593 - val_prc: 0.4694
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 131/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.0504 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.4861 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5407 - val_prc: 0.3911
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 132/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0231 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.0904 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.4852 - val_prc: 0.3634
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 133/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0270 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 4.2913 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.4481 - val_prc: 0.3385
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 134/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0095 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.4317 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5222 - val_prc: 0.3846
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 135/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.0220 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.4199 - val_tp: 5.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 4.0000 - val_accuracy: 0.3333 - val_precision: 0.2941 - val_recall: 0.5556 - val_auc: 0.4852 - val_prc: 0.3649
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 136/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0174 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.6998 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 3.0000 - val_accuracy: 0.3750 - val_precision: 0.3333 - val_recall: 0.6667 - val_auc: 0.4593 - val_prc: 0.3626
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 137/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0079 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.4095 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.3775
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 138/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.0085 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 3.3366 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5037 - val_prc: 0.3786
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 139/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0092 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.8076 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.4259 - val_prc: 0.3315
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 140/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 203ms/step - loss: 0.0059 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.4575 - val_tp: 8.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4167 - val_precision: 0.3810 - val_recall: 0.8889 - val_auc: 0.4963 - val_prc: 0.4059
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 141/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0131 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.2473 - val_tp: 8.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 1.0000 - val_accuracy: 0.4583 - val_precision: 0.4000 - val_recall: 0.8889 - val_auc: 0.5185 - val_prc: 0.4143
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 142/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.0465 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.7348 - val_tp: 5.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 4.0000 - val_accuracy: 0.4583 - val_precision: 0.3571 - val_recall: 0.5556 - val_auc: 0.5333 - val_prc: 0.4518
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 143/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0906 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.6769 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.5963 - val_prc: 0.5623
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 144/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0388 - tp: 22.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.3065 - val_tp: 4.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 5.0000 - val_accuracy: 0.5833 - val_precision: 0.4444 - val_recall: 0.4444 - val_auc: 0.5741 - val_prc: 0.5469
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 145/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0332 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 1.5890 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 2.0000 - val_accuracy: 0.5417 - val_precision: 0.4375 - val_recall: 0.7778 - val_auc: 0.6148 - val_prc: 0.4760
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 146/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0701 - tp: 20.0000 - fp: 1.0000 - tn: 35.0000 - fn: 2.0000 - accuracy: 0.9483 - precision: 0.9524 - recall: 0.9091 - auc: 0.9962 - prc: 0.9940 - val_loss: 3.6880 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.4481 - val_prc: 0.3441
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 147/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.0342 - tp: 22.0000 - fp: 1.0000 - tn: 35.0000 - fn: 0.0000e+00 - accuracy: 0.9828 - precision: 0.9565 - recall: 1.0000 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.1409 - val_tp: 5.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 4.0000 - val_accuracy: 0.3750 - val_precision: 0.3125 - val_recall: 0.5556 - val_auc: 0.4926 - val_prc: 0.3831
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 148/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.0566 - tp: 21.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 1.0000 - accuracy: 0.9828 - precision: 1.0000 - recall: 0.9545 - auc: 1.0000 - prc: 1.0000 - val_loss: 2.9883 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6000 - val_prc: 0.4391
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 149/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.0578 - tp: 21.0000 - fp: 1.0000 - tn: 35.0000 - fn: 1.0000 - accuracy: 0.9655 - precision: 0.9545 - recall: 0.9545 - auc: 0.9987 - prc: 0.9980 - val_loss: 4.5376 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5852 - val_prc: 0.4203
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 150/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.0794 - tp: 20.0000 - fp: 0.0000e+00 - tn: 36.0000 - fn: 2.0000 - accuracy: 0.9655 - precision: 1.0000 - recall: 0.9091 - auc: 0.9975 - prc: 0.9959 - val_loss: 3.9708 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6667 - val_prc: 0.4737
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/div>
&lt;h3 id="intermediate-augmentation">Intermediate augmentation&lt;/h3>
&lt;p>Additional layers, i.e., rotation, flip and shift, are enabled which will deeply enrich the training dataset.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">build_model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">augmentation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">rotation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">flip&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">shift&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">zoom&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">shear&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">brightness&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">contrast&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">performance&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;intermediate&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">train_model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">training_dataset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">validation_dataset&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="scrollable-output">
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> Epoch 1/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 10s 199ms/step - loss: 0.7231 - tp: 16.0000 - fp: 27.0000 - tn: 24.0000 - fn: 15.0000 - accuracy: 0.4878 - precision: 0.3721 - recall: 0.5161 - auc: 0.4956 - prc: 0.3989 - val_loss: 0.6800 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.3750
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 2/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6889 - tp: 3.0000 - fp: 8.0000 - tn: 28.0000 - fn: 19.0000 - accuracy: 0.5345 - precision: 0.2727 - recall: 0.1364 - auc: 0.4356 - prc: 0.3383 - val_loss: 0.6677 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3333 - val_prc: 0.2886
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 3/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6853 - tp: 4.0000 - fp: 4.0000 - tn: 32.0000 - fn: 18.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.1818 - auc: 0.4470 - prc: 0.3943 - val_loss: 0.6686 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4000 - val_prc: 0.3155
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 4/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6844 - tp: 1.0000 - fp: 5.0000 - tn: 31.0000 - fn: 21.0000 - accuracy: 0.5517 - precision: 0.1667 - recall: 0.0455 - auc: 0.4691 - prc: 0.3680 - val_loss: 0.7572 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4778 - val_prc: 0.3643
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 5/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.6479 - tp: 4.0000 - fp: 6.0000 - tn: 30.0000 - fn: 18.0000 - accuracy: 0.5862 - precision: 0.4000 - recall: 0.1818 - auc: 0.6086 - prc: 0.4274 - val_loss: 0.9019 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4000 - val_prc: 0.3155
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 6/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6591 - tp: 6.0000 - fp: 8.0000 - tn: 28.0000 - fn: 16.0000 - accuracy: 0.5862 - precision: 0.4286 - recall: 0.2727 - auc: 0.5922 - prc: 0.4135 - val_loss: 0.7039 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4630 - val_prc: 0.3416
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 7/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6428 - tp: 9.0000 - fp: 10.0000 - tn: 26.0000 - fn: 13.0000 - accuracy: 0.6034 - precision: 0.4737 - recall: 0.4091 - auc: 0.6345 - prc: 0.4728 - val_loss: 0.6765 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4630 - val_prc: 0.3887
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 8/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6761 - tp: 3.0000 - fp: 5.0000 - tn: 31.0000 - fn: 19.0000 - accuracy: 0.5862 - precision: 0.3750 - recall: 0.1364 - auc: 0.5038 - prc: 0.3718 - val_loss: 1.3303 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4111 - val_prc: 0.3283
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 9/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.6448 - tp: 3.0000 - fp: 3.0000 - tn: 33.0000 - fn: 19.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.1364 - auc: 0.6635 - prc: 0.5027 - val_loss: 1.3146 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5000 - val_prc: 0.3750
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 10/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 202ms/step - loss: 0.7098 - tp: 2.0000 - fp: 8.0000 - tn: 28.0000 - fn: 20.0000 - accuracy: 0.5172 - precision: 0.2000 - recall: 0.0909 - auc: 0.4369 - prc: 0.3235 - val_loss: 1.2832 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6556 - val_prc: 0.5505
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 11/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.6728 - tp: 2.0000 - fp: 5.0000 - tn: 31.0000 - fn: 20.0000 - accuracy: 0.5690 - precision: 0.2857 - recall: 0.0909 - auc: 0.5145 - prc: 0.3877 - val_loss: 1.0651 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5444 - val_prc: 0.4924
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 12/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6299 - tp: 4.0000 - fp: 3.0000 - tn: 33.0000 - fn: 18.0000 - accuracy: 0.6379 - precision: 0.5714 - recall: 0.1818 - auc: 0.6604 - prc: 0.5622 - val_loss: 0.7223 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5889 - val_prc: 0.3991
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 13/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.7063 - tp: 2.0000 - fp: 6.0000 - tn: 30.0000 - fn: 20.0000 - accuracy: 0.5517 - precision: 0.2500 - recall: 0.0909 - auc: 0.4539 - prc: 0.3761 - val_loss: 0.8667 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4407 - val_prc: 0.3629
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 14/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6713 - tp: 3.0000 - fp: 5.0000 - tn: 31.0000 - fn: 19.0000 - accuracy: 0.5862 - precision: 0.3750 - recall: 0.1364 - auc: 0.5139 - prc: 0.4051 - val_loss: 0.6503 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6333 - val_prc: 0.5285
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 15/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6131 - tp: 7.0000 - fp: 4.0000 - tn: 32.0000 - fn: 15.0000 - accuracy: 0.6724 - precision: 0.6364 - recall: 0.3182 - auc: 0.7153 - prc: 0.5919 - val_loss: 0.9687 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5074 - val_prc: 0.4616
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 16/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 203ms/step - loss: 0.6645 - tp: 1.0000 - fp: 5.0000 - tn: 31.0000 - fn: 21.0000 - accuracy: 0.5517 - precision: 0.1667 - recall: 0.0455 - auc: 0.5657 - prc: 0.3811 - val_loss: 1.1999 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3296 - val_prc: 0.3140
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 17/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.6871 - tp: 2.0000 - fp: 4.0000 - tn: 32.0000 - fn: 20.0000 - accuracy: 0.5862 - precision: 0.3333 - recall: 0.0909 - auc: 0.5051 - prc: 0.3926 - val_loss: 1.1274 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3074 - val_prc: 0.3098
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 18/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6332 - tp: 4.0000 - fp: 3.0000 - tn: 33.0000 - fn: 18.0000 - accuracy: 0.6379 - precision: 0.5714 - recall: 0.1818 - auc: 0.6793 - prc: 0.4978 - val_loss: 0.7809 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5037 - val_prc: 0.3814
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 19/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6442 - tp: 8.0000 - fp: 6.0000 - tn: 30.0000 - fn: 14.0000 - accuracy: 0.6552 - precision: 0.5714 - recall: 0.3636 - auc: 0.6016 - prc: 0.5000 - val_loss: 0.6405 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.6556 - val_prc: 0.6124
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 20/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6440 - tp: 9.0000 - fp: 10.0000 - tn: 26.0000 - fn: 13.0000 - accuracy: 0.6034 - precision: 0.4737 - recall: 0.4091 - auc: 0.6654 - prc: 0.5345 - val_loss: 0.9431 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6741 - val_prc: 0.6805
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 21/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.6616 - tp: 11.0000 - fp: 7.0000 - tn: 29.0000 - fn: 11.0000 - accuracy: 0.6897 - precision: 0.6111 - recall: 0.5000 - auc: 0.6477 - prc: 0.5794 - val_loss: 0.6928 - val_tp: 5.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 4.0000 - val_accuracy: 0.5000 - val_precision: 0.3846 - val_recall: 0.5556 - val_auc: 0.5481 - val_prc: 0.5116
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 22/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.7111 - tp: 2.0000 - fp: 6.0000 - tn: 30.0000 - fn: 20.0000 - accuracy: 0.5517 - precision: 0.2500 - recall: 0.0909 - auc: 0.4217 - prc: 0.3235 - val_loss: 0.6896 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 9.0000 - val_accuracy: 0.5417 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4407 - val_prc: 0.3527
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 23/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6780 - tp: 5.0000 - fp: 3.0000 - tn: 33.0000 - fn: 17.0000 - accuracy: 0.6552 - precision: 0.6250 - recall: 0.2273 - auc: 0.6162 - prc: 0.4667 - val_loss: 0.7727 - val_tp: 6.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 3.0000 - val_accuracy: 0.3750 - val_precision: 0.3333 - val_recall: 0.6667 - val_auc: 0.3593 - val_prc: 0.3773
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 24/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.6768 - tp: 2.0000 - fp: 3.0000 - tn: 33.0000 - fn: 20.0000 - accuracy: 0.6034 - precision: 0.4000 - recall: 0.0909 - auc: 0.5347 - prc: 0.3901 - val_loss: 0.7188 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 8.0000 - val_accuracy: 0.5833 - val_precision: 0.3333 - val_recall: 0.1111 - val_auc: 0.3074 - val_prc: 0.3651
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 25/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6734 - tp: 2.0000 - fp: 4.0000 - tn: 32.0000 - fn: 20.0000 - accuracy: 0.5862 - precision: 0.3333 - recall: 0.0909 - auc: 0.4905 - prc: 0.4147 - val_loss: 0.7435 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3370 - val_prc: 0.3695
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 26/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.6894 - tp: 5.0000 - fp: 5.0000 - tn: 31.0000 - fn: 17.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2273 - auc: 0.5271 - prc: 0.4133 - val_loss: 0.7057 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3741 - val_prc: 0.3137
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 27/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 202ms/step - loss: 0.6588 - tp: 3.0000 - fp: 2.0000 - tn: 34.0000 - fn: 19.0000 - accuracy: 0.6379 - precision: 0.6000 - recall: 0.1364 - auc: 0.6206 - prc: 0.4957 - val_loss: 0.6932 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4296 - val_prc: 0.3303
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 28/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.6489 - tp: 2.0000 - fp: 2.0000 - tn: 34.0000 - fn: 20.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.0909 - auc: 0.5884 - prc: 0.4461 - val_loss: 0.7580 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3778 - val_prc: 0.2952
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 29/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.6667 - tp: 4.0000 - fp: 4.0000 - tn: 32.0000 - fn: 18.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.1818 - auc: 0.5745 - prc: 0.4509 - val_loss: 0.6758 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.4407 - val_prc: 0.4427
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 30/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.6734 - tp: 7.0000 - fp: 6.0000 - tn: 30.0000 - fn: 15.0000 - accuracy: 0.6379 - precision: 0.5385 - recall: 0.3182 - auc: 0.5568 - prc: 0.4381 - val_loss: 0.7776 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5963 - val_prc: 0.3982
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 31/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6876 - tp: 6.0000 - fp: 8.0000 - tn: 28.0000 - fn: 16.0000 - accuracy: 0.5862 - precision: 0.4286 - recall: 0.2727 - auc: 0.5366 - prc: 0.3830 - val_loss: 0.7346 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.4111 - val_prc: 0.4668
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 32/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 202ms/step - loss: 0.6331 - tp: 6.0000 - fp: 6.0000 - tn: 30.0000 - fn: 16.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2727 - auc: 0.6610 - prc: 0.4939 - val_loss: 0.6994 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6926 - val_prc: 0.6041
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 33/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6269 - tp: 8.0000 - fp: 5.0000 - tn: 31.0000 - fn: 14.0000 - accuracy: 0.6724 - precision: 0.6154 - recall: 0.3636 - auc: 0.6629 - prc: 0.5904 - val_loss: 0.6840 - val_tp: 8.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4211 - val_recall: 0.8889 - val_auc: 0.6593 - val_prc: 0.5837
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 34/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6252 - tp: 9.0000 - fp: 6.0000 - tn: 30.0000 - fn: 13.0000 - accuracy: 0.6724 - precision: 0.6000 - recall: 0.4091 - auc: 0.6629 - prc: 0.5198 - val_loss: 0.7985 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.5630 - val_prc: 0.5478
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 35/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6482 - tp: 3.0000 - fp: 3.0000 - tn: 33.0000 - fn: 19.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.1364 - auc: 0.6042 - prc: 0.4433 - val_loss: 0.8125 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5889 - val_prc: 0.5534
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 36/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.6576 - tp: 8.0000 - fp: 6.0000 - tn: 30.0000 - fn: 14.0000 - accuracy: 0.6552 - precision: 0.5714 - recall: 0.3636 - auc: 0.5878 - prc: 0.4602 - val_loss: 0.8182 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6111 - val_prc: 0.6427
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 37/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 202ms/step - loss: 0.5779 - tp: 9.0000 - fp: 3.0000 - tn: 33.0000 - fn: 13.0000 - accuracy: 0.7241 - precision: 0.7500 - recall: 0.4091 - auc: 0.7557 - prc: 0.6339 - val_loss: 0.8414 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6000 - val_prc: 0.5591
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 38/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.6377 - tp: 6.0000 - fp: 6.0000 - tn: 30.0000 - fn: 16.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2727 - auc: 0.6345 - prc: 0.5422 - val_loss: 0.8881 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5037 - val_prc: 0.3854
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 39/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.5844 - tp: 9.0000 - fp: 4.0000 - tn: 32.0000 - fn: 13.0000 - accuracy: 0.7069 - precision: 0.6923 - recall: 0.4091 - auc: 0.7298 - prc: 0.6593 - val_loss: 0.8948 - val_tp: 8.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 1.0000 - val_accuracy: 0.3333 - val_precision: 0.3478 - val_recall: 0.8889 - val_auc: 0.4148 - val_prc: 0.3516
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 40/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.6297 - tp: 12.0000 - fp: 7.0000 - tn: 29.0000 - fn: 10.0000 - accuracy: 0.7069 - precision: 0.6316 - recall: 0.5455 - auc: 0.6635 - prc: 0.5439 - val_loss: 0.6382 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6778 - val_prc: 0.5666
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 41/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.6754 - tp: 8.0000 - fp: 10.0000 - tn: 26.0000 - fn: 14.0000 - accuracy: 0.5862 - precision: 0.4444 - recall: 0.3636 - auc: 0.6023 - prc: 0.4386 - val_loss: 0.5928 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.7000 - val_prc: 0.5393
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 42/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 204ms/step - loss: 0.6478 - tp: 6.0000 - fp: 5.0000 - tn: 31.0000 - fn: 16.0000 - accuracy: 0.6379 - precision: 0.5455 - recall: 0.2727 - auc: 0.6143 - prc: 0.4462 - val_loss: 0.7146 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.7000 - val_prc: 0.5030
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 43/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6467 - tp: 5.0000 - fp: 6.0000 - tn: 30.0000 - fn: 17.0000 - accuracy: 0.6034 - precision: 0.4545 - recall: 0.2273 - auc: 0.6136 - prc: 0.5181 - val_loss: 0.6625 - val_tp: 8.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 1.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.8889 - val_auc: 0.7444 - val_prc: 0.6732
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 44/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 205ms/step - loss: 0.5776 - tp: 10.0000 - fp: 3.0000 - tn: 33.0000 - fn: 12.0000 - accuracy: 0.7414 - precision: 0.7692 - recall: 0.4545 - auc: 0.7740 - prc: 0.6486 - val_loss: 0.8812 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.7704 - val_prc: 0.6667
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 45/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6245 - tp: 6.0000 - fp: 6.0000 - tn: 30.0000 - fn: 16.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2727 - auc: 0.6818 - prc: 0.4868 - val_loss: 0.6010 - val_tp: 6.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.6667 - val_auc: 0.7259 - val_prc: 0.6229
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 46/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 201ms/step - loss: 0.5504 - tp: 12.0000 - fp: 7.0000 - tn: 29.0000 - fn: 10.0000 - accuracy: 0.7069 - precision: 0.6316 - recall: 0.5455 - auc: 0.8005 - prc: 0.6214 - val_loss: 0.6673 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7704 - val_prc: 0.6662
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 47/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6320 - tp: 10.0000 - fp: 7.0000 - tn: 29.0000 - fn: 12.0000 - accuracy: 0.6724 - precision: 0.5882 - recall: 0.4545 - auc: 0.6616 - prc: 0.5851 - val_loss: 1.2353 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5963 - val_prc: 0.6506
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 48/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6673 - tp: 5.0000 - fp: 6.0000 - tn: 30.0000 - fn: 17.0000 - accuracy: 0.6034 - precision: 0.4545 - recall: 0.2273 - auc: 0.5587 - prc: 0.4591 - val_loss: 0.6620 - val_tp: 5.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 4.0000 - val_accuracy: 0.5000 - val_precision: 0.3846 - val_recall: 0.5556 - val_auc: 0.6741 - val_prc: 0.6882
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 49/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.6260 - tp: 5.0000 - fp: 5.0000 - tn: 31.0000 - fn: 17.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2273 - auc: 0.6515 - prc: 0.4895 - val_loss: 0.6224 - val_tp: 6.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.7500 - val_precision: 0.6667 - val_recall: 0.6667 - val_auc: 0.7000 - val_prc: 0.5446
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 50/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.5576 - tp: 8.0000 - fp: 4.0000 - tn: 32.0000 - fn: 14.0000 - accuracy: 0.6897 - precision: 0.6667 - recall: 0.3636 - auc: 0.7809 - prc: 0.7074 - val_loss: 0.6304 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 5.0000 - val_accuracy: 0.7083 - val_precision: 0.6667 - val_recall: 0.4444 - val_auc: 0.6444 - val_prc: 0.5080
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 51/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 201ms/step - loss: 0.5758 - tp: 6.0000 - fp: 7.0000 - tn: 29.0000 - fn: 16.0000 - accuracy: 0.6034 - precision: 0.4615 - recall: 0.2727 - auc: 0.7443 - prc: 0.5919 - val_loss: 0.5417 - val_tp: 7.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.7778 - val_auc: 0.7481 - val_prc: 0.6548
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 52/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6394 - tp: 11.0000 - fp: 10.0000 - tn: 26.0000 - fn: 11.0000 - accuracy: 0.6379 - precision: 0.5238 - recall: 0.5000 - auc: 0.6313 - prc: 0.5428 - val_loss: 0.8636 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.7407 - val_prc: 0.6544
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 53/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.5710 - tp: 11.0000 - fp: 5.0000 - tn: 31.0000 - fn: 11.0000 - accuracy: 0.7241 - precision: 0.6875 - recall: 0.5000 - auc: 0.7614 - prc: 0.6236 - val_loss: 0.5986 - val_tp: 6.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 3.0000 - val_accuracy: 0.7083 - val_precision: 0.6000 - val_recall: 0.6667 - val_auc: 0.7704 - val_prc: 0.6903
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 54/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6205 - tp: 8.0000 - fp: 9.0000 - tn: 27.0000 - fn: 14.0000 - accuracy: 0.6034 - precision: 0.4706 - recall: 0.3636 - auc: 0.6597 - prc: 0.5286 - val_loss: 0.6661 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7926 - val_prc: 0.7478
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 55/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6115 - tp: 8.0000 - fp: 8.0000 - tn: 28.0000 - fn: 14.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.3636 - auc: 0.6881 - prc: 0.5360 - val_loss: 0.6422 - val_tp: 8.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.5417 - val_precision: 0.4444 - val_recall: 0.8889 - val_auc: 0.7741 - val_prc: 0.7251
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 56/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.5945 - tp: 10.0000 - fp: 9.0000 - tn: 27.0000 - fn: 12.0000 - accuracy: 0.6379 - precision: 0.5263 - recall: 0.4545 - auc: 0.7146 - prc: 0.5257 - val_loss: 0.8486 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.6852 - val_prc: 0.5973
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 57/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6536 - tp: 9.0000 - fp: 8.0000 - tn: 28.0000 - fn: 13.0000 - accuracy: 0.6379 - precision: 0.5294 - recall: 0.4091 - auc: 0.6143 - prc: 0.5606 - val_loss: 0.8299 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.7630 - val_prc: 0.5696
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 58/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.5820 - tp: 11.0000 - fp: 7.0000 - tn: 29.0000 - fn: 11.0000 - accuracy: 0.6897 - precision: 0.6111 - recall: 0.5000 - auc: 0.7412 - prc: 0.5989 - val_loss: 0.8487 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.7926 - val_prc: 0.7304
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 59/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.5255 - tp: 14.0000 - fp: 8.0000 - tn: 28.0000 - fn: 8.0000 - accuracy: 0.7241 - precision: 0.6364 - recall: 0.6364 - auc: 0.8024 - prc: 0.6227 - val_loss: 1.0695 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.7667 - val_prc: 0.6272
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 60/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.5907 - tp: 11.0000 - fp: 8.0000 - tn: 28.0000 - fn: 11.0000 - accuracy: 0.6724 - precision: 0.5789 - recall: 0.5000 - auc: 0.7140 - prc: 0.5619 - val_loss: 0.9581 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.7333 - val_prc: 0.5601
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 61/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 203ms/step - loss: 0.6408 - tp: 7.0000 - fp: 10.0000 - tn: 26.0000 - fn: 15.0000 - accuracy: 0.5690 - precision: 0.4118 - recall: 0.3182 - auc: 0.6326 - prc: 0.4991 - val_loss: 0.7301 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.7407 - val_prc: 0.5834
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 62/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.6845 - tp: 6.0000 - fp: 8.0000 - tn: 28.0000 - fn: 16.0000 - accuracy: 0.5862 - precision: 0.4286 - recall: 0.2727 - auc: 0.5713 - prc: 0.4162 - val_loss: 0.5686 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.7815 - val_prc: 0.7189
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 63/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6058 - tp: 11.0000 - fp: 4.0000 - tn: 32.0000 - fn: 11.0000 - accuracy: 0.7414 - precision: 0.7333 - recall: 0.5000 - auc: 0.7096 - prc: 0.6545 - val_loss: 0.6273 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.6444 - val_prc: 0.4692
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 64/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.5758 - tp: 10.0000 - fp: 7.0000 - tn: 29.0000 - fn: 12.0000 - accuracy: 0.6724 - precision: 0.5882 - recall: 0.4545 - auc: 0.7443 - prc: 0.5750 - val_loss: 0.5612 - val_tp: 6.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.6667 - val_auc: 0.7852 - val_prc: 0.6986
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 65/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.5364 - tp: 14.0000 - fp: 5.0000 - tn: 31.0000 - fn: 8.0000 - accuracy: 0.7759 - precision: 0.7368 - recall: 0.6364 - auc: 0.8043 - prc: 0.7823 - val_loss: 0.7267 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7815 - val_prc: 0.7058
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 66/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.5138 - tp: 10.0000 - fp: 4.0000 - tn: 32.0000 - fn: 12.0000 - accuracy: 0.7241 - precision: 0.7143 - recall: 0.4545 - auc: 0.8258 - prc: 0.7563 - val_loss: 0.8425 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7926 - val_prc: 0.6857
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 67/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.6064 - tp: 10.0000 - fp: 5.0000 - tn: 31.0000 - fn: 12.0000 - accuracy: 0.7069 - precision: 0.6667 - recall: 0.4545 - auc: 0.7020 - prc: 0.6413 - val_loss: 1.0756 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.7630 - val_prc: 0.6048
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 68/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.4752 - tp: 13.0000 - fp: 5.0000 - tn: 31.0000 - fn: 9.0000 - accuracy: 0.7586 - precision: 0.7222 - recall: 0.5909 - auc: 0.8586 - prc: 0.8092 - val_loss: 0.5514 - val_tp: 8.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 1.0000 - val_accuracy: 0.7083 - val_precision: 0.5714 - val_recall: 0.8889 - val_auc: 0.7778 - val_prc: 0.6908
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 69/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.5680 - tp: 7.0000 - fp: 6.0000 - tn: 30.0000 - fn: 15.0000 - accuracy: 0.6379 - precision: 0.5385 - recall: 0.3182 - auc: 0.7601 - prc: 0.6544 - val_loss: 0.7441 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7778 - val_prc: 0.6757
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 70/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.5528 - tp: 14.0000 - fp: 11.0000 - tn: 25.0000 - fn: 8.0000 - accuracy: 0.6724 - precision: 0.5600 - recall: 0.6364 - auc: 0.7620 - prc: 0.6741 - val_loss: 0.7975 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.8222 - val_prc: 0.7165
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 71/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6495 - tp: 8.0000 - fp: 10.0000 - tn: 26.0000 - fn: 14.0000 - accuracy: 0.5862 - precision: 0.4444 - recall: 0.3636 - auc: 0.6433 - prc: 0.4926 - val_loss: 0.5878 - val_tp: 6.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.7500 - val_precision: 0.6667 - val_recall: 0.6667 - val_auc: 0.7630 - val_prc: 0.6391
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 72/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 202ms/step - loss: 0.5368 - tp: 13.0000 - fp: 5.0000 - tn: 31.0000 - fn: 9.0000 - accuracy: 0.7586 - precision: 0.7222 - recall: 0.5909 - auc: 0.7986 - prc: 0.7753 - val_loss: 0.6693 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.8222 - val_prc: 0.7316
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 73/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.5834 - tp: 8.0000 - fp: 5.0000 - tn: 31.0000 - fn: 14.0000 - accuracy: 0.6724 - precision: 0.6154 - recall: 0.3636 - auc: 0.7109 - prc: 0.6415 - val_loss: 0.8784 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7852 - val_prc: 0.6437
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 74/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.5698 - tp: 9.0000 - fp: 5.0000 - tn: 31.0000 - fn: 13.0000 - accuracy: 0.6897 - precision: 0.6429 - recall: 0.4091 - auc: 0.7380 - prc: 0.6186 - val_loss: 0.7223 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7852 - val_prc: 0.6321
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 75/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.5552 - tp: 9.0000 - fp: 3.0000 - tn: 33.0000 - fn: 13.0000 - accuracy: 0.7241 - precision: 0.7500 - recall: 0.4091 - auc: 0.7677 - prc: 0.6878 - val_loss: 0.5878 - val_tp: 9.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7083 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.8296 - val_prc: 0.7571
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 76/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.6154 - tp: 6.0000 - fp: 8.0000 - tn: 28.0000 - fn: 16.0000 - accuracy: 0.5862 - precision: 0.4286 - recall: 0.2727 - auc: 0.6667 - prc: 0.5832 - val_loss: 1.0197 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.8074 - val_prc: 0.6452
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 77/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.4835 - tp: 15.0000 - fp: 7.0000 - tn: 29.0000 - fn: 7.0000 - accuracy: 0.7586 - precision: 0.6818 - recall: 0.6818 - auc: 0.8712 - prc: 0.8272 - val_loss: 0.7506 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7519 - val_prc: 0.5957
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 78/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.4491 - tp: 17.0000 - fp: 6.0000 - tn: 30.0000 - fn: 5.0000 - accuracy: 0.8103 - precision: 0.7391 - recall: 0.7727 - auc: 0.8838 - prc: 0.8397 - val_loss: 0.5670 - val_tp: 8.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 1.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.8889 - val_auc: 0.8333 - val_prc: 0.8122
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 79/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 203ms/step - loss: 0.6433 - tp: 8.0000 - fp: 8.0000 - tn: 28.0000 - fn: 14.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.3636 - auc: 0.6244 - prc: 0.5385 - val_loss: 0.7280 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7370 - val_prc: 0.5898
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 80/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.4756 - tp: 14.0000 - fp: 6.0000 - tn: 30.0000 - fn: 8.0000 - accuracy: 0.7586 - precision: 0.7000 - recall: 0.6364 - auc: 0.8491 - prc: 0.7622 - val_loss: 0.9462 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.7444 - val_prc: 0.5806
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 81/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.5501 - tp: 15.0000 - fp: 6.0000 - tn: 30.0000 - fn: 7.0000 - accuracy: 0.7759 - precision: 0.7143 - recall: 0.6818 - auc: 0.7677 - prc: 0.7080 - val_loss: 0.7317 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.7259 - val_prc: 0.5787
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 82/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.5671 - tp: 12.0000 - fp: 7.0000 - tn: 29.0000 - fn: 10.0000 - accuracy: 0.7069 - precision: 0.6316 - recall: 0.5455 - auc: 0.7633 - prc: 0.6235 - val_loss: 0.6504 - val_tp: 8.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.5417 - val_precision: 0.4444 - val_recall: 0.8889 - val_auc: 0.7222 - val_prc: 0.5968
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 83/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.5685 - tp: 12.0000 - fp: 11.0000 - tn: 25.0000 - fn: 10.0000 - accuracy: 0.6379 - precision: 0.5217 - recall: 0.5455 - auc: 0.7348 - prc: 0.5781 - val_loss: 0.5893 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.7407 - val_prc: 0.5896
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 84/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.4972 - tp: 17.0000 - fp: 6.0000 - tn: 30.0000 - fn: 5.0000 - accuracy: 0.8103 - precision: 0.7391 - recall: 0.7727 - auc: 0.8371 - prc: 0.7867 - val_loss: 0.5521 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 5.0000 - val_accuracy: 0.6667 - val_precision: 0.5714 - val_recall: 0.4444 - val_auc: 0.7407 - val_prc: 0.5887
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 85/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.5048 - tp: 12.0000 - fp: 2.0000 - tn: 34.0000 - fn: 10.0000 - accuracy: 0.7931 - precision: 0.8571 - recall: 0.5455 - auc: 0.8346 - prc: 0.8221 - val_loss: 0.6126 - val_tp: 8.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 1.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.8889 - val_auc: 0.7333 - val_prc: 0.6328
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 86/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.4749 - tp: 15.0000 - fp: 5.0000 - tn: 31.0000 - fn: 7.0000 - accuracy: 0.7931 - precision: 0.7500 - recall: 0.6818 - auc: 0.8554 - prc: 0.8553 - val_loss: 0.5405 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 5.0000 - val_accuracy: 0.7083 - val_precision: 0.6667 - val_recall: 0.4444 - val_auc: 0.7519 - val_prc: 0.6317
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 87/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.4594 - tp: 13.0000 - fp: 4.0000 - tn: 32.0000 - fn: 9.0000 - accuracy: 0.7759 - precision: 0.7647 - recall: 0.5909 - auc: 0.8636 - prc: 0.8104 - val_loss: 0.5732 - val_tp: 5.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 4.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.5556 - val_auc: 0.7704 - val_prc: 0.6328
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 88/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.4853 - tp: 13.0000 - fp: 5.0000 - tn: 31.0000 - fn: 9.0000 - accuracy: 0.7586 - precision: 0.7222 - recall: 0.5909 - auc: 0.8422 - prc: 0.7794 - val_loss: 0.6447 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.7111 - val_prc: 0.6129
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 89/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 204ms/step - loss: 0.4654 - tp: 13.0000 - fp: 6.0000 - tn: 30.0000 - fn: 9.0000 - accuracy: 0.7414 - precision: 0.6842 - recall: 0.5909 - auc: 0.8529 - prc: 0.7959 - val_loss: 0.5588 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.7556 - val_prc: 0.5767
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 90/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.5127 - tp: 13.0000 - fp: 5.0000 - tn: 31.0000 - fn: 9.0000 - accuracy: 0.7586 - precision: 0.7222 - recall: 0.5909 - auc: 0.8207 - prc: 0.8025 - val_loss: 0.5891 - val_tp: 7.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.7778 - val_auc: 0.7259 - val_prc: 0.5909
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 91/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.4447 - tp: 16.0000 - fp: 6.0000 - tn: 30.0000 - fn: 6.0000 - accuracy: 0.7931 - precision: 0.7273 - recall: 0.7273 - auc: 0.8744 - prc: 0.8160 - val_loss: 0.9514 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.7370 - val_prc: 0.5892
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 92/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.4973 - tp: 12.0000 - fp: 6.0000 - tn: 30.0000 - fn: 10.0000 - accuracy: 0.7241 - precision: 0.6667 - recall: 0.5455 - auc: 0.8093 - prc: 0.7440 - val_loss: 0.7238 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.8222 - val_prc: 0.6338
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 93/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.4992 - tp: 13.0000 - fp: 6.0000 - tn: 30.0000 - fn: 9.0000 - accuracy: 0.7414 - precision: 0.6842 - recall: 0.5909 - auc: 0.8213 - prc: 0.7252 - val_loss: 0.5491 - val_tp: 6.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 3.0000 - val_accuracy: 0.7083 - val_precision: 0.6000 - val_recall: 0.6667 - val_auc: 0.7741 - val_prc: 0.6171
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 94/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.4720 - tp: 11.0000 - fp: 2.0000 - tn: 34.0000 - fn: 11.0000 - accuracy: 0.7759 - precision: 0.8462 - recall: 0.5000 - auc: 0.8327 - prc: 0.8080 - val_loss: 0.7878 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7778 - val_prc: 0.6203
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 95/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.4566 - tp: 13.0000 - fp: 5.0000 - tn: 31.0000 - fn: 9.0000 - accuracy: 0.7586 - precision: 0.7222 - recall: 0.5909 - auc: 0.8516 - prc: 0.7921 - val_loss: 0.8299 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7444 - val_prc: 0.5831
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 96/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 203ms/step - loss: 0.3962 - tp: 18.0000 - fp: 3.0000 - tn: 33.0000 - fn: 4.0000 - accuracy: 0.8793 - precision: 0.8571 - recall: 0.8182 - auc: 0.9205 - prc: 0.8865 - val_loss: 0.6900 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.7407 - val_prc: 0.5802
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 97/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.4767 - tp: 16.0000 - fp: 8.0000 - tn: 28.0000 - fn: 6.0000 - accuracy: 0.7586 - precision: 0.6667 - recall: 0.7273 - auc: 0.8314 - prc: 0.7729 - val_loss: 0.9409 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.7630 - val_prc: 0.5902
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 98/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.5089 - tp: 13.0000 - fp: 6.0000 - tn: 30.0000 - fn: 9.0000 - accuracy: 0.7414 - precision: 0.6842 - recall: 0.5909 - auc: 0.8068 - prc: 0.7213 - val_loss: 0.7647 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7926 - val_prc: 0.6194
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 99/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.3814 - tp: 18.0000 - fp: 3.0000 - tn: 33.0000 - fn: 4.0000 - accuracy: 0.8793 - precision: 0.8571 - recall: 0.8182 - auc: 0.9211 - prc: 0.8757 - val_loss: 0.6917 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7630 - val_prc: 0.5997
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 100/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.4576 - tp: 14.0000 - fp: 7.0000 - tn: 29.0000 - fn: 8.0000 - accuracy: 0.7414 - precision: 0.6667 - recall: 0.6364 - auc: 0.8403 - prc: 0.7991 - val_loss: 0.5468 - val_tp: 7.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 2.0000 - val_accuracy: 0.7083 - val_precision: 0.5833 - val_recall: 0.7778 - val_auc: 0.7926 - val_prc: 0.6373
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 101/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.4992 - tp: 10.0000 - fp: 6.0000 - tn: 30.0000 - fn: 12.0000 - accuracy: 0.6897 - precision: 0.6250 - recall: 0.4545 - auc: 0.8150 - prc: 0.6876 - val_loss: 0.5874 - val_tp: 9.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7917 - val_precision: 0.6429 - val_recall: 1.0000 - val_auc: 0.7963 - val_prc: 0.6272
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 102/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.3978 - tp: 16.0000 - fp: 5.0000 - tn: 31.0000 - fn: 6.0000 - accuracy: 0.8103 - precision: 0.7619 - recall: 0.7273 - auc: 0.8971 - prc: 0.8646 - val_loss: 0.5416 - val_tp: 9.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7083 - val_precision: 0.5625 - val_recall: 1.0000 - val_auc: 0.8481 - val_prc: 0.7233
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 103/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 203ms/step - loss: 0.3225 - tp: 20.0000 - fp: 4.0000 - tn: 32.0000 - fn: 2.0000 - accuracy: 0.8966 - precision: 0.8333 - recall: 0.9091 - auc: 0.9508 - prc: 0.9096 - val_loss: 0.6056 - val_tp: 9.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7500 - val_precision: 0.6000 - val_recall: 1.0000 - val_auc: 0.8111 - val_prc: 0.6288
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 104/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 177ms/step - loss: 0.4978 - tp: 14.0000 - fp: 7.0000 - tn: 29.0000 - fn: 8.0000 - accuracy: 0.7414 - precision: 0.6667 - recall: 0.6364 - auc: 0.8169 - prc: 0.7811 - val_loss: 0.5363 - val_tp: 2.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 7.0000 - val_accuracy: 0.5833 - val_precision: 0.4000 - val_recall: 0.2222 - val_auc: 0.8259 - val_prc: 0.6409
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 105/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.4204 - tp: 17.0000 - fp: 7.0000 - tn: 29.0000 - fn: 5.0000 - accuracy: 0.7931 - precision: 0.7083 - recall: 0.7727 - auc: 0.8920 - prc: 0.8506 - val_loss: 0.7022 - val_tp: 8.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 1.0000 - val_accuracy: 0.7917 - val_precision: 0.6667 - val_recall: 0.8889 - val_auc: 0.7852 - val_prc: 0.6055
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 106/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 178ms/step - loss: 0.4013 - tp: 14.0000 - fp: 5.0000 - tn: 31.0000 - fn: 8.0000 - accuracy: 0.7759 - precision: 0.7368 - recall: 0.6364 - auc: 0.8984 - prc: 0.8537 - val_loss: 0.6417 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 5.0000 - val_accuracy: 0.6667 - val_precision: 0.5714 - val_recall: 0.4444 - val_auc: 0.8074 - val_prc: 0.6291
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 107/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.4677 - tp: 15.0000 - fp: 7.0000 - tn: 29.0000 - fn: 7.0000 - accuracy: 0.7586 - precision: 0.6818 - recall: 0.6818 - auc: 0.8403 - prc: 0.7835 - val_loss: 0.7031 - val_tp: 9.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6667 - val_precision: 0.5294 - val_recall: 1.0000 - val_auc: 0.7556 - val_prc: 0.5980
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 108/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.4087 - tp: 17.0000 - fp: 7.0000 - tn: 29.0000 - fn: 5.0000 - accuracy: 0.7931 - precision: 0.7083 - recall: 0.7727 - auc: 0.8965 - prc: 0.8407 - val_loss: 0.5617 - val_tp: 7.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 2.0000 - val_accuracy: 0.7083 - val_precision: 0.5833 - val_recall: 0.7778 - val_auc: 0.7704 - val_prc: 0.6275
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 109/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.3948 - tp: 18.0000 - fp: 7.0000 - tn: 29.0000 - fn: 4.0000 - accuracy: 0.8103 - precision: 0.7200 - recall: 0.8182 - auc: 0.9141 - prc: 0.8720 - val_loss: 0.7229 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7926 - val_prc: 0.6126
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 110/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.4375 - tp: 15.0000 - fp: 3.0000 - tn: 33.0000 - fn: 7.0000 - accuracy: 0.8276 - precision: 0.8333 - recall: 0.6818 - auc: 0.8712 - prc: 0.8051 - val_loss: 0.9132 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7963 - val_prc: 0.5592
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 111/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 204ms/step - loss: 0.4325 - tp: 14.0000 - fp: 4.0000 - tn: 32.0000 - fn: 8.0000 - accuracy: 0.7931 - precision: 0.7778 - recall: 0.6364 - auc: 0.8725 - prc: 0.8424 - val_loss: 0.7350 - val_tp: 7.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.7778 - val_auc: 0.7519 - val_prc: 0.5969
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 112/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 206ms/step - loss: 0.3652 - tp: 18.0000 - fp: 3.0000 - tn: 33.0000 - fn: 4.0000 - accuracy: 0.8793 - precision: 0.8571 - recall: 0.8182 - auc: 0.9173 - prc: 0.8903 - val_loss: 0.7394 - val_tp: 9.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7917 - val_precision: 0.6429 - val_recall: 1.0000 - val_auc: 0.8148 - val_prc: 0.5568
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 113/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.3341 - tp: 18.0000 - fp: 3.0000 - tn: 33.0000 - fn: 4.0000 - accuracy: 0.8793 - precision: 0.8571 - recall: 0.8182 - auc: 0.9318 - prc: 0.8883 - val_loss: 0.7916 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.8074 - val_prc: 0.5688
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 114/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 204ms/step - loss: 0.3653 - tp: 16.0000 - fp: 6.0000 - tn: 30.0000 - fn: 6.0000 - accuracy: 0.7931 - precision: 0.7273 - recall: 0.7273 - auc: 0.9129 - prc: 0.8670 - val_loss: 0.5830 - val_tp: 9.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7917 - val_precision: 0.6429 - val_recall: 1.0000 - val_auc: 0.8259 - val_prc: 0.6409
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 115/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.4516 - tp: 14.0000 - fp: 7.0000 - tn: 29.0000 - fn: 8.0000 - accuracy: 0.7414 - precision: 0.6667 - recall: 0.6364 - auc: 0.8573 - prc: 0.8112 - val_loss: 0.9753 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7556 - val_prc: 0.5279
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 116/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.3821 - tp: 15.0000 - fp: 2.0000 - tn: 34.0000 - fn: 7.0000 - accuracy: 0.8448 - precision: 0.8824 - recall: 0.6818 - auc: 0.9217 - prc: 0.8727 - val_loss: 0.8852 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 2.0000 - val_accuracy: 0.5417 - val_precision: 0.4375 - val_recall: 0.7778 - val_auc: 0.7111 - val_prc: 0.5018
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 117/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.3503 - tp: 19.0000 - fp: 6.0000 - tn: 30.0000 - fn: 3.0000 - accuracy: 0.8448 - precision: 0.7600 - recall: 0.8636 - auc: 0.9312 - prc: 0.9195 - val_loss: 0.8045 - val_tp: 7.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.7917 - val_precision: 0.7000 - val_recall: 0.7778 - val_auc: 0.6778 - val_prc: 0.4830
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 118/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.3895 - tp: 15.0000 - fp: 2.0000 - tn: 34.0000 - fn: 7.0000 - accuracy: 0.8448 - precision: 0.8824 - recall: 0.6818 - auc: 0.9034 - prc: 0.8964 - val_loss: 0.6635 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.7556 - val_prc: 0.6040
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 119/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 186ms/step - loss: 0.5087 - tp: 12.0000 - fp: 10.0000 - tn: 26.0000 - fn: 10.0000 - accuracy: 0.6552 - precision: 0.5455 - recall: 0.5455 - auc: 0.7948 - prc: 0.7226 - val_loss: 0.6657 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.8000 - val_prc: 0.5502
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 120/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.2348 - tp: 21.0000 - fp: 2.0000 - tn: 34.0000 - fn: 1.0000 - accuracy: 0.9483 - precision: 0.9130 - recall: 0.9545 - auc: 0.9798 - prc: 0.9608 - val_loss: 0.5682 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 5.0000 - val_accuracy: 0.6667 - val_precision: 0.5714 - val_recall: 0.4444 - val_auc: 0.7778 - val_prc: 0.6127
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 121/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.3735 - tp: 17.0000 - fp: 5.0000 - tn: 31.0000 - fn: 5.0000 - accuracy: 0.8276 - precision: 0.7727 - recall: 0.7727 - auc: 0.9097 - prc: 0.8467 - val_loss: 0.5960 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.7222 - val_prc: 0.6640
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 122/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.3904 - tp: 18.0000 - fp: 4.0000 - tn: 32.0000 - fn: 4.0000 - accuracy: 0.8621 - precision: 0.8182 - recall: 0.8182 - auc: 0.9059 - prc: 0.8604 - val_loss: 0.7521 - val_tp: 7.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.7917 - val_precision: 0.7000 - val_recall: 0.7778 - val_auc: 0.8074 - val_prc: 0.5730
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 123/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.4307 - tp: 13.0000 - fp: 4.0000 - tn: 32.0000 - fn: 9.0000 - accuracy: 0.7759 - precision: 0.7647 - recall: 0.5909 - auc: 0.8662 - prc: 0.8304 - val_loss: 0.8221 - val_tp: 8.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 1.0000 - val_accuracy: 0.7500 - val_precision: 0.6154 - val_recall: 0.8889 - val_auc: 0.7815 - val_prc: 0.5605
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 124/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.3608 - tp: 15.0000 - fp: 4.0000 - tn: 32.0000 - fn: 7.0000 - accuracy: 0.8103 - precision: 0.7895 - recall: 0.6818 - auc: 0.9173 - prc: 0.8897 - val_loss: 0.6435 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 6.0000 - val_accuracy: 0.6667 - val_precision: 0.6000 - val_recall: 0.3333 - val_auc: 0.7963 - val_prc: 0.6412
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 125/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 204ms/step - loss: 0.4595 - tp: 12.0000 - fp: 7.0000 - tn: 29.0000 - fn: 10.0000 - accuracy: 0.7069 - precision: 0.6316 - recall: 0.5455 - auc: 0.8510 - prc: 0.8111 - val_loss: 0.5586 - val_tp: 7.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 2.0000 - val_accuracy: 0.7917 - val_precision: 0.7000 - val_recall: 0.7778 - val_auc: 0.8444 - val_prc: 0.6860
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 126/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.5282 - tp: 14.0000 - fp: 6.0000 - tn: 30.0000 - fn: 8.0000 - accuracy: 0.7586 - precision: 0.7000 - recall: 0.6364 - auc: 0.7973 - prc: 0.7196 - val_loss: 0.5984 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.8444 - val_prc: 0.6145
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 127/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.2486 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9823 - prc: 0.9752 - val_loss: 0.5118 - val_tp: 5.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 4.0000 - val_accuracy: 0.7500 - val_precision: 0.7143 - val_recall: 0.5556 - val_auc: 0.8296 - val_prc: 0.6650
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 128/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.3434 - tp: 18.0000 - fp: 4.0000 - tn: 32.0000 - fn: 4.0000 - accuracy: 0.8621 - precision: 0.8182 - recall: 0.8182 - auc: 0.9261 - prc: 0.9242 - val_loss: 0.8890 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.8519 - val_prc: 0.6766
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 129/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.3145 - tp: 18.0000 - fp: 4.0000 - tn: 32.0000 - fn: 4.0000 - accuracy: 0.8621 - precision: 0.8182 - recall: 0.8182 - auc: 0.9457 - prc: 0.9302 - val_loss: 0.7309 - val_tp: 9.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7917 - val_precision: 0.6429 - val_recall: 1.0000 - val_auc: 0.8296 - val_prc: 0.5784
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 130/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 205ms/step - loss: 0.3860 - tp: 15.0000 - fp: 5.0000 - tn: 31.0000 - fn: 7.0000 - accuracy: 0.7931 - precision: 0.7500 - recall: 0.6818 - auc: 0.9040 - prc: 0.8792 - val_loss: 0.7924 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7741 - val_prc: 0.6130
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 131/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.3228 - tp: 16.0000 - fp: 3.0000 - tn: 33.0000 - fn: 6.0000 - accuracy: 0.8448 - precision: 0.8421 - recall: 0.7273 - auc: 0.9337 - prc: 0.9099 - val_loss: 0.5971 - val_tp: 4.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 5.0000 - val_accuracy: 0.7083 - val_precision: 0.6667 - val_recall: 0.4444 - val_auc: 0.7630 - val_prc: 0.6222
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 132/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.4218 - tp: 16.0000 - fp: 6.0000 - tn: 30.0000 - fn: 6.0000 - accuracy: 0.7931 - precision: 0.7273 - recall: 0.7273 - auc: 0.8788 - prc: 0.8136 - val_loss: 0.5367 - val_tp: 6.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.6667 - val_auc: 0.7704 - val_prc: 0.5306
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 133/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.3656 - tp: 17.0000 - fp: 5.0000 - tn: 31.0000 - fn: 5.0000 - accuracy: 0.8276 - precision: 0.7727 - recall: 0.7727 - auc: 0.9078 - prc: 0.8838 - val_loss: 0.9682 - val_tp: 9.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6667 - val_precision: 0.5294 - val_recall: 1.0000 - val_auc: 0.8074 - val_prc: 0.5502
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 134/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.3243 - tp: 17.0000 - fp: 3.0000 - tn: 33.0000 - fn: 5.0000 - accuracy: 0.8621 - precision: 0.8500 - recall: 0.7727 - auc: 0.9426 - prc: 0.9233 - val_loss: 1.0982 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.7074 - val_prc: 0.4750
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 135/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 205ms/step - loss: 0.3823 - tp: 15.0000 - fp: 6.0000 - tn: 30.0000 - fn: 7.0000 - accuracy: 0.7759 - precision: 0.7143 - recall: 0.6818 - auc: 0.9015 - prc: 0.8525 - val_loss: 0.6301 - val_tp: 6.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 3.0000 - val_accuracy: 0.7500 - val_precision: 0.6667 - val_recall: 0.6667 - val_auc: 0.7556 - val_prc: 0.5358
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 136/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.3087 - tp: 19.0000 - fp: 6.0000 - tn: 30.0000 - fn: 3.0000 - accuracy: 0.8448 - precision: 0.7600 - recall: 0.8636 - auc: 0.9457 - prc: 0.9215 - val_loss: 0.6437 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.7444 - val_prc: 0.6089
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 137/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.2735 - tp: 19.0000 - fp: 3.0000 - tn: 33.0000 - fn: 3.0000 - accuracy: 0.8966 - precision: 0.8636 - recall: 0.8636 - auc: 0.9602 - prc: 0.9406 - val_loss: 0.7527 - val_tp: 8.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 1.0000 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.8889 - val_auc: 0.7407 - val_prc: 0.5234
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 138/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.3350 - tp: 15.0000 - fp: 3.0000 - tn: 33.0000 - fn: 7.0000 - accuracy: 0.8276 - precision: 0.8333 - recall: 0.6818 - auc: 0.9318 - prc: 0.8967 - val_loss: 1.2845 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.6778 - val_prc: 0.4751
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 139/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.2660 - tp: 20.0000 - fp: 4.0000 - tn: 32.0000 - fn: 2.0000 - accuracy: 0.8966 - precision: 0.8333 - recall: 0.9091 - auc: 0.9634 - prc: 0.9440 - val_loss: 1.0685 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7519 - val_prc: 0.5315
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 140/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.3174 - tp: 17.0000 - fp: 1.0000 - tn: 35.0000 - fn: 5.0000 - accuracy: 0.8966 - precision: 0.9444 - recall: 0.7727 - auc: 0.9362 - prc: 0.9181 - val_loss: 0.5186 - val_tp: 9.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.7500 - val_precision: 0.6000 - val_recall: 1.0000 - val_auc: 0.8185 - val_prc: 0.6623
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 141/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.2520 - tp: 21.0000 - fp: 3.0000 - tn: 33.0000 - fn: 1.0000 - accuracy: 0.9310 - precision: 0.8750 - recall: 0.9545 - auc: 0.9691 - prc: 0.9353 - val_loss: 0.5983 - val_tp: 6.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 3.0000 - val_accuracy: 0.7083 - val_precision: 0.6000 - val_recall: 0.6667 - val_auc: 0.7815 - val_prc: 0.5590
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 142/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.2707 - tp: 17.0000 - fp: 2.0000 - tn: 34.0000 - fn: 5.0000 - accuracy: 0.8793 - precision: 0.8947 - recall: 0.7727 - auc: 0.9672 - prc: 0.9555 - val_loss: 0.8502 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7741 - val_prc: 0.5509
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 143/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.2451 - tp: 16.0000 - fp: 2.0000 - tn: 34.0000 - fn: 6.0000 - accuracy: 0.8621 - precision: 0.8889 - recall: 0.7273 - auc: 0.9602 - prc: 0.9489 - val_loss: 0.7822 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.8407 - val_prc: 0.5990
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 144/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.4054 - tp: 16.0000 - fp: 8.0000 - tn: 28.0000 - fn: 6.0000 - accuracy: 0.7586 - precision: 0.6667 - recall: 0.7273 - auc: 0.8838 - prc: 0.8657 - val_loss: 0.6807 - val_tp: 6.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 3.0000 - val_accuracy: 0.5833 - val_precision: 0.4615 - val_recall: 0.6667 - val_auc: 0.6593 - val_prc: 0.5073
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 145/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.3129 - tp: 16.0000 - fp: 6.0000 - tn: 30.0000 - fn: 6.0000 - accuracy: 0.7931 - precision: 0.7273 - recall: 0.7273 - auc: 0.9318 - prc: 0.9062 - val_loss: 1.0719 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7741 - val_prc: 0.5227
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 146/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.2956 - tp: 19.0000 - fp: 1.0000 - tn: 35.0000 - fn: 3.0000 - accuracy: 0.9310 - precision: 0.9500 - recall: 0.8636 - auc: 0.9527 - prc: 0.9343 - val_loss: 0.8674 - val_tp: 9.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6667 - val_precision: 0.5294 - val_recall: 1.0000 - val_auc: 0.7519 - val_prc: 0.5146
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 147/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.3469 - tp: 16.0000 - fp: 4.0000 - tn: 32.0000 - fn: 6.0000 - accuracy: 0.8276 - precision: 0.8000 - recall: 0.7273 - auc: 0.9167 - prc: 0.8675 - val_loss: 1.3816 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.7630 - val_prc: 0.5416
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 148/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.2680 - tp: 18.0000 - fp: 4.0000 - tn: 32.0000 - fn: 4.0000 - accuracy: 0.8621 - precision: 0.8182 - recall: 0.8182 - auc: 0.9552 - prc: 0.9417 - val_loss: 0.6550 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.7704 - val_prc: 0.5871
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 149/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.2699 - tp: 19.0000 - fp: 4.0000 - tn: 32.0000 - fn: 3.0000 - accuracy: 0.8793 - precision: 0.8261 - recall: 0.8636 - auc: 0.9640 - prc: 0.9416 - val_loss: 1.2333 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.7778 - val_prc: 0.5428
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 150/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.3789 - tp: 13.0000 - fp: 3.0000 - tn: 33.0000 - fn: 9.0000 - accuracy: 0.7931 - precision: 0.8125 - recall: 0.5909 - auc: 0.8977 - prc: 0.8600 - val_loss: 0.9867 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.8185 - val_prc: 0.5882
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/div>
&lt;h3 id="advanced-augmentation">Advanced augmentation&lt;/h3>
&lt;p>The advanced approach is more aggressive since it includes zoom and even shear augmentation. As already specified, the latter also introduces an image distortion.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">build_model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">augmentation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">rotation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">flip&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">shift&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">zoom&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">shear&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">brightness&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">contrast&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">performance&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;advanced&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">train_model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">training_dataset&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">validation_dataset&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="scrollable-output">
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 1/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 12s 203ms/step - loss: 0.7046 - tp: 14.0000 - fp: 22.0000 - tn: 29.0000 - fn: 17.0000 - accuracy: 0.5244 - precision: 0.3889 - recall: 0.4516 - auc: 0.5427 - prc: 0.4471 - val_loss: 0.6764 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4222 - val_prc: 0.3302
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 2/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.6903 - tp: 2.0000 - fp: 7.0000 - tn: 29.0000 - fn: 20.0000 - accuracy: 0.5345 - precision: 0.2222 - recall: 0.0909 - auc: 0.4848 - prc: 0.3495 - val_loss: 0.7282 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5778 - val_prc: 0.4324
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 3/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.6244 - tp: 7.0000 - fp: 7.0000 - tn: 29.0000 - fn: 15.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.3182 - auc: 0.6578 - prc: 0.5596 - val_loss: 0.7974 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.3481 - val_prc: 0.3063
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 4/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6840 - tp: 8.0000 - fp: 13.0000 - tn: 23.0000 - fn: 14.0000 - accuracy: 0.5345 - precision: 0.3810 - recall: 0.3636 - auc: 0.5644 - prc: 0.3948 - val_loss: 0.9454 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5000 - val_prc: 0.3750
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 5/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.7390 - tp: 5.0000 - fp: 14.0000 - tn: 22.0000 - fn: 17.0000 - accuracy: 0.4655 - precision: 0.2632 - recall: 0.2273 - auc: 0.3977 - prc: 0.3196 - val_loss: 0.7560 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5926 - val_prc: 0.5165
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 6/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.6541 - tp: 6.0000 - fp: 2.0000 - tn: 34.0000 - fn: 16.0000 - accuracy: 0.6897 - precision: 0.7500 - recall: 0.2727 - auc: 0.6168 - prc: 0.5517 - val_loss: 0.8246 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6370 - val_prc: 0.5326
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 7/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.7085 - tp: 6.0000 - fp: 13.0000 - tn: 23.0000 - fn: 16.0000 - accuracy: 0.5000 - precision: 0.3158 - recall: 0.2727 - auc: 0.4217 - prc: 0.3568 - val_loss: 0.6744 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6000 - val_prc: 0.5026
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 8/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 205ms/step - loss: 0.6690 - tp: 2.0000 - fp: 4.0000 - tn: 32.0000 - fn: 20.0000 - accuracy: 0.5862 - precision: 0.3333 - recall: 0.0909 - auc: 0.5025 - prc: 0.3570 - val_loss: 0.7372 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4074 - val_prc: 0.3063
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 9/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6826 - tp: 2.0000 - fp: 2.0000 - tn: 34.0000 - fn: 20.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.0909 - auc: 0.4413 - prc: 0.4079 - val_loss: 0.6816 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5630 - val_prc: 0.5217
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 10/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.6951 - tp: 3.0000 - fp: 5.0000 - tn: 31.0000 - fn: 19.0000 - accuracy: 0.5862 - precision: 0.3750 - recall: 0.1364 - auc: 0.4463 - prc: 0.3494 - val_loss: 0.6639 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5926 - val_prc: 0.5852
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 11/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 204ms/step - loss: 0.6829 - tp: 7.0000 - fp: 10.0000 - tn: 26.0000 - fn: 15.0000 - accuracy: 0.5690 - precision: 0.4118 - recall: 0.3182 - auc: 0.4943 - prc: 0.4054 - val_loss: 0.8546 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6037 - val_prc: 0.5473
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 12/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.6517 - tp: 2.0000 - fp: 3.0000 - tn: 33.0000 - fn: 20.0000 - accuracy: 0.6034 - precision: 0.4000 - recall: 0.0909 - auc: 0.5909 - prc: 0.4719 - val_loss: 0.8066 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5667 - val_prc: 0.5399
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 13/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.6674 - tp: 4.0000 - fp: 3.0000 - tn: 33.0000 - fn: 18.0000 - accuracy: 0.6379 - precision: 0.5714 - recall: 0.1818 - auc: 0.5366 - prc: 0.4593 - val_loss: 0.7085 - val_tp: 7.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 2.0000 - val_accuracy: 0.3750 - val_precision: 0.3500 - val_recall: 0.7778 - val_auc: 0.5111 - val_prc: 0.4115
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 14/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.6801 - tp: 4.0000 - fp: 3.0000 - tn: 33.0000 - fn: 18.0000 - accuracy: 0.6379 - precision: 0.5714 - recall: 0.1818 - auc: 0.4747 - prc: 0.3952 - val_loss: 0.6619 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5481 - val_prc: 0.4855
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 15/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6520 - tp: 3.0000 - fp: 5.0000 - tn: 31.0000 - fn: 19.0000 - accuracy: 0.5862 - precision: 0.3750 - recall: 0.1364 - auc: 0.5846 - prc: 0.4373 - val_loss: 0.6975 - val_tp: 4.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 5.0000 - val_accuracy: 0.5000 - val_precision: 0.3636 - val_recall: 0.4444 - val_auc: 0.4741 - val_prc: 0.3648
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 16/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 208ms/step - loss: 0.6187 - tp: 4.0000 - fp: 2.0000 - tn: 34.0000 - fn: 18.0000 - accuracy: 0.6552 - precision: 0.6667 - recall: 0.1818 - auc: 0.6926 - prc: 0.5912 - val_loss: 0.7353 - val_tp: 7.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 2.0000 - val_accuracy: 0.3333 - val_precision: 0.3333 - val_recall: 0.7778 - val_auc: 0.4667 - val_prc: 0.3716
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 17/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 205ms/step - loss: 0.6701 - tp: 3.0000 - fp: 9.0000 - tn: 27.0000 - fn: 19.0000 - accuracy: 0.5172 - precision: 0.2500 - recall: 0.1364 - auc: 0.5297 - prc: 0.3845 - val_loss: 0.6876 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5519 - val_prc: 0.4178
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 18/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 205ms/step - loss: 0.6775 - tp: 6.0000 - fp: 7.0000 - tn: 29.0000 - fn: 16.0000 - accuracy: 0.6034 - precision: 0.4615 - recall: 0.2727 - auc: 0.5638 - prc: 0.4825 - val_loss: 0.6814 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.5481 - val_prc: 0.4884
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 19/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.6564 - tp: 7.0000 - fp: 6.0000 - tn: 30.0000 - fn: 15.0000 - accuracy: 0.6379 - precision: 0.5385 - recall: 0.3182 - auc: 0.5909 - prc: 0.4990 - val_loss: 0.7657 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5481 - val_prc: 0.4780
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 20/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.6924 - tp: 8.0000 - fp: 12.0000 - tn: 24.0000 - fn: 14.0000 - accuracy: 0.5517 - precision: 0.4000 - recall: 0.3636 - auc: 0.5259 - prc: 0.4359 - val_loss: 0.7146 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5593 - val_prc: 0.4812
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 21/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.6663 - tp: 2.0000 - fp: 3.0000 - tn: 33.0000 - fn: 20.0000 - accuracy: 0.6034 - precision: 0.4000 - recall: 0.0909 - auc: 0.5114 - prc: 0.4048 - val_loss: 0.6704 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.5370 - val_prc: 0.4039
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 22/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 179ms/step - loss: 0.6685 - tp: 3.0000 - fp: 5.0000 - tn: 31.0000 - fn: 19.0000 - accuracy: 0.5862 - precision: 0.3750 - recall: 0.1364 - auc: 0.5739 - prc: 0.4351 - val_loss: 0.7108 - val_tp: 5.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 4.0000 - val_accuracy: 0.4583 - val_precision: 0.3571 - val_recall: 0.5556 - val_auc: 0.5037 - val_prc: 0.3629
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 23/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.6624 - tp: 2.0000 - fp: 3.0000 - tn: 33.0000 - fn: 20.0000 - accuracy: 0.6034 - precision: 0.4000 - recall: 0.0909 - auc: 0.5404 - prc: 0.4075 - val_loss: 0.7205 - val_tp: 5.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 4.0000 - val_accuracy: 0.4167 - val_precision: 0.3333 - val_recall: 0.5556 - val_auc: 0.3963 - val_prc: 0.2977
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 24/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 204ms/step - loss: 0.6372 - tp: 3.0000 - fp: 7.0000 - tn: 29.0000 - fn: 19.0000 - accuracy: 0.5517 - precision: 0.3000 - recall: 0.1364 - auc: 0.6288 - prc: 0.5001 - val_loss: 0.8073 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.6815 - val_prc: 0.6517
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 25/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6473 - tp: 9.0000 - fp: 6.0000 - tn: 30.0000 - fn: 13.0000 - accuracy: 0.6724 - precision: 0.6000 - recall: 0.4091 - auc: 0.6288 - prc: 0.5083 - val_loss: 0.7682 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.6963 - val_prc: 0.6363
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 26/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 186ms/step - loss: 0.6004 - tp: 5.0000 - fp: 5.0000 - tn: 31.0000 - fn: 17.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2273 - auc: 0.7027 - prc: 0.5617 - val_loss: 0.7955 - val_tp: 9.0000 - val_fp: 14.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4167 - val_precision: 0.3913 - val_recall: 1.0000 - val_auc: 0.7296 - val_prc: 0.6976
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 27/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6501 - tp: 6.0000 - fp: 6.0000 - tn: 30.0000 - fn: 16.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2727 - auc: 0.6111 - prc: 0.4957 - val_loss: 1.1787 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.7259 - val_prc: 0.7172
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 28/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 186ms/step - loss: 0.6617 - tp: 3.0000 - fp: 5.0000 - tn: 31.0000 - fn: 19.0000 - accuracy: 0.5862 - precision: 0.3750 - recall: 0.1364 - auc: 0.6080 - prc: 0.4269 - val_loss: 0.8681 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.7889 - val_prc: 0.7475
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 29/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6911 - tp: 6.0000 - fp: 5.0000 - tn: 31.0000 - fn: 16.0000 - accuracy: 0.6379 - precision: 0.5455 - recall: 0.2727 - auc: 0.4918 - prc: 0.4204 - val_loss: 0.6744 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.7074 - val_prc: 0.6566
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 30/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.6421 - tp: 6.0000 - fp: 5.0000 - tn: 31.0000 - fn: 16.0000 - accuracy: 0.6379 - precision: 0.5455 - recall: 0.2727 - auc: 0.6263 - prc: 0.5563 - val_loss: 0.7569 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7148 - val_prc: 0.6154
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 31/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6879 - tp: 2.0000 - fp: 3.0000 - tn: 33.0000 - fn: 20.0000 - accuracy: 0.6034 - precision: 0.4000 - recall: 0.0909 - auc: 0.4729 - prc: 0.3863 - val_loss: 0.6015 - val_tp: 5.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 4.0000 - val_accuracy: 0.6667 - val_precision: 0.5556 - val_recall: 0.5556 - val_auc: 0.7185 - val_prc: 0.6091
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 32/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6516 - tp: 2.0000 - fp: 4.0000 - tn: 32.0000 - fn: 20.0000 - accuracy: 0.5862 - precision: 0.3333 - recall: 0.0909 - auc: 0.5884 - prc: 0.4562 - val_loss: 0.5953 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 8.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.1111 - val_auc: 0.7333 - val_prc: 0.6369
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 33/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.6394 - tp: 8.0000 - fp: 9.0000 - tn: 27.0000 - fn: 14.0000 - accuracy: 0.6034 - precision: 0.4706 - recall: 0.3636 - auc: 0.6187 - prc: 0.5052 - val_loss: 0.6376 - val_tp: 5.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 4.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.5556 - val_auc: 0.6926 - val_prc: 0.6676
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 34/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.7035 - tp: 6.0000 - fp: 13.0000 - tn: 23.0000 - fn: 16.0000 - accuracy: 0.5000 - precision: 0.3158 - recall: 0.2727 - auc: 0.5322 - prc: 0.3737 - val_loss: 0.6689 - val_tp: 5.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 4.0000 - val_accuracy: 0.5000 - val_precision: 0.3846 - val_recall: 0.5556 - val_auc: 0.6704 - val_prc: 0.6534
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 35/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 206ms/step - loss: 0.6712 - tp: 1.0000 - fp: 2.0000 - tn: 34.0000 - fn: 21.0000 - accuracy: 0.6034 - precision: 0.3333 - recall: 0.0455 - auc: 0.5840 - prc: 0.4860 - val_loss: 0.6611 - val_tp: 6.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 3.0000 - val_accuracy: 0.5833 - val_precision: 0.4615 - val_recall: 0.6667 - val_auc: 0.7074 - val_prc: 0.6201
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 36/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6275 - tp: 5.0000 - fp: 5.0000 - tn: 31.0000 - fn: 17.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2273 - auc: 0.6591 - prc: 0.4538 - val_loss: 0.6931 - val_tp: 8.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4167 - val_precision: 0.3810 - val_recall: 0.8889 - val_auc: 0.6963 - val_prc: 0.6599
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 37/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.6712 - tp: 6.0000 - fp: 5.0000 - tn: 31.0000 - fn: 16.0000 - accuracy: 0.6379 - precision: 0.5455 - recall: 0.2727 - auc: 0.5404 - prc: 0.4800 - val_loss: 0.6658 - val_tp: 7.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 2.0000 - val_accuracy: 0.5833 - val_precision: 0.4667 - val_recall: 0.7778 - val_auc: 0.7222 - val_prc: 0.6967
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 38/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6676 - tp: 4.0000 - fp: 5.0000 - tn: 31.0000 - fn: 18.0000 - accuracy: 0.6034 - precision: 0.4444 - recall: 0.1818 - auc: 0.5486 - prc: 0.4141 - val_loss: 0.6029 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 8.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.1111 - val_auc: 0.7000 - val_prc: 0.5160
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 39/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 186ms/step - loss: 0.6224 - tp: 4.0000 - fp: 2.0000 - tn: 34.0000 - fn: 18.0000 - accuracy: 0.6552 - precision: 0.6667 - recall: 0.1818 - auc: 0.6578 - prc: 0.6070 - val_loss: 0.6108 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.6704 - val_prc: 0.4683
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 40/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6676 - tp: 6.0000 - fp: 8.0000 - tn: 28.0000 - fn: 16.0000 - accuracy: 0.5862 - precision: 0.4286 - recall: 0.2727 - auc: 0.5726 - prc: 0.4630 - val_loss: 0.6539 - val_tp: 7.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.7778 - val_auc: 0.7185 - val_prc: 0.6816
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 41/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.7080 - tp: 1.0000 - fp: 3.0000 - tn: 33.0000 - fn: 21.0000 - accuracy: 0.5862 - precision: 0.2500 - recall: 0.0455 - auc: 0.4028 - prc: 0.3391 - val_loss: 0.6216 - val_tp: 4.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 5.0000 - val_accuracy: 0.5833 - val_precision: 0.4444 - val_recall: 0.4444 - val_auc: 0.7481 - val_prc: 0.7127
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 42/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6574 - tp: 4.0000 - fp: 5.0000 - tn: 31.0000 - fn: 18.0000 - accuracy: 0.6034 - precision: 0.4444 - recall: 0.1818 - auc: 0.6010 - prc: 0.4143 - val_loss: 0.6158 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7259 - val_prc: 0.6933
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 43/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6293 - tp: 5.0000 - fp: 3.0000 - tn: 33.0000 - fn: 17.0000 - accuracy: 0.6552 - precision: 0.6250 - recall: 0.2273 - auc: 0.6692 - prc: 0.5125 - val_loss: 0.6061 - val_tp: 5.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 4.0000 - val_accuracy: 0.6667 - val_precision: 0.5556 - val_recall: 0.5556 - val_auc: 0.7111 - val_prc: 0.4929
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 44/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.7083 - tp: 3.0000 - fp: 6.0000 - tn: 30.0000 - fn: 19.0000 - accuracy: 0.5690 - precision: 0.3333 - recall: 0.1364 - auc: 0.4476 - prc: 0.4012 - val_loss: 0.6599 - val_tp: 1.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 8.0000 - val_accuracy: 0.5833 - val_precision: 0.3333 - val_recall: 0.1111 - val_auc: 0.6444 - val_prc: 0.4695
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 45/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 206ms/step - loss: 0.6447 - tp: 7.0000 - fp: 4.0000 - tn: 32.0000 - fn: 15.0000 - accuracy: 0.6724 - precision: 0.6364 - recall: 0.3182 - auc: 0.6111 - prc: 0.5782 - val_loss: 0.6556 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 8.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.1111 - val_auc: 0.6889 - val_prc: 0.4995
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 46/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.6695 - tp: 4.0000 - fp: 4.0000 - tn: 32.0000 - fn: 18.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.1818 - auc: 0.5234 - prc: 0.4325 - val_loss: 0.6279 - val_tp: 1.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 8.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.1111 - val_auc: 0.6741 - val_prc: 0.4755
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 47/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.6543 - tp: 2.0000 - fp: 2.0000 - tn: 34.0000 - fn: 20.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.0909 - auc: 0.5726 - prc: 0.4613 - val_loss: 0.6232 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 6.0000 - val_accuracy: 0.6667 - val_precision: 0.6000 - val_recall: 0.3333 - val_auc: 0.6630 - val_prc: 0.5356
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 48/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.6752 - tp: 2.0000 - fp: 4.0000 - tn: 32.0000 - fn: 20.0000 - accuracy: 0.5862 - precision: 0.3333 - recall: 0.0909 - auc: 0.5069 - prc: 0.3705 - val_loss: 0.6255 - val_tp: 5.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 4.0000 - val_accuracy: 0.6667 - val_precision: 0.5556 - val_recall: 0.5556 - val_auc: 0.7259 - val_prc: 0.6719
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 49/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.6410 - tp: 6.0000 - fp: 3.0000 - tn: 33.0000 - fn: 16.0000 - accuracy: 0.6724 - precision: 0.6667 - recall: 0.2727 - auc: 0.6477 - prc: 0.5384 - val_loss: 0.7278 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.6259 - val_prc: 0.4578
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 50/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 205ms/step - loss: 0.6456 - tp: 5.0000 - fp: 5.0000 - tn: 31.0000 - fn: 17.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.2273 - auc: 0.6073 - prc: 0.4832 - val_loss: 0.5857 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.7074 - val_prc: 0.6049
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 51/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 180ms/step - loss: 0.7014 - tp: 4.0000 - fp: 9.0000 - tn: 27.0000 - fn: 18.0000 - accuracy: 0.5345 - precision: 0.3077 - recall: 0.1818 - auc: 0.4905 - prc: 0.4029 - val_loss: 0.6040 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.6037 - val_prc: 0.4975
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 52/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.5984 - tp: 10.0000 - fp: 2.0000 - tn: 34.0000 - fn: 12.0000 - accuracy: 0.7586 - precision: 0.8333 - recall: 0.4545 - auc: 0.7367 - prc: 0.7033 - val_loss: 0.5748 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.7296 - val_prc: 0.5922
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 53/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.6348 - tp: 8.0000 - fp: 5.0000 - tn: 31.0000 - fn: 14.0000 - accuracy: 0.6724 - precision: 0.6154 - recall: 0.3636 - auc: 0.6402 - prc: 0.5631 - val_loss: 0.5882 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.7926 - val_prc: 0.7050
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 54/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6085 - tp: 5.0000 - fp: 4.0000 - tn: 32.0000 - fn: 17.0000 - accuracy: 0.6379 - precision: 0.5556 - recall: 0.2273 - auc: 0.7241 - prc: 0.5583 - val_loss: 0.5641 - val_tp: 4.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 5.0000 - val_accuracy: 0.7500 - val_precision: 0.8000 - val_recall: 0.4444 - val_auc: 0.7556 - val_prc: 0.7083
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 55/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 206ms/step - loss: 0.7480 - tp: 3.0000 - fp: 10.0000 - tn: 26.0000 - fn: 19.0000 - accuracy: 0.5000 - precision: 0.2308 - recall: 0.1364 - auc: 0.4116 - prc: 0.3103 - val_loss: 0.6614 - val_tp: 8.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 1.0000 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.8889 - val_auc: 0.7519 - val_prc: 0.6442
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 56/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6687 - tp: 2.0000 - fp: 7.0000 - tn: 29.0000 - fn: 20.0000 - accuracy: 0.5345 - precision: 0.2222 - recall: 0.0909 - auc: 0.5461 - prc: 0.3720 - val_loss: 0.6286 - val_tp: 2.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 7.0000 - val_accuracy: 0.5417 - val_precision: 0.3333 - val_recall: 0.2222 - val_auc: 0.6333 - val_prc: 0.5093
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 57/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.6409 - tp: 8.0000 - fp: 3.0000 - tn: 33.0000 - fn: 14.0000 - accuracy: 0.7069 - precision: 0.7273 - recall: 0.3636 - auc: 0.6439 - prc: 0.5363 - val_loss: 0.5970 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7111 - val_prc: 0.4876
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 58/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.5910 - tp: 10.0000 - fp: 4.0000 - tn: 32.0000 - fn: 12.0000 - accuracy: 0.7241 - precision: 0.7143 - recall: 0.4545 - auc: 0.7506 - prc: 0.6676 - val_loss: 0.5880 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 9.0000 - val_accuracy: 0.5833 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7222 - val_prc: 0.5002
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 59/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 204ms/step - loss: 0.6581 - tp: 9.0000 - fp: 5.0000 - tn: 31.0000 - fn: 13.0000 - accuracy: 0.6897 - precision: 0.6429 - recall: 0.4091 - auc: 0.5808 - prc: 0.5330 - val_loss: 0.7256 - val_tp: 8.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 1.0000 - val_accuracy: 0.4167 - val_precision: 0.3810 - val_recall: 0.8889 - val_auc: 0.6407 - val_prc: 0.4802
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 60/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6269 - tp: 7.0000 - fp: 7.0000 - tn: 29.0000 - fn: 15.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.3182 - auc: 0.6566 - prc: 0.5440 - val_loss: 0.5785 - val_tp: 3.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 6.0000 - val_accuracy: 0.7083 - val_precision: 0.7500 - val_recall: 0.3333 - val_auc: 0.7444 - val_prc: 0.6829
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 61/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 207ms/step - loss: 0.5986 - tp: 7.0000 - fp: 3.0000 - tn: 33.0000 - fn: 15.0000 - accuracy: 0.6897 - precision: 0.7000 - recall: 0.3182 - auc: 0.7071 - prc: 0.6466 - val_loss: 0.5624 - val_tp: 5.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 4.0000 - val_accuracy: 0.7083 - val_precision: 0.6250 - val_recall: 0.5556 - val_auc: 0.7778 - val_prc: 0.7414
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 62/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6476 - tp: 8.0000 - fp: 4.0000 - tn: 32.0000 - fn: 14.0000 - accuracy: 0.6897 - precision: 0.6667 - recall: 0.3636 - auc: 0.6080 - prc: 0.5822 - val_loss: 0.6408 - val_tp: 8.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 1.0000 - val_accuracy: 0.6667 - val_precision: 0.5333 - val_recall: 0.8889 - val_auc: 0.7519 - val_prc: 0.6329
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 63/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6191 - tp: 9.0000 - fp: 4.0000 - tn: 32.0000 - fn: 13.0000 - accuracy: 0.7069 - precision: 0.6923 - recall: 0.4091 - auc: 0.6736 - prc: 0.5997 - val_loss: 0.5931 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.7519 - val_prc: 0.6941
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 64/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.5364 - tp: 10.0000 - fp: 3.0000 - tn: 33.0000 - fn: 12.0000 - accuracy: 0.7414 - precision: 0.7692 - recall: 0.4545 - auc: 0.8125 - prc: 0.7487 - val_loss: 0.7057 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7370 - val_prc: 0.5976
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 65/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.6301 - tp: 5.0000 - fp: 3.0000 - tn: 33.0000 - fn: 17.0000 - accuracy: 0.6552 - precision: 0.6250 - recall: 0.2273 - auc: 0.6376 - prc: 0.5758 - val_loss: 0.5733 - val_tp: 7.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 2.0000 - val_accuracy: 0.7500 - val_precision: 0.6364 - val_recall: 0.7778 - val_auc: 0.7963 - val_prc: 0.7514
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 66/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6038 - tp: 8.0000 - fp: 7.0000 - tn: 29.0000 - fn: 14.0000 - accuracy: 0.6379 - precision: 0.5333 - recall: 0.3636 - auc: 0.7014 - prc: 0.5630 - val_loss: 0.6188 - val_tp: 9.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 1.0000 - val_auc: 0.8074 - val_prc: 0.7480
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 67/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.5997 - tp: 7.0000 - fp: 5.0000 - tn: 31.0000 - fn: 15.0000 - accuracy: 0.6552 - precision: 0.5833 - recall: 0.3182 - auc: 0.6812 - prc: 0.5390 - val_loss: 0.5888 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.7185 - val_prc: 0.6326
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 68/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.5919 - tp: 9.0000 - fp: 7.0000 - tn: 29.0000 - fn: 13.0000 - accuracy: 0.6552 - precision: 0.5625 - recall: 0.4091 - auc: 0.7348 - prc: 0.6161 - val_loss: 0.7248 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.6630 - val_prc: 0.5743
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 69/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.6469 - tp: 11.0000 - fp: 11.0000 - tn: 25.0000 - fn: 11.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.5000 - auc: 0.6364 - prc: 0.5145 - val_loss: 0.8186 - val_tp: 8.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4211 - val_recall: 0.8889 - val_auc: 0.5963 - val_prc: 0.5537
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 70/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6409 - tp: 5.0000 - fp: 6.0000 - tn: 30.0000 - fn: 17.0000 - accuracy: 0.6034 - precision: 0.4545 - recall: 0.2273 - auc: 0.6231 - prc: 0.4339 - val_loss: 0.7859 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.5407 - val_prc: 0.5091
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 71/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 205ms/step - loss: 0.6128 - tp: 11.0000 - fp: 6.0000 - tn: 30.0000 - fn: 11.0000 - accuracy: 0.7069 - precision: 0.6471 - recall: 0.5000 - auc: 0.7083 - prc: 0.6678 - val_loss: 0.9675 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6259 - val_prc: 0.5440
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 72/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6540 - tp: 9.0000 - fp: 7.0000 - tn: 29.0000 - fn: 13.0000 - accuracy: 0.6552 - precision: 0.5625 - recall: 0.4091 - auc: 0.5694 - prc: 0.5458 - val_loss: 1.0076 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7148 - val_prc: 0.5536
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 73/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.6401 - tp: 9.0000 - fp: 9.0000 - tn: 27.0000 - fn: 13.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.4091 - auc: 0.6414 - prc: 0.5230 - val_loss: 0.7720 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6852 - val_prc: 0.5312
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 74/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.6105 - tp: 6.0000 - fp: 4.0000 - tn: 32.0000 - fn: 16.0000 - accuracy: 0.6552 - precision: 0.6000 - recall: 0.2727 - auc: 0.6837 - prc: 0.5591 - val_loss: 0.6210 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7148 - val_prc: 0.5004
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 75/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6179 - tp: 9.0000 - fp: 7.0000 - tn: 29.0000 - fn: 13.0000 - accuracy: 0.6552 - precision: 0.5625 - recall: 0.4091 - auc: 0.6856 - prc: 0.5644 - val_loss: 0.9179 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.7000 - val_prc: 0.5459
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 76/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 207ms/step - loss: 0.5325 - tp: 11.0000 - fp: 8.0000 - tn: 28.0000 - fn: 11.0000 - accuracy: 0.6724 - precision: 0.5789 - recall: 0.5000 - auc: 0.7942 - prc: 0.6587 - val_loss: 1.1924 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.5667 - val_prc: 0.5299
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 77/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.6737 - tp: 8.0000 - fp: 7.0000 - tn: 29.0000 - fn: 14.0000 - accuracy: 0.6379 - precision: 0.5333 - recall: 0.3636 - auc: 0.5972 - prc: 0.4402 - val_loss: 0.7186 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6148 - val_prc: 0.5530
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 78/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 207ms/step - loss: 0.6254 - tp: 6.0000 - fp: 4.0000 - tn: 32.0000 - fn: 16.0000 - accuracy: 0.6552 - precision: 0.6000 - recall: 0.2727 - auc: 0.6610 - prc: 0.5580 - val_loss: 0.7345 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.6259 - val_prc: 0.5359
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 79/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6034 - tp: 6.0000 - fp: 5.0000 - tn: 31.0000 - fn: 16.0000 - accuracy: 0.6379 - precision: 0.5455 - recall: 0.2727 - auc: 0.7083 - prc: 0.6006 - val_loss: 0.6372 - val_tp: 7.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 2.0000 - val_accuracy: 0.6667 - val_precision: 0.5385 - val_recall: 0.7778 - val_auc: 0.6444 - val_prc: 0.5230
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 80/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.5715 - tp: 12.0000 - fp: 4.0000 - tn: 32.0000 - fn: 10.0000 - accuracy: 0.7586 - precision: 0.7500 - recall: 0.5455 - auc: 0.7393 - prc: 0.6489 - val_loss: 1.0162 - val_tp: 9.0000 - val_fp: 15.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.3750 - val_precision: 0.3750 - val_recall: 1.0000 - val_auc: 0.5407 - val_prc: 0.4858
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 81/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.5576 - tp: 12.0000 - fp: 8.0000 - tn: 28.0000 - fn: 10.0000 - accuracy: 0.6897 - precision: 0.6000 - recall: 0.5455 - auc: 0.7727 - prc: 0.6753 - val_loss: 0.8449 - val_tp: 8.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 1.0000 - val_accuracy: 0.4583 - val_precision: 0.4000 - val_recall: 0.8889 - val_auc: 0.5296 - val_prc: 0.4704
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 82/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 186ms/step - loss: 0.6260 - tp: 7.0000 - fp: 9.0000 - tn: 27.0000 - fn: 15.0000 - accuracy: 0.5862 - precision: 0.4375 - recall: 0.3182 - auc: 0.6705 - prc: 0.5344 - val_loss: 0.7249 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7333 - val_prc: 0.6488
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 83/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.6625 - tp: 9.0000 - fp: 7.0000 - tn: 29.0000 - fn: 13.0000 - accuracy: 0.6552 - precision: 0.5625 - recall: 0.4091 - auc: 0.5934 - prc: 0.5237 - val_loss: 0.6239 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6815 - val_prc: 0.4929
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 84/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 207ms/step - loss: 0.6588 - tp: 7.0000 - fp: 8.0000 - tn: 28.0000 - fn: 15.0000 - accuracy: 0.6034 - precision: 0.4667 - recall: 0.3182 - auc: 0.6136 - prc: 0.4304 - val_loss: 0.5812 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.6889 - val_prc: 0.5560
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 85/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.5769 - tp: 7.0000 - fp: 4.0000 - tn: 32.0000 - fn: 15.0000 - accuracy: 0.6724 - precision: 0.6364 - recall: 0.3182 - auc: 0.7923 - prc: 0.6225 - val_loss: 0.6539 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7815 - val_prc: 0.6941
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 86/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.6371 - tp: 10.0000 - fp: 8.0000 - tn: 28.0000 - fn: 12.0000 - accuracy: 0.6552 - precision: 0.5556 - recall: 0.4545 - auc: 0.6553 - prc: 0.4990 - val_loss: 0.5598 - val_tp: 5.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 4.0000 - val_accuracy: 0.5833 - val_precision: 0.4545 - val_recall: 0.5556 - val_auc: 0.7111 - val_prc: 0.6067
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 87/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.6124 - tp: 11.0000 - fp: 8.0000 - tn: 28.0000 - fn: 11.0000 - accuracy: 0.6724 - precision: 0.5789 - recall: 0.5000 - auc: 0.7071 - prc: 0.5848 - val_loss: 0.7889 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.6926 - val_prc: 0.5178
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 88/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.5571 - tp: 13.0000 - fp: 7.0000 - tn: 29.0000 - fn: 9.0000 - accuracy: 0.7241 - precision: 0.6500 - recall: 0.5909 - auc: 0.7588 - prc: 0.6341 - val_loss: 0.9594 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.6667 - val_prc: 0.5001
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 89/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 206ms/step - loss: 0.5916 - tp: 11.0000 - fp: 10.0000 - tn: 26.0000 - fn: 11.0000 - accuracy: 0.6379 - precision: 0.5238 - recall: 0.5000 - auc: 0.7083 - prc: 0.6126 - val_loss: 0.6811 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7481 - val_prc: 0.7207
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 90/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.5792 - tp: 13.0000 - fp: 7.0000 - tn: 29.0000 - fn: 9.0000 - accuracy: 0.7241 - precision: 0.6500 - recall: 0.5909 - auc: 0.7468 - prc: 0.6888 - val_loss: 0.5624 - val_tp: 2.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 7.0000 - val_accuracy: 0.7083 - val_precision: 1.0000 - val_recall: 0.2222 - val_auc: 0.7407 - val_prc: 0.6354
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 91/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.6174 - tp: 8.0000 - fp: 7.0000 - tn: 29.0000 - fn: 14.0000 - accuracy: 0.6379 - precision: 0.5333 - recall: 0.3636 - auc: 0.6679 - prc: 0.5753 - val_loss: 0.6009 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7741 - val_prc: 0.6963
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 92/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.6138 - tp: 8.0000 - fp: 7.0000 - tn: 29.0000 - fn: 14.0000 - accuracy: 0.6379 - precision: 0.5333 - recall: 0.3636 - auc: 0.6774 - prc: 0.5170 - val_loss: 0.5624 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.7148 - val_prc: 0.6135
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 93/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.6290 - tp: 13.0000 - fp: 9.0000 - tn: 27.0000 - fn: 9.0000 - accuracy: 0.6897 - precision: 0.5909 - recall: 0.5909 - auc: 0.6806 - prc: 0.5072 - val_loss: 0.5822 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.7074 - val_prc: 0.5435
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 94/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 206ms/step - loss: 0.6012 - tp: 10.0000 - fp: 5.0000 - tn: 31.0000 - fn: 12.0000 - accuracy: 0.7069 - precision: 0.6667 - recall: 0.4545 - auc: 0.7115 - prc: 0.5411 - val_loss: 0.5738 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.7296 - val_prc: 0.6240
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 95/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.6244 - tp: 8.0000 - fp: 9.0000 - tn: 27.0000 - fn: 14.0000 - accuracy: 0.6034 - precision: 0.4706 - recall: 0.3636 - auc: 0.6742 - prc: 0.5485 - val_loss: 0.5757 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.7111 - val_prc: 0.5901
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 96/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.6106 - tp: 6.0000 - fp: 3.0000 - tn: 33.0000 - fn: 16.0000 - accuracy: 0.6724 - precision: 0.6667 - recall: 0.2727 - auc: 0.7033 - prc: 0.6131 - val_loss: 0.5921 - val_tp: 2.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 7.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.2222 - val_auc: 0.6519 - val_prc: 0.5283
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 97/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 187ms/step - loss: 0.6145 - tp: 9.0000 - fp: 7.0000 - tn: 29.0000 - fn: 13.0000 - accuracy: 0.6552 - precision: 0.5625 - recall: 0.4091 - auc: 0.6806 - prc: 0.5688 - val_loss: 0.6388 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 6.0000 - val_accuracy: 0.5833 - val_precision: 0.4286 - val_recall: 0.3333 - val_auc: 0.5630 - val_prc: 0.4780
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 98/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.6289 - tp: 5.0000 - fp: 8.0000 - tn: 28.0000 - fn: 17.0000 - accuracy: 0.5690 - precision: 0.3846 - recall: 0.2273 - auc: 0.6244 - prc: 0.4785 - val_loss: 0.7110 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6556 - val_prc: 0.6244
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 99/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 207ms/step - loss: 0.5653 - tp: 9.0000 - fp: 2.0000 - tn: 34.0000 - fn: 13.0000 - accuracy: 0.7414 - precision: 0.8182 - recall: 0.4091 - auc: 0.7765 - prc: 0.7518 - val_loss: 0.5964 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.6704 - val_prc: 0.5604
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 100/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.6159 - tp: 7.0000 - fp: 6.0000 - tn: 30.0000 - fn: 15.0000 - accuracy: 0.6379 - precision: 0.5385 - recall: 0.3182 - auc: 0.6856 - prc: 0.4980 - val_loss: 0.5476 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 6.0000 - val_accuracy: 0.6667 - val_precision: 0.6000 - val_recall: 0.3333 - val_auc: 0.7778 - val_prc: 0.7039
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 101/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.5697 - tp: 9.0000 - fp: 4.0000 - tn: 32.0000 - fn: 13.0000 - accuracy: 0.7069 - precision: 0.6923 - recall: 0.4091 - auc: 0.7494 - prc: 0.6223 - val_loss: 0.5477 - val_tp: 1.0000 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 8.0000 - val_accuracy: 0.6667 - val_precision: 1.0000 - val_recall: 0.1111 - val_auc: 0.7926 - val_prc: 0.6801
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 102/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.6199 - tp: 7.0000 - fp: 7.0000 - tn: 29.0000 - fn: 15.0000 - accuracy: 0.6207 - precision: 0.5000 - recall: 0.3182 - auc: 0.6660 - prc: 0.4526 - val_loss: 0.6044 - val_tp: 9.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6667 - val_precision: 0.5294 - val_recall: 1.0000 - val_auc: 0.6667 - val_prc: 0.5210
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 103/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.5188 - tp: 13.0000 - fp: 1.0000 - tn: 35.0000 - fn: 9.0000 - accuracy: 0.8276 - precision: 0.9286 - recall: 0.5909 - auc: 0.8365 - prc: 0.8287 - val_loss: 0.5609 - val_tp: 7.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 2.0000 - val_accuracy: 0.6667 - val_precision: 0.5385 - val_recall: 0.7778 - val_auc: 0.7481 - val_prc: 0.5854
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 104/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 207ms/step - loss: 0.5498 - tp: 10.0000 - fp: 6.0000 - tn: 30.0000 - fn: 12.0000 - accuracy: 0.6897 - precision: 0.6250 - recall: 0.4545 - auc: 0.7803 - prc: 0.6850 - val_loss: 0.5660 - val_tp: 7.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 2.0000 - val_accuracy: 0.6667 - val_precision: 0.5385 - val_recall: 0.7778 - val_auc: 0.7370 - val_prc: 0.5807
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 105/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.6338 - tp: 8.0000 - fp: 7.0000 - tn: 29.0000 - fn: 14.0000 - accuracy: 0.6379 - precision: 0.5333 - recall: 0.3636 - auc: 0.6313 - prc: 0.5414 - val_loss: 0.6451 - val_tp: 8.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.5417 - val_precision: 0.4444 - val_recall: 0.8889 - val_auc: 0.6778 - val_prc: 0.5501
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 106/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.5249 - tp: 12.0000 - fp: 6.0000 - tn: 30.0000 - fn: 10.0000 - accuracy: 0.7241 - precision: 0.6667 - recall: 0.5455 - auc: 0.8138 - prc: 0.7819 - val_loss: 0.5430 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.6852 - val_prc: 0.5312
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 107/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 186ms/step - loss: 0.5815 - tp: 15.0000 - fp: 10.0000 - tn: 26.0000 - fn: 7.0000 - accuracy: 0.7069 - precision: 0.6000 - recall: 0.6818 - auc: 0.7216 - prc: 0.5448 - val_loss: 0.8003 - val_tp: 8.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.5417 - val_precision: 0.4444 - val_recall: 0.8889 - val_auc: 0.6222 - val_prc: 0.5369
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 108/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.5578 - tp: 12.0000 - fp: 6.0000 - tn: 30.0000 - fn: 10.0000 - accuracy: 0.7241 - precision: 0.6667 - recall: 0.5455 - auc: 0.7620 - prc: 0.6217 - val_loss: 0.8668 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7333 - val_prc: 0.5797
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 109/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 208ms/step - loss: 0.5450 - tp: 14.0000 - fp: 6.0000 - tn: 30.0000 - fn: 8.0000 - accuracy: 0.7586 - precision: 0.7000 - recall: 0.6364 - auc: 0.7847 - prc: 0.7347 - val_loss: 0.5321 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.7630 - val_prc: 0.5972
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 110/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.5715 - tp: 14.0000 - fp: 7.0000 - tn: 29.0000 - fn: 8.0000 - accuracy: 0.7414 - precision: 0.6667 - recall: 0.6364 - auc: 0.7582 - prc: 0.6544 - val_loss: 0.5747 - val_tp: 2.0000 - val_fp: 1.0000 - val_tn: 14.0000 - val_fn: 7.0000 - val_accuracy: 0.6667 - val_precision: 0.6667 - val_recall: 0.2222 - val_auc: 0.7148 - val_prc: 0.5994
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 111/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 186ms/step - loss: 0.5356 - tp: 14.0000 - fp: 5.0000 - tn: 31.0000 - fn: 8.0000 - accuracy: 0.7759 - precision: 0.7368 - recall: 0.6364 - auc: 0.8087 - prc: 0.7395 - val_loss: 0.5713 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.7037 - val_prc: 0.6061
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 112/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.5344 - tp: 11.0000 - fp: 4.0000 - tn: 32.0000 - fn: 11.0000 - accuracy: 0.7414 - precision: 0.7333 - recall: 0.5000 - auc: 0.7923 - prc: 0.7589 - val_loss: 0.5548 - val_tp: 3.0000 - val_fp: 2.0000 - val_tn: 13.0000 - val_fn: 6.0000 - val_accuracy: 0.6667 - val_precision: 0.6000 - val_recall: 0.3333 - val_auc: 0.7148 - val_prc: 0.5722
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 113/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 186ms/step - loss: 0.4920 - tp: 16.0000 - fp: 6.0000 - tn: 30.0000 - fn: 6.0000 - accuracy: 0.7931 - precision: 0.7273 - recall: 0.7273 - auc: 0.8586 - prc: 0.8224 - val_loss: 0.5397 - val_tp: 3.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 6.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.3333 - val_auc: 0.7370 - val_prc: 0.5998
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 114/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.6154 - tp: 8.0000 - fp: 5.0000 - tn: 31.0000 - fn: 14.0000 - accuracy: 0.6724 - precision: 0.6154 - recall: 0.3636 - auc: 0.6888 - prc: 0.5479 - val_loss: 0.9068 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.6407 - val_prc: 0.5192
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 115/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 207ms/step - loss: 0.5012 - tp: 14.0000 - fp: 5.0000 - tn: 31.0000 - fn: 8.0000 - accuracy: 0.7759 - precision: 0.7368 - recall: 0.6364 - auc: 0.8750 - prc: 0.8653 - val_loss: 0.7173 - val_tp: 8.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.5417 - val_precision: 0.4444 - val_recall: 0.8889 - val_auc: 0.6741 - val_prc: 0.5405
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 116/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 207ms/step - loss: 0.5362 - tp: 13.0000 - fp: 5.0000 - tn: 31.0000 - fn: 9.0000 - accuracy: 0.7586 - precision: 0.7222 - recall: 0.5909 - auc: 0.7746 - prc: 0.7763 - val_loss: 0.6689 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.6889 - val_prc: 0.5579
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 117/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 206ms/step - loss: 0.5471 - tp: 14.0000 - fp: 7.0000 - tn: 29.0000 - fn: 8.0000 - accuracy: 0.7414 - precision: 0.6667 - recall: 0.6364 - auc: 0.7929 - prc: 0.6062 - val_loss: 0.9950 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6704 - val_prc: 0.5921
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 118/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.5357 - tp: 13.0000 - fp: 8.0000 - tn: 28.0000 - fn: 9.0000 - accuracy: 0.7069 - precision: 0.6190 - recall: 0.5909 - auc: 0.8087 - prc: 0.7147 - val_loss: 0.6493 - val_tp: 9.0000 - val_fp: 8.0000 - val_tn: 7.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.6667 - val_precision: 0.5294 - val_recall: 1.0000 - val_auc: 0.6963 - val_prc: 0.5473
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 119/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.4701 - tp: 15.0000 - fp: 5.0000 - tn: 31.0000 - fn: 7.0000 - accuracy: 0.7931 - precision: 0.7500 - recall: 0.6818 - auc: 0.8725 - prc: 0.8120 - val_loss: 0.5653 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.7407 - val_prc: 0.6079
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 120/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.5085 - tp: 15.0000 - fp: 9.0000 - tn: 27.0000 - fn: 7.0000 - accuracy: 0.7241 - precision: 0.6250 - recall: 0.6818 - auc: 0.8277 - prc: 0.8029 - val_loss: 0.7471 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 15.0000 - val_fn: 9.0000 - val_accuracy: 0.6250 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7259 - val_prc: 0.6723
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 121/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.4898 - tp: 16.0000 - fp: 4.0000 - tn: 32.0000 - fn: 6.0000 - accuracy: 0.8276 - precision: 0.8000 - recall: 0.7273 - auc: 0.8371 - prc: 0.7237 - val_loss: 0.6696 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7333 - val_prc: 0.6027
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 122/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.5793 - tp: 12.0000 - fp: 9.0000 - tn: 27.0000 - fn: 10.0000 - accuracy: 0.6724 - precision: 0.5714 - recall: 0.5455 - auc: 0.7330 - prc: 0.5865 - val_loss: 0.5316 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.7519 - val_prc: 0.6179
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 123/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 208ms/step - loss: 0.5606 - tp: 11.0000 - fp: 5.0000 - tn: 31.0000 - fn: 11.0000 - accuracy: 0.7241 - precision: 0.6875 - recall: 0.5000 - auc: 0.7481 - prc: 0.6783 - val_loss: 0.5416 - val_tp: 7.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.7778 - val_auc: 0.7667 - val_prc: 0.6311
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 124/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.5782 - tp: 11.0000 - fp: 8.0000 - tn: 28.0000 - fn: 11.0000 - accuracy: 0.6724 - precision: 0.5789 - recall: 0.5000 - auc: 0.7424 - prc: 0.6540 - val_loss: 0.5523 - val_tp: 4.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 5.0000 - val_accuracy: 0.5833 - val_precision: 0.4444 - val_recall: 0.4444 - val_auc: 0.6963 - val_prc: 0.5483
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 125/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 187ms/step - loss: 0.5540 - tp: 15.0000 - fp: 5.0000 - tn: 31.0000 - fn: 7.0000 - accuracy: 0.7931 - precision: 0.7500 - recall: 0.6818 - auc: 0.7664 - prc: 0.6315 - val_loss: 0.6888 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.7185 - val_prc: 0.6165
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 126/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 186ms/step - loss: 0.4999 - tp: 16.0000 - fp: 5.0000 - tn: 31.0000 - fn: 6.0000 - accuracy: 0.8103 - precision: 0.7619 - recall: 0.7273 - auc: 0.8359 - prc: 0.8347 - val_loss: 0.6917 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7370 - val_prc: 0.6028
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 127/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.5091 - tp: 14.0000 - fp: 8.0000 - tn: 28.0000 - fn: 8.0000 - accuracy: 0.7241 - precision: 0.6364 - recall: 0.6364 - auc: 0.8182 - prc: 0.7421 - val_loss: 0.5726 - val_tp: 7.0000 - val_fp: 7.0000 - val_tn: 8.0000 - val_fn: 2.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.7778 - val_auc: 0.7630 - val_prc: 0.6269
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 128/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 186ms/step - loss: 0.5261 - tp: 12.0000 - fp: 8.0000 - tn: 28.0000 - fn: 10.0000 - accuracy: 0.6897 - precision: 0.6000 - recall: 0.5455 - auc: 0.8011 - prc: 0.6893 - val_loss: 0.5381 - val_tp: 4.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 5.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.4444 - val_auc: 0.7407 - val_prc: 0.5803
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 129/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.5419 - tp: 10.0000 - fp: 6.0000 - tn: 30.0000 - fn: 12.0000 - accuracy: 0.6897 - precision: 0.6250 - recall: 0.4545 - auc: 0.7866 - prc: 0.7089 - val_loss: 0.6339 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.7148 - val_prc: 0.5883
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 130/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 189ms/step - loss: 0.5201 - tp: 14.0000 - fp: 6.0000 - tn: 30.0000 - fn: 8.0000 - accuracy: 0.7586 - precision: 0.7000 - recall: 0.6364 - auc: 0.8150 - prc: 0.7406 - val_loss: 0.7827 - val_tp: 8.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 1.0000 - val_accuracy: 0.5417 - val_precision: 0.4444 - val_recall: 0.8889 - val_auc: 0.6963 - val_prc: 0.5670
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 131/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.5769 - tp: 10.0000 - fp: 8.0000 - tn: 28.0000 - fn: 12.0000 - accuracy: 0.6552 - precision: 0.5556 - recall: 0.4545 - auc: 0.7393 - prc: 0.5730 - val_loss: 0.7029 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7556 - val_prc: 0.5191
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 132/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 211ms/step - loss: 0.4640 - tp: 16.0000 - fp: 6.0000 - tn: 30.0000 - fn: 6.0000 - accuracy: 0.7931 - precision: 0.7273 - recall: 0.7273 - auc: 0.8592 - prc: 0.7727 - val_loss: 0.6821 - val_tp: 9.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5833 - val_precision: 0.4737 - val_recall: 1.0000 - val_auc: 0.7296 - val_prc: 0.5268
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 133/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.4724 - tp: 15.0000 - fp: 4.0000 - tn: 32.0000 - fn: 7.0000 - accuracy: 0.8103 - precision: 0.7895 - recall: 0.6818 - auc: 0.8567 - prc: 0.8352 - val_loss: 0.9136 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6778 - val_prc: 0.5550
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 134/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 206ms/step - loss: 0.4977 - tp: 12.0000 - fp: 4.0000 - tn: 32.0000 - fn: 10.0000 - accuracy: 0.7586 - precision: 0.7500 - recall: 0.5455 - auc: 0.8232 - prc: 0.7806 - val_loss: 0.7380 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.6444 - val_prc: 0.4939
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 135/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.4914 - tp: 13.0000 - fp: 5.0000 - tn: 31.0000 - fn: 9.0000 - accuracy: 0.7586 - precision: 0.7222 - recall: 0.5909 - auc: 0.8295 - prc: 0.8147 - val_loss: 0.7016 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.6741 - val_prc: 0.4743
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 136/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.4006 - tp: 18.0000 - fp: 6.0000 - tn: 30.0000 - fn: 4.0000 - accuracy: 0.8276 - precision: 0.7500 - recall: 0.8182 - auc: 0.9160 - prc: 0.8728 - val_loss: 0.8513 - val_tp: 7.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 2.0000 - val_accuracy: 0.5417 - val_precision: 0.4375 - val_recall: 0.7778 - val_auc: 0.6704 - val_prc: 0.4851
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 137/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 185ms/step - loss: 0.4486 - tp: 14.0000 - fp: 5.0000 - tn: 31.0000 - fn: 8.0000 - accuracy: 0.7759 - precision: 0.7368 - recall: 0.6364 - auc: 0.8586 - prc: 0.8096 - val_loss: 0.9344 - val_tp: 6.0000 - val_fp: 10.0000 - val_tn: 5.0000 - val_fn: 3.0000 - val_accuracy: 0.4583 - val_precision: 0.3750 - val_recall: 0.6667 - val_auc: 0.5889 - val_prc: 0.4850
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 138/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.5557 - tp: 13.0000 - fp: 7.0000 - tn: 29.0000 - fn: 9.0000 - accuracy: 0.7241 - precision: 0.6500 - recall: 0.5909 - auc: 0.7740 - prc: 0.7189 - val_loss: 0.7317 - val_tp: 6.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 3.0000 - val_accuracy: 0.5000 - val_precision: 0.4000 - val_recall: 0.6667 - val_auc: 0.6185 - val_prc: 0.5282
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 139/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 208ms/step - loss: 0.5169 - tp: 12.0000 - fp: 5.0000 - tn: 31.0000 - fn: 10.0000 - accuracy: 0.7414 - precision: 0.7059 - recall: 0.5455 - auc: 0.7955 - prc: 0.7069 - val_loss: 0.5705 - val_tp: 3.0000 - val_fp: 4.0000 - val_tn: 11.0000 - val_fn: 6.0000 - val_accuracy: 0.5833 - val_precision: 0.4286 - val_recall: 0.3333 - val_auc: 0.7296 - val_prc: 0.6653
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 140/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.4208 - tp: 16.0000 - fp: 4.0000 - tn: 32.0000 - fn: 6.0000 - accuracy: 0.8276 - precision: 0.8000 - recall: 0.7273 - auc: 0.8902 - prc: 0.8377 - val_loss: 0.7661 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.7111 - val_prc: 0.6723
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 141/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.4170 - tp: 17.0000 - fp: 6.0000 - tn: 30.0000 - fn: 5.0000 - accuracy: 0.8103 - precision: 0.7391 - recall: 0.7727 - auc: 0.8996 - prc: 0.8173 - val_loss: 1.0633 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.6667 - val_prc: 0.4958
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 142/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 186ms/step - loss: 0.4598 - tp: 13.0000 - fp: 4.0000 - tn: 32.0000 - fn: 9.0000 - accuracy: 0.7759 - precision: 0.7647 - recall: 0.5909 - auc: 0.8504 - prc: 0.8274 - val_loss: 0.9489 - val_tp: 9.0000 - val_fp: 12.0000 - val_tn: 3.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5000 - val_precision: 0.4286 - val_recall: 1.0000 - val_auc: 0.6185 - val_prc: 0.4544
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 143/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 183ms/step - loss: 0.4329 - tp: 16.0000 - fp: 6.0000 - tn: 30.0000 - fn: 6.0000 - accuracy: 0.7931 - precision: 0.7273 - recall: 0.7273 - auc: 0.8782 - prc: 0.8446 - val_loss: 0.9654 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.6778 - val_prc: 0.5528
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 144/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 200ms/step - loss: 0.4520 - tp: 16.0000 - fp: 4.0000 - tn: 32.0000 - fn: 6.0000 - accuracy: 0.8276 - precision: 0.8000 - recall: 0.7273 - auc: 0.8611 - prc: 0.7639 - val_loss: 1.3029 - val_tp: 9.0000 - val_fp: 13.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.4583 - val_precision: 0.4091 - val_recall: 1.0000 - val_auc: 0.6185 - val_prc: 0.5865
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 145/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 198ms/step - loss: 0.4697 - tp: 18.0000 - fp: 9.0000 - tn: 27.0000 - fn: 4.0000 - accuracy: 0.7759 - precision: 0.6667 - recall: 0.8182 - auc: 0.8409 - prc: 0.7420 - val_loss: 0.8416 - val_tp: 8.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 1.0000 - val_accuracy: 0.5000 - val_precision: 0.4211 - val_recall: 0.8889 - val_auc: 0.6000 - val_prc: 0.5343
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 146/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 6s 216ms/step - loss: 0.4762 - tp: 13.0000 - fp: 4.0000 - tn: 32.0000 - fn: 9.0000 - accuracy: 0.7759 - precision: 0.7647 - recall: 0.5909 - auc: 0.8396 - prc: 0.7806 - val_loss: 0.7761 - val_tp: 8.0000 - val_fp: 9.0000 - val_tn: 6.0000 - val_fn: 1.0000 - val_accuracy: 0.5833 - val_precision: 0.4706 - val_recall: 0.8889 - val_auc: 0.6889 - val_prc: 0.5789
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 147/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.3946 - tp: 16.0000 - fp: 3.0000 - tn: 33.0000 - fn: 6.0000 - accuracy: 0.8448 - precision: 0.8421 - recall: 0.7273 - auc: 0.9091 - prc: 0.8527 - val_loss: 0.5931 - val_tp: 6.0000 - val_fp: 5.0000 - val_tn: 10.0000 - val_fn: 3.0000 - val_accuracy: 0.6667 - val_precision: 0.5455 - val_recall: 0.6667 - val_auc: 0.7111 - val_prc: 0.5656
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 148/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 182ms/step - loss: 0.4193 - tp: 18.0000 - fp: 3.0000 - tn: 33.0000 - fn: 4.0000 - accuracy: 0.8793 - precision: 0.8571 - recall: 0.8182 - auc: 0.9003 - prc: 0.9016 - val_loss: 0.6307 - val_tp: 4.0000 - val_fp: 3.0000 - val_tn: 12.0000 - val_fn: 5.0000 - val_accuracy: 0.6667 - val_precision: 0.5714 - val_recall: 0.4444 - val_auc: 0.6815 - val_prc: 0.6220
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 149/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 181ms/step - loss: 0.5422 - tp: 14.0000 - fp: 9.0000 - tn: 27.0000 - fn: 8.0000 - accuracy: 0.7069 - precision: 0.6087 - recall: 0.6364 - auc: 0.7734 - prc: 0.7439 - val_loss: 0.6075 - val_tp: 6.0000 - val_fp: 6.0000 - val_tn: 9.0000 - val_fn: 3.0000 - val_accuracy: 0.6250 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6778 - val_prc: 0.4324
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Epoch 150/150
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 29/29 [==============================] - 5s 184ms/step - loss: 0.4843 - tp: 13.0000 - fp: 4.0000 - tn: 32.0000 - fn: 9.0000 - accuracy: 0.7759 - precision: 0.7647 - recall: 0.5909 - auc: 0.8308 - prc: 0.7820 - val_loss: 0.7802 - val_tp: 9.0000 - val_fp: 11.0000 - val_tn: 4.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.5417 - val_precision: 0.4500 - val_recall: 1.0000 - val_auc: 0.7185 - val_prc: 0.6671
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/div>
&lt;h2 id="performance-evaluation">Performance evaluation&lt;/h2>
&lt;p>Once the training is completed, the model performance can be plotted. Since the validation set is unbalanced, as already specified, the ROC AUC is used to provide a representation of the model&amp;rsquo;s performance.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">fig&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ax&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">subplots&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">figsize&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ax&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ax&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ravel&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metric&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="s2">&amp;#34;auc&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;val_auc&amp;#34;&lt;/span>&lt;span class="p">]):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">label&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">history&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">performance&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">items&lt;/span>&lt;span class="p">():&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">ax&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">plot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">history&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">history&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">metric&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">ax&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_title&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;Model &lt;/span>&lt;span class="si">{}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">format&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">metric&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">ax&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_xlabel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;epochs&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">ax&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_ylabel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">metric&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">ax&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_ylim&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="mf">0.2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">ax&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">legend&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">performance&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">keys&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_88_0_hu16f3f076f57d40a685396504a44d4f91_212619_7fc740f4e4be3a7b85746f9b9a43e89c.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_88_0_hu16f3f076f57d40a685396504a44d4f91_212619_b8e5a4b358dcad1685b63f51d6bf2a59.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_88_0_hu16f3f076f57d40a685396504a44d4f91_212619_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_88_0_hu16f3f076f57d40a685396504a44d4f91_212619_7fc740f4e4be3a7b85746f9b9a43e89c.webp"
width="760"
height="220"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">fig&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ax&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">subplots&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">figsize&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">5&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ax&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ax&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ravel&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metric&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="s2">&amp;#34;loss&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;val_loss&amp;#34;&lt;/span>&lt;span class="p">]):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">label&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">history&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">performance&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">items&lt;/span>&lt;span class="p">():&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">ax&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">plot&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">history&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">history&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">metric&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">ax&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_title&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;Model &lt;/span>&lt;span class="si">{}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">format&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">metric&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">ax&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_xlabel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;epochs&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">ax&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">set_ylabel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">metric&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">ax&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">legend&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">performance&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">keys&lt;/span>&lt;span class="p">())&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_89_0_hu57839307438c9e5612cb6a4f785a90df_220283_db09dbdeec224cef75b871fd263271ec.webp 400w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_89_0_hu57839307438c9e5612cb6a4f785a90df_220283_c1f88533282770954ddef347df459a74.webp 760w,
/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_89_0_hu57839307438c9e5612cb6a4f785a90df_220283_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0100-brain-stroke-detection-3d-cnn/brain_stroke_detection_3d_cnn_files/brain_stroke_detection_3d_cnn_89_0_hu57839307438c9e5612cb6a4f785a90df_220283_db09dbdeec224cef75b871fd263271ec.webp"
width="760"
height="220"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://keras.io/examples/vision/3D_image_classification/" target="_blank" rel="noopener">3D image classification from CT scans&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://vincentblog.xyz/posts/medical-images-in-python-computed-tomography" target="_blank" rel="noopener">Medical Images In python (Computed Tomography)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.imaios.com/en/resources/blog/ai-for-medical-imaging-data-augmentation" target="_blank" rel="noopener">Data augmentation for medical image analysis in deep learning&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>DICOM images in Python: An overview</title><link>https://www.peco602.com/post/0090-python-dicom/</link><pubDate>Thu, 23 Feb 2023 00:00:00 +0000</pubDate><guid>https://www.peco602.com/post/0090-python-dicom/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>DICOM or Digital Imaging and Communications in medicine are image files sourced from different modalities, e.g., CT or MRI scans, and based on an &lt;a href="https://www.dicomstandard.org/" target="_blank" rel="noopener">international standard&lt;/a> to transmit, store, retrieve, print, process, and display medical imaging information. DICOM files do not only contain the image, but also additional data, such as the patient identifier, date of birth, age, sex, and any other useful information about the diagnosis. Obviousely, DICOM files cannot be viewed as normal photos, so several DICOM viewers are available online (a list is available &lt;a href="https://technologyadvice.com/blog/healthcare/5-dicom-viewers/" target="_blank" rel="noopener">here&lt;/a>), but, as always, Python can be very powerful in case additional processing is needed.&lt;/p>
&lt;h2 id="pre-requisites">Pre-requisites&lt;/h2>
&lt;p>First, the following libraries are required:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;a href="https://pypi.org/project/pydicom/" target="_blank" rel="noopener">Pydicom&lt;/a>&lt;/strong>: DICOM files reading and decoding library&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://numpy.org/install/" target="_blank" rel="noopener">Numpy&lt;/a>&lt;/strong>:Array manipulation library&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://pypi.org/project/Pillow/2.2.2/" target="_blank" rel="noopener">Pillow&lt;/a>&lt;/strong>: Image processing library&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://matplotlib.org/stable/users/installing/index.html" target="_blank" rel="noopener">Matplotlib&lt;/a>&lt;/strong>: Image visualization library&lt;/li>
&lt;/ul>
&lt;p>and can be easily installed via the command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">pip install pydicom numpy pillow matplotlib
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="data-structure">Data structure&lt;/h2>
&lt;p>Once the Python environment is ready and a DICOM file is available, it can be read via the &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.filereader.dcmread.html#pydicom.filereader.dcmread" target="_blank" rel="noopener">&lt;code>dcmread()&lt;/code>&lt;/a> method.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pydicom&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">dcmread&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">DICOM_PATH&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;/home/user/Desktop/exam/MD44PKO2/T2T5OLJX/I7600000&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ds&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dcmread&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">DICOM_PATH&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">type&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>pydicom.dataset.FileDataset
&lt;/code>&lt;/pre>
&lt;p>This method returns a &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.dataset.FileDataset.html#pydicom.dataset.FileDataset" target="_blank" rel="noopener">&lt;code>FileDataset&lt;/code>&lt;/a> instance, which in turn represents an extension of &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.dataset.Dataset.html#pydicom.dataset.Dataset" target="_blank" rel="noopener">&lt;code>Dataset&lt;/code>&lt;/a> class. It makes reading and writing to file easier and wraps a dictionary of &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.dataelem.DataElement.html#pydicom.dataelem.DataElement" target="_blank" rel="noopener">&lt;code>DataElement&lt;/code>&lt;/a>. A &lt;code>DataElement&lt;/code> is then composed of the following parts:&lt;/p>
&lt;ul>
&lt;li>a &lt;code>tag&lt;/code> that identifies the attribute, usually in the format (XXXX,XXXX) with hexadecimal numbers, and may be divided further into DICOM Group Number and DICOM Element Number;&lt;/li>
&lt;li>a &lt;code>Value Representation (VR)&lt;/code> that describes the data type and format of the attribute value.&lt;/li>
&lt;li>a &lt;code>Value Multiplicity (VM)&lt;/code> that is automatically determined from the contents of the value.&lt;/li>
&lt;li>a &lt;code>value&lt;/code> which can be one of:
&lt;ul>
&lt;li>a regular numeric, string or text value as an int, float, str, bytes, etc&lt;/li>
&lt;li>a list of regular values (if &lt;code>VM&lt;/code>&amp;gt;1)&lt;/li>
&lt;li>a &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.sequence.Sequence.html#pydicom.sequence.Sequence" target="_blank" rel="noopener">&lt;code>Sequence&lt;/code>&lt;/a> instance, where a &lt;code>Sequence&lt;/code> is a list of &lt;code>Dataset&lt;/code> instances, where each Dataset contains DataElement instances, and so on&amp;hellip;&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>You can display the entire dataset by simply printing its string (str or repr) value:&lt;/p>
&lt;!-- ```python
# TO BE COMMENTED
ds.remove_private_tags()
ds.PatientName = 'ROSSI^MARIO'
ds.PatientID = '99999999'
ds.PatientBirthDate = '19330101'
ds.PatientAge = '090Y'
ds.PatientAddress = 'XXXXXXXXXX'
ds.InstitutionName = 'XXXXXXXXXX'
ds.InstitutionAddress = 'XXXXXXXXXX'
``` -->
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>Dataset.file_meta -------------------------------
(0002, 0000) File Meta Information Group Length UL: 168
(0002, 0001) File Meta Information Version OB: b'\x00\x01'
(0002, 0002) Media Storage SOP Class UID UI: CT Image Storage
(0002, 0003) Media Storage SOP Instance UID UI: 1.3.12.2.1107.5.1.4.55050.30000022121515300815600002074
(0002, 0010) Transfer Syntax UID UI: Explicit VR Little Endian
(0002, 0012) Implementation Class UID UI: 1.2.840.113704.7.0.2
-------------------------------------------------
(0008, 0008) Image Type CS: ['DERIVED', 'SECONDARY', 'OTHER', 'CSA MPR', 'CSAPARALLEL', 'AXIAL', 'CT_SOM5 SEQ']
(0008, 0016) SOP Class UID UI: CT Image Storage
(0008, 0018) SOP Instance UID UI: 1.3.12.2.1107.5.1.4.55050.30000022121515300815600002074
(0008, 0020) Study Date DA: '20221215'
(0008, 0021) Series Date DA: '20221215'
(0008, 0022) Acquisition Date DA: '20221215'
(0008, 0023) Content Date DA: '20221215'
(0008, 0030) Study Time TM: '162614'
(0008, 0031) Series Time TM: '163202'
(0008, 0032) Acquisition Time TM: '162821.901196'
(0008, 0033) Content Time TM: '163202.921000'
(0008, 0050) Accession Number SH: '5895682501'
(0008, 0060) Modality CS: 'CT'
(0008, 0061) Modalities in Study CS: ['CT', 'SR']
(0008, 0070) Manufacturer LO: 'SIEMENS'
(0008, 0080) Institution Name LO: 'XXXXXXXXXX'
(0008, 0081) Institution Address ST: 'XXXXXXXXXX'
(0008, 0090) Referring Physician's Name PN: 'MEDICO^REFERTANTE'
(0008, 1010) Station Name SH: 'CT55050'
(0008, 1030) Study Description LO: 'TC CRANIO (CAPO)'
(0008, 1032) Procedure Code Sequence 1 item(s) ----
(0008, 0100) Code Value SH: 'RS0932'
(0008, 0104) Code Meaning LO: 'TC CRANIO (CAPO)'
---------
(0008, 103e) Series Description LO: 'ax ok'
(0008, 1048) Physician(s) of Record PN: '10440^NEUROLOGIA'
(0008, 1070) Operators' Name PN: 'meduser'
(0008, 1080) Admitting Diagnoses Description LO: '-'
(0008, 1090) Manufacturer's Model Name LO: 'Sensation 64'
(0008, 1140) Referenced Image Sequence 1 item(s) ----
(0008, 1150) Referenced SOP Class UID UI: CT Image Storage
(0008, 1155) Referenced SOP Instance UID UI: 1.3.12.2.1107.5.1.4.55050.30000022121515300815600001998
---------
(0008, 2111) Derivation Description ST: 'MEDCOM RESAMPLED'
(0010, 0010) Patient's Name PN: 'ROSSI^MARIO'
(0010, 0020) Patient ID LO: '99999999'
(0010, 0021) Issuer of Patient ID LO: 'X1V1_MPI'
(0010, 0030) Patient's Birth Date DA: '19330101'
(0010, 0040) Patient's Sex CS: 'M'
(0010, 1010) Patient's Age AS: '090Y'
(0010, 1040) Patient's Address CS: 'XXXXXXXXXX'
(0018, 0015) Body Part Examined CS: 'HEAD'
(0018, 0050) Slice Thickness DS: '0.6'
(0018, 0060) KVP DS: '120.0'
(0018, 1000) Device Serial Number LO: '55050'
(0018, 1020) Software Versions LO: 'syngo CT 2014A'
(0018, 1030) Protocol Name LO: 'CBM_encefalo_SEQ'
(0018, 1110) Distance Source to Detector DS: '1040.0'
(0018, 1111) Distance Source to Patient DS: '570.0'
(0018, 1120) Gantry/Detector Tilt DS: '0.0'
(0018, 1130) Table Height DS: '255.0'
(0018, 1140) Rotation Direction CS: 'CW'
(0018, 1160) Filter Type SH: '0'
(0018, 1170) Generator Power IS: '45'
(0018, 1190) Focal Spot(s) DS: '1.2'
(0018, 1200) Date of Last Calibration DA: '20221215'
(0018, 1201) Time of Last Calibration TM: '073319.000000'
(0018, 1210) Convolution Kernel SH: 'H10s'
(0018, 5100) Patient Position CS: 'HFS'
(0020, 000d) Study Instance UID UI: 1.2.840.113564.9.1.2015111110072131.20221209153953.25895682501
(0020, 000e) Series Instance UID UI: 1.3.12.2.1107.5.1.4.55050.30000022121515300815600001997
(0020, 0010) Study ID SH: 'CT20221215162611'
(0020, 0011) Series Number IS: '604'
(0020, 0012) Acquisition Number IS: None
(0020, 0013) Instance Number IS: '76'
(0020, 0032) Image Position (Patient) DS: [-86.56525199874, -359.7734375, -75.906572657132]
(0020, 0037) Image Orientation (Patient) DS: [0.97661555018595, 1.224606354e-016, -0.2149931792755, -1.19596961e-016, 1, 2.632820134e-017]
(0020, 0052) Frame of Reference UID UI: 1.3.12.2.1107.5.1.4.55050.30000022121506293760900002193
(0020, 1040) Position Reference Indicator LO: ''
(0020, 1208) Number of Study Related Instances IS: '546'
(0020, 4000) Image Comments LT: ''
(0028, 0002) Samples per Pixel US: 1
(0028, 0004) Photometric Interpretation CS: 'MONOCHROME2'
(0028, 0010) Rows US: 512
(0028, 0011) Columns US: 512
(0028, 0030) Pixel Spacing DS: [0.453125, 0.453125]
(0028, 0100) Bits Allocated US: 16
(0028, 0101) Bits Stored US: 12
(0028, 0102) High Bit US: 11
(0028, 0103) Pixel Representation US: 0
(0028, 1050) Window Center DS: [35, 700]
(0028, 1051) Window Width DS: [80, 3200]
(0028, 1052) Rescale Intercept DS: '-1024.0'
(0028, 1053) Rescale Slope DS: '1.0'
(0028, 1054) Rescale Type LO: 'HU'
(0028, 1055) Window Center &amp;amp; Width Explanation LO: ['WINDOW1', 'WINDOW2']
(0028, 2110) Lossy Image Compression CS: '00'
(0032, 1032) Requesting Physician PN: '10440^NEUROLOGIA'
(0032, 1060) Requested Procedure Description LO: 'TC CRANIO (CAPO)'
(0032, 1064) Requested Procedure Code Sequence 1 item(s) ----
(0008, 0100) Code Value SH: 'RS0932'
(0008, 0104) Code Meaning LO: 'TC CRANIO (CAPO)'
---------
(0040, 0275) Request Attributes Sequence 1 item(s) ----
(0040, 0007) Scheduled Procedure Step Descriptio LO: 'TC CRANIO (CAPO)'
(0040, 0008) Scheduled Protocol Code Sequence 1 item(s) ----
(0008, 0100) Code Value SH: 'RS0932'
(0008, 0102) Coding Scheme Designator SH: 'DSS_MESA'
(0008, 0104) Code Meaning LO: 'TC CRANIO (CAPO)'
---------
(0040, 0009) Scheduled Procedure Step ID SH: '5895682501'
---------
(0040, 1008) Confidentiality Code LO: 'N'
(0088, 0200) Icon Image Sequence 1 item(s) ----
(0028, 0002) Samples per Pixel US: 1
(0028, 0004) Photometric Interpretation CS: 'MONOCHROME2'
(0028, 0010) Rows US: 64
(0028, 0011) Columns US: 64
(0028, 0034) Pixel Aspect Ratio IS: [1, 1]
(0028, 0100) Bits Allocated US: 8
(0028, 0101) Bits Stored US: 8
(0028, 0102) High Bit US: 7
(0028, 0103) Pixel Representation US: 0
(7fe0, 0010) Pixel Data OB: Array of 4096 elements
---------
(6000, 0010) Overlay Rows US: 512
(6000, 0011) Overlay Columns US: 512
(6000, 0015) Number of Frames in Overlay IS: '1'
(6000, 0022) Overlay Description LO: 'Siemens MedCom Object Graphics'
(6000, 0040) Overlay Type CS: 'G'
(6000, 0050) Overlay Origin SS: [1, 1]
(6000, 0051) Image Frame Origin US: 1
(6000, 0100) Overlay Bits Allocated US: 1
(6000, 0102) Overlay Bit Position US: 0
(6000, 3000) Overlay Data OW: Array of 32768 elements
(7fe0, 0010) Pixel Data OW: Array of 524288 elements
&lt;/code>&lt;/pre>
&lt;p>You can access specific elements by their DICOM keyword or tag number. When using the tag number, a &lt;code>DataElement&lt;/code> instance is returned, so &lt;code>DataElement.value&lt;/code> must be used to get the value.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>&lt;em>NOTE:&lt;/em>&lt;/strong> Some attributes values have been redacted or replaced with fake values for patient privacy.&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PatientName&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>'ROSSI^MARIO'
&lt;/code>&lt;/pre>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">ds&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mh">0x10&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mh">0x10&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">value&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>'ROSSI^MARIO'
&lt;/code>&lt;/pre>
&lt;p>If you dont remember or know the exact element tag or keyword, the &lt;code>Dataset&lt;/code> class provides a handy &lt;code>dir()&lt;/code> method, useful during interactive sessions at the Python prompt. It will return any non-private element keywords in the dataset that have the specified string anywhere in the keyword (case insensitive).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dir&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;pat&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>['DistanceSourceToPatient',
'ImageOrientationPatient',
'ImagePositionPatient',
'IssuerOfPatientID',
'PatientAddress',
'PatientAge',
'PatientBirthDate',
'PatientID',
'PatientName',
'PatientPosition',
'PatientSex']
&lt;/code>&lt;/pre>
&lt;p>Calling &lt;code>Dataset.dir()&lt;/code> without passing it an argument will return a list of all non-private element keywords in the dataset:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dir&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>['AccessionNumber',
'AcquisitionDate',
'AcquisitionNumber',
'AcquisitionTime',
'AdmittingDiagnosesDescription',
'BitsAllocated',
'BitsStored',
'BodyPartExamined',
'Columns',
'ConfidentialityCode',
'ContentDate',
'ContentTime',
'ConvolutionKernel',
'DateOfLastCalibration',
'DerivationDescription',
'DeviceSerialNumber',
'DistanceSourceToDetector',
'DistanceSourceToPatient',
'FilterType',
'FocalSpots',
'FrameOfReferenceUID',
'GantryDetectorTilt',
'GeneratorPower',
'HighBit',
'IconImageSequence',
'ImageComments',
'ImageFrameOrigin',
'ImageOrientationPatient',
'ImagePositionPatient',
'ImageType',
'InstanceNumber',
'InstitutionAddress',
'InstitutionName',
'IssuerOfPatientID',
'KVP',
'LossyImageCompression',
'Manufacturer',
'ManufacturerModelName',
'ModalitiesInStudy',
'Modality',
'NumberOfFramesInOverlay',
'NumberOfStudyRelatedInstances',
'OperatorsName',
'OverlayBitPosition',
'OverlayBitsAllocated',
'OverlayColumns',
'OverlayData',
'OverlayDescription',
'OverlayOrigin',
'OverlayRows',
'OverlayType',
'PatientAddress',
'PatientAge',
'PatientBirthDate',
'PatientID',
'PatientName',
'PatientPosition',
'PatientSex',
'PhotometricInterpretation',
'PhysiciansOfRecord',
'PixelData',
'PixelRepresentation',
'PixelSpacing',
'PositionReferenceIndicator',
'ProcedureCodeSequence',
'ProtocolName',
'ReferencedImageSequence',
'ReferringPhysicianName',
'RequestAttributesSequence',
'RequestedProcedureCodeSequence',
'RequestedProcedureDescription',
'RequestingPhysician',
'RescaleIntercept',
'RescaleSlope',
'RescaleType',
'RotationDirection',
'Rows',
'SOPClassUID',
'SOPInstanceUID',
'SamplesPerPixel',
'SeriesDate',
'SeriesDescription',
'SeriesInstanceUID',
'SeriesNumber',
'SeriesTime',
'SliceThickness',
'SoftwareVersions',
'StationName',
'StudyDate',
'StudyDescription',
'StudyID',
'StudyInstanceUID',
'StudyTime',
'TableHeight',
'TimeOfLastCalibration',
'WindowCenter',
'WindowCenterWidthExplanation',
'WindowWidth']
&lt;/code>&lt;/pre>
&lt;blockquote>
&lt;p>&lt;strong>&lt;em>NOTE:&lt;/em>&lt;/strong> You can also view DICOM files in a collapsible tree using the example program &lt;a href="https://github.com/pydicom/contrib-pydicom/blob/master/plotting-visualization/dcm_qt_tree.py" target="_blank" rel="noopener">dcm_qt_tree.py&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;h2 id="image-visualization">Image visualization&lt;/h2>
&lt;p>DICOM images pixel data is stored as raw bytes in the &lt;code>DataElement&lt;/code> associated to the &lt;code>PixelData&lt;/code> tag. &lt;code>PixelData&lt;/code> is often not immediately useful as data may be stored in a variety of different ways:&lt;/p>
&lt;ul>
&lt;li>The pixel values may be signed or unsigned integers, or floats&lt;/li>
&lt;li>There may be multiple image frames&lt;/li>
&lt;li>There may be multiple planes per frame (i.e., RGB) and the order of the pixels may be different&lt;/li>
&lt;li>The image data may be encoded using one of the available compression standards (1.2.840.10008.1.2.4.50 JPEG Baseline, 1.2.840.10008.1.2.5 RLE Lossless, etc). Encoded image data will also be encapsulated and each encapsulated image frame may be broken up into one or more fragments.&lt;/li>
&lt;/ul>
&lt;p>Because of the complexity in interpreting the pixel data, pydicom provides an easy way to get it in a convenient form: &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.dataset.Dataset.html#pydicom.dataset.Dataset.pixel_array" target="_blank" rel="noopener">&lt;code>Dataset.pixel_array&lt;/code>&lt;/a>. As an example, if the pixel data is compressed then &lt;code>pixel_array&lt;/code> will directly return the uncompressed data.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">matplotlib.pyplot&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">plt&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pixel_array&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bone&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>&amp;lt;matplotlib.image.AxesImage at 0x7f5625845280&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0090-python-dicom/dicom_files/dicom_17_1_hu5cd3fcbac50ea0a3e37b2b8c02f36615_76432_a0d4e1be83f4cb0c55f87b7f4904ed80.webp 400w,
/post/0090-python-dicom/dicom_files/dicom_17_1_hu5cd3fcbac50ea0a3e37b2b8c02f36615_76432_bfde284ff4ca51548ee97668ef0a8d7e.webp 760w,
/post/0090-python-dicom/dicom_files/dicom_17_1_hu5cd3fcbac50ea0a3e37b2b8c02f36615_76432_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0090-python-dicom/dicom_files/dicom_17_1_hu5cd3fcbac50ea0a3e37b2b8c02f36615_76432_a0d4e1be83f4cb0c55f87b7f4904ed80.webp"
width="430"
height="418"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>As it is possible to see, the picture details are not well-defined so the information content is quite poor. The following additional DICOM post-processing should be &lt;strong>sequentially&lt;/strong> performed in order to enhance the image content.&lt;/p>
&lt;h3 id="1-color-palette">1. Color Palette&lt;/h3>
&lt;p>Some DICOM datasets store their output image pixel values in a lookup table (LUT), where the values in Pixel Data are the index to a corresponding LUT entry. When a datasets (0028,0004) Photometric Interpretation value is PALETTE COLOR then the &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.pixel_data_handlers.util.html#pydicom.pixel_data_handlers.util.apply_color_lut" target="_blank" rel="noopener">&lt;code>apply_color_lut()&lt;/code>&lt;/a> function can be used to apply a palette color LUT to the pixel data to produce an RGB image.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pydicom.pixel_data_handlers.util&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">apply_color_lut&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;(0028,0004) Photometric Interpretation: &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mh">0x28&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mh">0x4&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">value&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">rgb&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">apply_color_lut&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">rgb&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bone&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">except&lt;/span> &lt;span class="ne">Exception&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">e&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>(0028,0004) Photometric Interpretation: MONOCHROME2
No suitable Palette Color Lookup Table Module found
&lt;/code>&lt;/pre>
&lt;p>This was expected since the &lt;em>Photometric Interpretation&lt;/em> is &lt;em>MONOCHROME2&lt;/em>, so no suitable Palette Color Lookup Table Module could found and the &lt;code>apply_color_lut&lt;/code> method fails.&lt;/p>
&lt;h3 id="2-modality-lut-or-rescale-operation">2. Modality LUT or Rescale Operation&lt;/h3>
&lt;p>The DICOM &lt;a href="http://dicom.nema.org/medical/dicom/current/output/chtml/part03/sect_C.11.html#sect_C.11.1" target="_blank" rel="noopener">Modality LUT&lt;/a> module converts raw pixel data values to a specific (possibly unitless) physical quantity, such as Hounsfield units for CT scan (as in this case). The &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.pixel_data_handlers.util.html#pydicom.pixel_data_handlers.util.apply_voi_lut" target="_blank" rel="noopener">&lt;code>apply_modality_lut()&lt;/code>&lt;/a> function can be used with an input array of raw values and a dataset containing a Modality LUT module to return the converted values. When a dataset requires multiple grayscale transformations, the Modality LUT transformation is always applied first.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pydicom.pixel_data_handlers.util&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">apply_modality_lut&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pixel_array&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">hu&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">apply_modality_lut&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">hu&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bone&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>&amp;lt;matplotlib.image.AxesImage at 0x7f5621d45d60&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0090-python-dicom/dicom_files/dicom_23_1_hu5cd3fcbac50ea0a3e37b2b8c02f36615_76432_7f7e419c08ca4d6a615088a8bc0c5603.webp 400w,
/post/0090-python-dicom/dicom_files/dicom_23_1_hu5cd3fcbac50ea0a3e37b2b8c02f36615_76432_ecb72cbaa6e095d8999258131f5453ec.webp 760w,
/post/0090-python-dicom/dicom_files/dicom_23_1_hu5cd3fcbac50ea0a3e37b2b8c02f36615_76432_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0090-python-dicom/dicom_files/dicom_23_1_hu5cd3fcbac50ea0a3e37b2b8c02f36615_76432_7f7e419c08ca4d6a615088a8bc0c5603.webp"
width="430"
height="418"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>The image has not visually changed, but the pixel values have been correctly transformed into Hounsfield units.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">max&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>(0, 2335)
&lt;/code>&lt;/pre>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">hu&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">max&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">hu&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>(-1024.0, 1311.0)
&lt;/code>&lt;/pre>
&lt;h3 id="3-voi-lut-or-windowing-operation">3. VOI LUT or Windowing Operation&lt;/h3>
&lt;p>The DICOM &lt;a href="http://dicom.nema.org/medical/dicom/current/output/chtml/part03/sect_C.11.2.html" target="_blank" rel="noopener">VOI LUT&lt;/a> module applies a VOI or windowing operation to input values. The &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.pixel_data_handlers.util.html#pydicom.pixel_data_handlers.util.apply_voi_lut" target="_blank" rel="noopener">&lt;code>apply_voi_lut()&lt;/code>&lt;/a> function can be used with an input array and a dataset containing a VOI LUT module to return values with applied VOI LUT or windowing. When a dataset contains multiple VOI or windowing views then a particular view can be returned by using the index keyword parameter. In this case the index &lt;code>0&lt;/code> will be used.&lt;/p>
&lt;p>When a dataset requires multiple grayscale transformations, then its assumed that the modality LUT or rescale operation has already been applied.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pydicom.pixel_data_handlers.util&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">apply_voi_lut&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">out&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">apply_voi_lut&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">hu&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">index&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">out&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bone&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>&amp;lt;matplotlib.image.AxesImage at 0x7f5621ab8c40&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0090-python-dicom/dicom_files/dicom_28_1_huf447e093701c4bcb4834419a79ca0b5d_92272_cf1702a0385e32544cc75cd0037f9df4.webp 400w,
/post/0090-python-dicom/dicom_files/dicom_28_1_huf447e093701c4bcb4834419a79ca0b5d_92272_a7c221cdea1e0f4c5712617f3d9b6522.webp 760w,
/post/0090-python-dicom/dicom_files/dicom_28_1_huf447e093701c4bcb4834419a79ca0b5d_92272_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0090-python-dicom/dicom_files/dicom_28_1_huf447e093701c4bcb4834419a79ca0b5d_92272_cf1702a0385e32544cc75cd0037f9df4.webp"
width="430"
height="418"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Got it! The sequence of pre-processing steps has deeply enhanced the details of the CT scan contained in the DICOM file. At this point, the image can be definitely visually analyzed.&lt;/p>
&lt;h2 id="image-export">Image export&lt;/h2>
&lt;p>As already discussed, DICOM files contain not only image data, but also lots of ancillary information. It has also been demonstrated the image may not be immediately usable without some processing. DICOM images are not accessible without specific viewers and the image exchange may be even more difficult since different viewers may differently process the images. A possible solution could be to convert the DICOM file into a standard exchange format, e.g., JPEG or PNG.&lt;/p>
&lt;p>The starting point is the pre-processed image &lt;code>out&lt;/code>. The first step is to convert pixel data to &lt;code>float&lt;/code> in order to avoid overflow or underflow losses during image scaling.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">new_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">astype&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">float&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Pixel data is currently expressed in Hounsfield units, but it must rescaled into the &lt;code>[0, 255]&lt;/code> interval and then converted to 8 bits unsigned integer.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">PIL&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">Image&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">scaled_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">maximum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">new_image&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">new_image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">max&lt;/span>&lt;span class="p">())&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mf">255.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">scaled_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">uint8&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">scaled_image&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">final_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">fromarray&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">scaled_image&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The image can then be easily saved in &lt;code>jpg&lt;/code> or &lt;code>png&lt;/code> format.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">final_image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;dicom.jpg&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">final_image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;dicom.png&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>As a test, it is possible to import and plot the just saved &lt;code>jpg&lt;/code> image.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">img&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">asarray&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;dicom.jpg&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">img&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bone&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>&amp;lt;matplotlib.image.AxesImage at 0x7f5621a34cd0&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0090-python-dicom/dicom_files/dicom_39_1_hu8a1cc0d0a0d51869e683fa2ca2d58092_98210_9fd570e07dd83a10d9acd04b9bf9d909.webp 400w,
/post/0090-python-dicom/dicom_files/dicom_39_1_hu8a1cc0d0a0d51869e683fa2ca2d58092_98210_4f288a8f75b4a28c411e0b6c418dd9a1.webp 760w,
/post/0090-python-dicom/dicom_files/dicom_39_1_hu8a1cc0d0a0d51869e683fa2ca2d58092_98210_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0090-python-dicom/dicom_files/dicom_39_1_hu8a1cc0d0a0d51869e683fa2ca2d58092_98210_9fd570e07dd83a10d9acd04b9bf9d909.webp"
width="430"
height="418"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h2 id="dicom-file-sets-and-dicomdir">DICOM File-sets and DICOMDIR&lt;/h2>
&lt;p>A File-set is a collection of DICOM files that share a common naming space. Most people have probably interacted with a File-set without being aware of it; one place theyre frequently used is on the CDs/DVDs containing DICOM data that are given to a patient after a medical procedure (such as an MR or ultrasound). The specification for File-sets is given in&lt;a href="http://dicom.nema.org/medical/dicom/current/output/chtml/part10/chapter_8.html" target="_blank" rel="noopener">Part 10 of the DICOM Standard&lt;/a>.&lt;/p>
&lt;p>Every File-set must contain a single file with the filename&lt;strong>&lt;code>DICOMDIR&lt;/code>&lt;/strong>, the location of which is dependent on the type of media used to store the File-set. For the most commonly used media (DVD, CD, USB, PC file system, etc), the DICOMDIR file will be in the root directory of the File-set. For other media types,&lt;a href="http://dicom.nema.org/medical/dicom/current/output/chtml/part12/ps3.12.html" target="_blank" rel="noopener">Part 12 of the DICOM Standard&lt;/a> specifies where the DICOMDIR must be located.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>&lt;em>NOTE:&lt;/em>&lt;/strong> Despite its name, a DICOMDIR file is not a file system directory and can be read using &lt;code>dcmread()&lt;/code> like any other DICOM dataset&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">DICOMDIR_PATH&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;/home/user/Desktop/exam/DICOMDIR&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ds&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dcmread&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">DICOMDIR_PATH&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">type&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>pydicom.dicomdir.DicomDir
&lt;/code>&lt;/pre>
&lt;p>The most important element in a DICOMDIR is the (0004,1220) &lt;em>Directory Record Sequence&lt;/em>: each item in the sequence is a directory record, and one or more records are used to briefly describe an available item, i.e., the so called SOP Instance, and its location within the File-sets directory structure. Each record has a record type given by the (0004,1430) &lt;em>Directory Record Type&lt;/em> element, and different records are related to each other using the hierarchy given in &lt;a href="https://dicom.nema.org/medical/dicom/current/output/chtml/part03/sect_F.4.html#table_F.4-1" target="_blank" rel="noopener">Table F.4-1&lt;/a>. As examples, it is possible to go through some directory records:&lt;/p>
&lt;!-- ```python
# TO BE COMMENTED
ds.DirectoryRecordSequence[0].PatientName = 'ROSSI^MARIO'
ds.DirectoryRecordSequence[0].PatientID = '99999999'
ds.DirectoryRecordSequence[0].PatientBirthDate = '19330101'
``` -->
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DirectoryRecordSequence&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>(0004, 1400) Offset of the Next Directory Record UL: 0
(0004, 1410) Record In-use Flag US: 65535
(0004, 1420) Offset of Referenced Lower-Level Di UL: 500
(0004, 1430) Directory Record Type CS: 'PATIENT'
(0010, 0010) Patient's Name PN: 'ROSSI^MARIO'
(0010, 0020) Patient ID LO: '99999999'
(0010, 0021) Issuer of Patient ID LO: 'X1V1_MPI'
(0010, 0030) Patient's Birth Date DA: '19330101'
(0010, 0040) Patient's Sex CS: 'M'
&lt;/code>&lt;/pre>
&lt;p>This is a &lt;code>PATIENT&lt;/code> record which provides details about the patient, such as &lt;em>Patient&amp;rsquo;s Name&lt;/em> and &lt;em>Patient ID&lt;/em> (refer to &lt;a href="http://dicom.nema.org/medical/dicom/current/output/chtml/part03/sect_F.5.html#table_F.5-1" target="_blank" rel="noopener">Table F.5-1&lt;/a>).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DirectoryRecordSequence&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>(0004, 1400) Offset of the Next Directory Record UL: 0
(0004, 1410) Record In-use Flag US: 65535
(0004, 1420) Offset of Referenced Lower-Level Di UL: 956
(0004, 1430) Directory Record Type CS: 'STUDY'
(0008, 0020) Study Date DA: '20221215'
(0008, 0030) Study Time TM: '162614'
(0008, 0050) Accession Number SH: '5895682501'
(0008, 0061) Modalities in Study CS: 'CT'
(0008, 0090) Referring Physician's Name PN: 'MEDICO^REFERTANTE'
(0008, 1030) Study Description LO: 'TC CRANIO (CAPO)'
(0020, 000d) Study Instance UID UI: 1.2.840.113564.9.1.2015111110072131.20221209153953.25895682501
(0020, 0010) Study ID SH: 'CT20221215162611'
(0020, 1206) Number of Study Related Series IS: '5'
(0020, 1208) Number of Study Related Instances IS: '545'
(07a1, 0010) Private Creator LO: 'ELSCINT1'
(07a1, 1040) [Tamar Study Body Part] CS: 'ABDOMEN'
(07a3, 0010) Private Creator LO: 'ELSCINT1'
(07a3, 1069) Private tag data OB: Array of 98 elements
&lt;/code>&lt;/pre>
&lt;p>This is a &lt;code>STUDY&lt;/code> record, where details such as acquisition date, time and description are included (refer to &lt;a href="https://dicom.nema.org/medical/dicom/current/output/chtml/part03/sect_F.5.2.html" target="_blank" rel="noopener">Table F.5-2&lt;/a>).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DirectoryRecordSequence&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>(0004, 1400) Offset of the Next Directory Record UL: 6032
(0004, 1410) Record In-use Flag US: 65535
(0004, 1420) Offset of Referenced Lower-Level Di UL: 1214
(0004, 1430) Directory Record Type CS: 'SERIES'
(0008, 0021) Series Date DA: '20221215'
(0008, 0031) Series Time TM: '162644'
(0008, 0060) Modality CS: 'CT'
(0008, 103e) Series Description LO: 'Topogram 0.6 T20s'
(0018, 0015) Body Part Examined CS: 'ABDOMEN'
(0018, 1030) Protocol Name LO: 'CBM_encefalo_SEQ'
(0020, 000e) Series Instance UID UI: 1.3.12.2.1107.5.1.4.55050.30000022121508001632800000005
(0020, 0011) Series Number IS: '1'
(0020, 1209) Number of Series Related Instances IS: '1'
&lt;/code>&lt;/pre>
&lt;p>The &lt;code>SERIES&lt;/code> record adds details about the acquisition modality, i.e., &lt;code>CT&lt;/code>, and the examined body part, i.e., &lt;code>ABDOMEN&lt;/code> (refer to &lt;a href="https://dicom.nema.org/medical/dicom/current/output/chtml/part03/sect_F.5.3.html" target="_blank" rel="noopener">Table F.5-3&lt;/a>).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DirectoryRecordSequence&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>(0004, 1400) Offset of the Next Directory Record UL: 0
(0004, 1410) Record In-use Flag US: 65535
(0004, 1420) Offset of Referenced Lower-Level Di UL: 0
(0004, 1430) Directory Record Type CS: 'IMAGE'
(0004, 1500) Referenced File ID CS: ['MD44PKO2', 'OBGUOM0I', 'I1000000']
(0004, 1510) Referenced SOP Class UID in File UI: CT Image Storage
(0004, 1511) Referenced SOP Instance UID in File UI: 1.3.12.2.1107.5.1.4.55050.30000022121506293760900002194
(0004, 1512) Referenced Transfer Syntax UID in F UI: Explicit VR Little Endian
(0008, 0008) Image Type CS: ['ORIGINAL', 'PRIMARY', 'LOCALIZER', 'CT_SOM5 TOP']
(0008, 0016) SOP Class UID UI: CT Image Storage
(0008, 0018) SOP Instance UID UI: 1.3.12.2.1107.5.1.4.55050.30000022121506293760900002194
(0008, 0023) Content Date DA: '20221215'
(0008, 0033) Content Time TM: '162704.453698'
(0008, 0060) Modality CS: 'CT'
(0018, 0010) Contrast/Bolus Agent LO: ''
(0020, 0013) Instance Number IS: '1'
(0020, 0052) Frame of Reference UID UI: 1.3.12.2.1107.5.1.4.55050.30000022121506293760900002193
(0020, 1041) Slice Location DS: '-14.5'
(0028, 0002) Samples per Pixel US: 1
(0028, 0004) Photometric Interpretation CS: 'MONOCHROME2'
(0028, 0010) Rows US: 512
(0028, 0011) Columns US: 512
(0028, 0100) Bits Allocated US: 16
(0088, 0200) Icon Image Sequence 1 item(s) ----
(0028, 0002) Samples per Pixel US: 1
(0028, 0004) Photometric Interpretation CS: 'MONOCHROME2'
(0028, 0010) Rows US: 64
(0028, 0011) Columns US: 64
(0028, 0034) Pixel Aspect Ratio IS: [1, 1]
(0028, 0100) Bits Allocated US: 8
(0028, 0101) Bits Stored US: 8
(0028, 0102) High Bit US: 7
(0028, 0103) Pixel Representation US: 0
(7fe0, 0010) Pixel Data OB: Array of 4096 elements
---------
(00e1, 0010) Private Creator LO: 'ELSCINT1'
(00e1, 1040) [Image Label] SH: ''
&lt;/code>&lt;/pre>
&lt;p>Last but not least, the &lt;code>IMAGE&lt;/code> record contains all the image data, i.e., &lt;code>Pixel Data&lt;/code>, and metadata, e.g., &lt;code>Bits Allocated&lt;/code>, &lt;code>Photometric Interpretation&lt;/code>.&lt;/p>
&lt;p>While its possible to access everything within a File-set using the DICOMDIR dataset, making changes to an existing File-set quickly becomes complicated due to the need to add and remove directory records, recalculate the byte offsets for existing records and manage the corresponding file system changes. A more user-friendly way to interact with one is via the &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.fileset.FileSet.html#pydicom.fileset.FileSet" target="_blank" rel="noopener">FileSet&lt;/a> class.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pydicom.fileset&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">FileSet&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">fs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">FileSet&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">type&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>pydicom.fileset.FileSet
&lt;/code>&lt;/pre>
&lt;p>An overview of the File-sets contents is shown when printing:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>DICOM File-set
Root directory: /home/user/Desktop/exam
File-set ID: (no value available)
File-set UID: 1.2.840.113704.7.1.0.12118132138452.1672763590.1000003
Descriptor file ID: (no value available)
Descriptor file character set: (no value available)
Changes staged for write(): DICOMDIR update, directory structure update
Managed instances:
PATIENT: PatientID='99999999', PatientName='ROSSI^MARIO'
STUDY: StudyDate=20221215, StudyTime=162614, StudyDescription='TC CRANIO (CAPO)'
SERIES: Modality=CT, SeriesNumber=1
IMAGE: 1 SOP Instance
SERIES: Modality=CT, SeriesNumber=2
IMAGE: 66 SOP Instances
SERIES: Modality=CT, SeriesNumber=602
IMAGE: 199 SOP Instances
SERIES: Modality=CT, SeriesNumber=603
IMAGE: 143 SOP Instances
SERIES: Modality=CT, SeriesNumber=604
IMAGE: 136 SOP Instances
&lt;/code>&lt;/pre>
&lt;p>which basically provides a brief summary of the directory records previously introduced.&lt;/p>
&lt;h2 id="conclusions">Conclusions&lt;/h2>
&lt;p>This post has provided a wide overview of DICOM images in Python in particular about:&lt;/p>
&lt;ul>
&lt;li>DICOM data structure&lt;/li>
&lt;li>DICOM image visualization (and pre-processing)&lt;/li>
&lt;li>DICOM image export&lt;/li>
&lt;li>DICOM file-sets and DICOMDIR&lt;/li>
&lt;/ul>
&lt;p>As a summary, the following script summarizes all the introduced concepts since it allows to read a &lt;code>DICOMDIR&lt;/code> file (via the &lt;code>DICOMDIR_PATH&lt;/code> variable) and convert all the SOP instances to JPEG images. The exported images will be saved to a specific path based on specific metadata, i.e., &lt;code>{OUTPUT_PATH}/{patient_id}/{study_date}/{series_number}/{instance_number}.jpg&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">os&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">PIL&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">Image&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pydicom&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">dcmread&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pydicom.fileset&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">FileSet&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pydicom.pixel_data_handlers.util&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">apply_color_lut&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">apply_modality_lut&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">apply_voi_lut&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">DICOMDIR_PATH&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;/home/user/Desktop/exam/DICOMDIR&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">OUTPUT_PATH&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;/home/user/Desktop/exam_converted&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># DICOMDIR reading&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ds&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dcmread&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">DICOMDIR_PATH&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">fs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">FileSet&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Iterating over the FileSet instances&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">instance&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">fs&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Loading the corresponding SOP Instance dataset&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">ds&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">instance&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">load&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Getting instance metadata to categorize images&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">patient_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PatientID&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">study_date&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StudyDate&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">series_number&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SeriesNumber&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">instance_number&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">InstanceNumber&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Getting instance pixel data&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pixel_array&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Applying color palette (if available)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">apply_color_lut&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">except&lt;/span> &lt;span class="ne">Exception&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">pass&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Applying modality LUT&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">hu&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">apply_modality_lut&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Applying VOI LUT&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">out&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">apply_voi_lut&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">hu&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">index&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Rescaling pixel data&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">new_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">astype&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">float&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">scaled_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">maximum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">new_image&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">new_image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">max&lt;/span>&lt;span class="p">())&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mf">255.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">scaled_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">uint8&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">scaled_image&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">final_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">fromarray&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">scaled_image&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Exporting image in JPEG format&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">IMAGE_PATH&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">OUTPUT_PATH&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sep&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">patient_id&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sep&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">study_date&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sep&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">series_number&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">makedirs&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">IMAGE_PATH&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">exist_ok&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">OUTPUT_IMAGE&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">IMAGE_PATH&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sep&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">instance_number&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">.jpg&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">final_image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">OUTPUT_IMAGE&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="references">References&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.dicomstandard.org/" target="_blank" rel="noopener">Digital Image and Communications in Medicine&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://pydicom.github.io/pydicom/stable/" target="_blank" rel="noopener">pydicom documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://medium.com/analytics-vidhya/dicom-and-deep-learning-63373e99d79a" target="_blank" rel="noopener">Extract DICOM Images Only for Deep Learning | by Nawaf Alageel | Analytics Vidhya | Medium&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mscipio.github.io/post/read_dicom_files_in_python/" target="_blank" rel="noopener">How to read DICOM files into Python | MICHELE SCIPIONI (mscipio.github.io)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://pycad.co/how-to-convert-a-dicom-image-into-jpg-or-png/" target="_blank" rel="noopener">How To Convert a DICOM Image Into JPG or PNG - PYCAD&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>