<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Python | Giovanni Pecoraro</title><link>https://www.peco602.com/tag/python/</link><atom:link href="https://www.peco602.com/tag/python/index.xml" rel="self" type="application/rss+xml"/><description>Python</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 15 Mar 2023 00:00:00 +0000</lastBuildDate><image><url>https://www.peco602.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Python</title><link>https://www.peco602.com/tag/python/</link></image><item><title>Archive-To-Images</title><link>https://www.peco602.com/project/0050-archive-to-images/</link><pubDate>Wed, 15 Mar 2023 00:00:00 +0000</pubDate><guid>https://www.peco602.com/project/0050-archive-to-images/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>Since some cloud providers offer free unlimited picture-only storage, the &lt;strong>Archive-To-Images&lt;/strong> library allows to convert any collection of files into pictures to be uploaded without any additional cost.&lt;/p>
&lt;h2 id="installation">Installation&lt;/h2>
&lt;p>The package can be easily installed via &lt;code>pip&lt;/code> package manager:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ pip install archive-to-images
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="usage-as-cli">Usage as CLI&lt;/h2>
&lt;h3 id="transform-to-images">Transform to images&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ archive-to-images transform --help
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Usage: archive-to-images transform &lt;span class="o">[&lt;/span>OPTIONS&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Transforms an archive into multiple images.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">│ * --path -p TEXT Path containing data to be archived. &lt;span class="o">[&lt;/span>default: None&lt;span class="o">]&lt;/span> &lt;span class="o">[&lt;/span>required&lt;span class="o">]&lt;/span> │
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">│ * --name -n TEXT Name of the archive. &lt;span class="o">[&lt;/span>default: None&lt;span class="o">]&lt;/span> &lt;span class="o">[&lt;/span>required&lt;span class="o">]&lt;/span> │
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">│ --size -s &lt;span class="o">[&lt;/span>0.5&lt;span class="p">|&lt;/span>1&lt;span class="p">|&lt;/span>2&lt;span class="p">|&lt;/span>5&lt;span class="p">|&lt;/span>10&lt;span class="o">]&lt;/span> Maximum size of an image in MB. &lt;span class="o">[&lt;/span>default: 1&lt;span class="o">]&lt;/span> │
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">│ --encrypt -e Protect archive with password. │
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">│ --verbose -v Enable verbose output. │
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">│ --help Show this message and exit. │
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Create an image collection from data contained in multiple paths.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ archive-to-images transform --path /home/alice/Desktop --path /home/alice/Documents --name ARCHIVE_ALICE
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Set the maximum image size in MB (default: 1):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ archive-to-images transform --path /home/alice/Desktop --path /home/alice/Documents --name ARCHIVE_ALICE -s &lt;span class="m">5&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Encrypt data with a password:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ archive-to-images transform --path /home/alice/Desktop --path /home/alice/Documents --name ARCHIVE_ALICE -s &lt;span class="m">5&lt;/span> -e
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="restore-from-images">Restore from images&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ archive-to-images restore --help
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Usage: archive-to-images restore &lt;span class="o">[&lt;/span>OPTIONS&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Restores an archive from multiple images.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">╭─ Options ────────────────────────────────────────────────────────────────────────────────────────────────────────────╮
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">│ * --path -p TEXT Path containing images to be processed. &lt;span class="o">[&lt;/span>default: None&lt;span class="o">]&lt;/span> &lt;span class="o">[&lt;/span>required&lt;span class="o">]&lt;/span> │
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">│ --verbose -v Enable verbose output. │
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">│ --help Show this message and exit. │
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Restore the archives stored in image collections:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ archive-to-images restore --path /home/alice/Downloads/Album1 --path /home/alice/Downloads/Album2
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The library will automatically find all the archives stored in the images and will output a &lt;code>zip&lt;/code> archive for each one.&lt;/p>
&lt;h2 id="usage-as-docker">Usage as docker&lt;/h2>
&lt;p>Run the docker image and bind the current folder to the &lt;code>workspace&lt;/code> path inside the container:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ docker run -it --rm -v &lt;span class="k">$(&lt;/span>&lt;span class="nb">pwd&lt;/span>&lt;span class="k">)&lt;/span>:/workspace peco602/archive_to_images:latest bash
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>then it is possible to use the CLI directly from the container bash.&lt;/p></description></item><item><title>DICOM images in Python: An overview</title><link>https://www.peco602.com/post/0090-python-dicom/</link><pubDate>Thu, 23 Feb 2023 00:00:00 +0000</pubDate><guid>https://www.peco602.com/post/0090-python-dicom/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>DICOM or Digital Imaging and Communications in medicine are image files sourced from different modalities, e.g., CT or MRI scans, and based on an &lt;a href="https://www.dicomstandard.org/" target="_blank" rel="noopener">international standard&lt;/a> to transmit, store, retrieve, print, process, and display medical imaging information. DICOM files do not only contain the image, but also additional data, such as the patient identifier, date of birth, age, sex, and any other useful information about the diagnosis. Obviousely, DICOM files cannot be viewed as normal photos, so several DICOM viewers are available online (a list is available &lt;a href="https://technologyadvice.com/blog/healthcare/5-dicom-viewers/" target="_blank" rel="noopener">here&lt;/a>), but, as always, Python can be very powerful in case additional processing is needed.&lt;/p>
&lt;h2 id="pre-requisites">Pre-requisites&lt;/h2>
&lt;p>First, the following libraries are required:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;a href="https://pypi.org/project/pydicom/" target="_blank" rel="noopener">Pydicom&lt;/a>&lt;/strong>: DICOM files reading and decoding library&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://numpy.org/install/" target="_blank" rel="noopener">Numpy&lt;/a>&lt;/strong>: Array manipulation library&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://pypi.org/project/Pillow/2.2.2/" target="_blank" rel="noopener">Pillow&lt;/a>&lt;/strong>: Image processing library&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://matplotlib.org/stable/users/installing/index.html" target="_blank" rel="noopener">Matplotlib&lt;/a>&lt;/strong>: Image visualization library&lt;/li>
&lt;/ul>
&lt;p>and can be easily installed via the command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">pip install pydicom numpy pillow matplotlib
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="data-structure">Data structure&lt;/h2>
&lt;p>Once the Python environment is ready and a DICOM file is available, it can be read via the &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.filereader.dcmread.html#pydicom.filereader.dcmread" target="_blank" rel="noopener">&lt;code>dcmread()&lt;/code>&lt;/a> method.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pydicom&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">dcmread&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">DICOM_PATH&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;/home/user/Desktop/exam/MD44PKO2/T2T5OLJX/I7600000&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ds&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dcmread&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">DICOM_PATH&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">type&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>pydicom.dataset.FileDataset
&lt;/code>&lt;/pre>
&lt;p>This method returns a &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.dataset.FileDataset.html#pydicom.dataset.FileDataset" target="_blank" rel="noopener">&lt;code>FileDataset&lt;/code>&lt;/a> instance, which in turn represents an extension of &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.dataset.Dataset.html#pydicom.dataset.Dataset" target="_blank" rel="noopener">&lt;code>Dataset&lt;/code>&lt;/a> class. It makes reading and writing to file easier and wraps a dictionary of &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.dataelem.DataElement.html#pydicom.dataelem.DataElement" target="_blank" rel="noopener">&lt;code>DataElement&lt;/code>&lt;/a>. A &lt;code>DataElement&lt;/code> is then composed of the following parts:&lt;/p>
&lt;ul>
&lt;li>a &lt;code>tag&lt;/code> that identifies the attribute, usually in the format (XXXX,XXXX) with hexadecimal numbers, and may be divided further into DICOM Group Number and DICOM Element Number;&lt;/li>
&lt;li>a &lt;code>Value Representation (VR)&lt;/code> that describes the data type and format of the attribute value.&lt;/li>
&lt;li>a &lt;code>Value Multiplicity (VM)&lt;/code> that is automatically determined from the contents of the value.&lt;/li>
&lt;li>a &lt;code>value&lt;/code> which can be one of:
&lt;ul>
&lt;li>a regular numeric, string or text value as an int, float, str, bytes, etc&lt;/li>
&lt;li>a list of regular values (if &lt;code>VM&lt;/code>&amp;gt;1)&lt;/li>
&lt;li>a &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.sequence.Sequence.html#pydicom.sequence.Sequence" target="_blank" rel="noopener">&lt;code>Sequence&lt;/code>&lt;/a> instance, where a &lt;code>Sequence&lt;/code> is a list of &lt;code>Dataset&lt;/code> instances, where each Dataset contains DataElement instances, and so on&amp;hellip;&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>You can display the entire dataset by simply printing its string (str or repr) value:&lt;/p>
&lt;!-- ```python
# TO BE COMMENTED
ds.remove_private_tags()
ds.PatientName = 'ROSSI^MARIO'
ds.PatientID = '99999999'
ds.PatientBirthDate = '19330101'
ds.PatientAge = '090Y'
ds.PatientAddress = 'XXXXXXXXXX'
ds.InstitutionName = 'XXXXXXXXXX'
ds.InstitutionAddress = 'XXXXXXXXXX'
``` -->
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>Dataset.file_meta -------------------------------
(0002, 0000) File Meta Information Group Length UL: 168
(0002, 0001) File Meta Information Version OB: b'\x00\x01'
(0002, 0002) Media Storage SOP Class UID UI: CT Image Storage
(0002, 0003) Media Storage SOP Instance UID UI: 1.3.12.2.1107.5.1.4.55050.30000022121515300815600002074
(0002, 0010) Transfer Syntax UID UI: Explicit VR Little Endian
(0002, 0012) Implementation Class UID UI: 1.2.840.113704.7.0.2
-------------------------------------------------
(0008, 0008) Image Type CS: ['DERIVED', 'SECONDARY', 'OTHER', 'CSA MPR', 'CSAPARALLEL', 'AXIAL', 'CT_SOM5 SEQ']
(0008, 0016) SOP Class UID UI: CT Image Storage
(0008, 0018) SOP Instance UID UI: 1.3.12.2.1107.5.1.4.55050.30000022121515300815600002074
(0008, 0020) Study Date DA: '20221215'
(0008, 0021) Series Date DA: '20221215'
(0008, 0022) Acquisition Date DA: '20221215'
(0008, 0023) Content Date DA: '20221215'
(0008, 0030) Study Time TM: '162614'
(0008, 0031) Series Time TM: '163202'
(0008, 0032) Acquisition Time TM: '162821.901196'
(0008, 0033) Content Time TM: '163202.921000'
(0008, 0050) Accession Number SH: '5895682501'
(0008, 0060) Modality CS: 'CT'
(0008, 0061) Modalities in Study CS: ['CT', 'SR']
(0008, 0070) Manufacturer LO: 'SIEMENS'
(0008, 0080) Institution Name LO: 'XXXXXXXXXX'
(0008, 0081) Institution Address ST: 'XXXXXXXXXX'
(0008, 0090) Referring Physician's Name PN: 'MEDICO^REFERTANTE'
(0008, 1010) Station Name SH: 'CT55050'
(0008, 1030) Study Description LO: 'TC CRANIO (CAPO)'
(0008, 1032) Procedure Code Sequence 1 item(s) ----
(0008, 0100) Code Value SH: 'RS0932'
(0008, 0104) Code Meaning LO: 'TC CRANIO (CAPO)'
---------
(0008, 103e) Series Description LO: 'ax ok'
(0008, 1048) Physician(s) of Record PN: '10440^NEUROLOGIA'
(0008, 1070) Operators' Name PN: 'meduser'
(0008, 1080) Admitting Diagnoses Description LO: '-'
(0008, 1090) Manufacturer's Model Name LO: 'Sensation 64'
(0008, 1140) Referenced Image Sequence 1 item(s) ----
(0008, 1150) Referenced SOP Class UID UI: CT Image Storage
(0008, 1155) Referenced SOP Instance UID UI: 1.3.12.2.1107.5.1.4.55050.30000022121515300815600001998
---------
(0008, 2111) Derivation Description ST: 'MEDCOM RESAMPLED'
(0010, 0010) Patient's Name PN: 'ROSSI^MARIO'
(0010, 0020) Patient ID LO: '99999999'
(0010, 0021) Issuer of Patient ID LO: 'X1V1_MPI'
(0010, 0030) Patient's Birth Date DA: '19330101'
(0010, 0040) Patient's Sex CS: 'M'
(0010, 1010) Patient's Age AS: '090Y'
(0010, 1040) Patient's Address CS: 'XXXXXXXXXX'
(0018, 0015) Body Part Examined CS: 'HEAD'
(0018, 0050) Slice Thickness DS: '0.6'
(0018, 0060) KVP DS: '120.0'
(0018, 1000) Device Serial Number LO: '55050'
(0018, 1020) Software Versions LO: 'syngo CT 2014A'
(0018, 1030) Protocol Name LO: 'CBM_encefalo_SEQ'
(0018, 1110) Distance Source to Detector DS: '1040.0'
(0018, 1111) Distance Source to Patient DS: '570.0'
(0018, 1120) Gantry/Detector Tilt DS: '0.0'
(0018, 1130) Table Height DS: '255.0'
(0018, 1140) Rotation Direction CS: 'CW'
(0018, 1160) Filter Type SH: '0'
(0018, 1170) Generator Power IS: '45'
(0018, 1190) Focal Spot(s) DS: '1.2'
(0018, 1200) Date of Last Calibration DA: '20221215'
(0018, 1201) Time of Last Calibration TM: '073319.000000'
(0018, 1210) Convolution Kernel SH: 'H10s'
(0018, 5100) Patient Position CS: 'HFS'
(0020, 000d) Study Instance UID UI: 1.2.840.113564.9.1.2015111110072131.20221209153953.25895682501
(0020, 000e) Series Instance UID UI: 1.3.12.2.1107.5.1.4.55050.30000022121515300815600001997
(0020, 0010) Study ID SH: 'CT20221215162611'
(0020, 0011) Series Number IS: '604'
(0020, 0012) Acquisition Number IS: None
(0020, 0013) Instance Number IS: '76'
(0020, 0032) Image Position (Patient) DS: [-86.56525199874, -359.7734375, -75.906572657132]
(0020, 0037) Image Orientation (Patient) DS: [0.97661555018595, 1.224606354e-016, -0.2149931792755, -1.19596961e-016, 1, 2.632820134e-017]
(0020, 0052) Frame of Reference UID UI: 1.3.12.2.1107.5.1.4.55050.30000022121506293760900002193
(0020, 1040) Position Reference Indicator LO: ''
(0020, 1208) Number of Study Related Instances IS: '546'
(0020, 4000) Image Comments LT: ''
(0028, 0002) Samples per Pixel US: 1
(0028, 0004) Photometric Interpretation CS: 'MONOCHROME2'
(0028, 0010) Rows US: 512
(0028, 0011) Columns US: 512
(0028, 0030) Pixel Spacing DS: [0.453125, 0.453125]
(0028, 0100) Bits Allocated US: 16
(0028, 0101) Bits Stored US: 12
(0028, 0102) High Bit US: 11
(0028, 0103) Pixel Representation US: 0
(0028, 1050) Window Center DS: [35, 700]
(0028, 1051) Window Width DS: [80, 3200]
(0028, 1052) Rescale Intercept DS: '-1024.0'
(0028, 1053) Rescale Slope DS: '1.0'
(0028, 1054) Rescale Type LO: 'HU'
(0028, 1055) Window Center &amp;amp; Width Explanation LO: ['WINDOW1', 'WINDOW2']
(0028, 2110) Lossy Image Compression CS: '00'
(0032, 1032) Requesting Physician PN: '10440^NEUROLOGIA'
(0032, 1060) Requested Procedure Description LO: 'TC CRANIO (CAPO)'
(0032, 1064) Requested Procedure Code Sequence 1 item(s) ----
(0008, 0100) Code Value SH: 'RS0932'
(0008, 0104) Code Meaning LO: 'TC CRANIO (CAPO)'
---------
(0040, 0275) Request Attributes Sequence 1 item(s) ----
(0040, 0007) Scheduled Procedure Step Descriptio LO: 'TC CRANIO (CAPO)'
(0040, 0008) Scheduled Protocol Code Sequence 1 item(s) ----
(0008, 0100) Code Value SH: 'RS0932'
(0008, 0102) Coding Scheme Designator SH: 'DSS_MESA'
(0008, 0104) Code Meaning LO: 'TC CRANIO (CAPO)'
---------
(0040, 0009) Scheduled Procedure Step ID SH: '5895682501'
---------
(0040, 1008) Confidentiality Code LO: 'N'
(0088, 0200) Icon Image Sequence 1 item(s) ----
(0028, 0002) Samples per Pixel US: 1
(0028, 0004) Photometric Interpretation CS: 'MONOCHROME2'
(0028, 0010) Rows US: 64
(0028, 0011) Columns US: 64
(0028, 0034) Pixel Aspect Ratio IS: [1, 1]
(0028, 0100) Bits Allocated US: 8
(0028, 0101) Bits Stored US: 8
(0028, 0102) High Bit US: 7
(0028, 0103) Pixel Representation US: 0
(7fe0, 0010) Pixel Data OB: Array of 4096 elements
---------
(6000, 0010) Overlay Rows US: 512
(6000, 0011) Overlay Columns US: 512
(6000, 0015) Number of Frames in Overlay IS: '1'
(6000, 0022) Overlay Description LO: 'Siemens MedCom Object Graphics'
(6000, 0040) Overlay Type CS: 'G'
(6000, 0050) Overlay Origin SS: [1, 1]
(6000, 0051) Image Frame Origin US: 1
(6000, 0100) Overlay Bits Allocated US: 1
(6000, 0102) Overlay Bit Position US: 0
(6000, 3000) Overlay Data OW: Array of 32768 elements
(7fe0, 0010) Pixel Data OW: Array of 524288 elements
&lt;/code>&lt;/pre>
&lt;p>You can access specific elements by their DICOM keyword or tag number. When using the tag number, a &lt;code>DataElement&lt;/code> instance is returned, so &lt;code>DataElement.value&lt;/code> must be used to get the value.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>&lt;em>NOTE:&lt;/em>&lt;/strong> Some attributes values have been redacted or replaced with fake values for patient privacy.&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PatientName&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>'ROSSI^MARIO'
&lt;/code>&lt;/pre>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">ds&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mh">0x10&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mh">0x10&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">value&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>'ROSSI^MARIO'
&lt;/code>&lt;/pre>
&lt;p>If you don’t remember or know the exact element tag or keyword, the &lt;code>Dataset&lt;/code> class provides a handy &lt;code>dir()&lt;/code> method, useful during interactive sessions at the Python prompt. It will return any non-private element keywords in the dataset that have the specified string anywhere in the keyword (case insensitive).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dir&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;pat&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>['DistanceSourceToPatient',
'ImageOrientationPatient',
'ImagePositionPatient',
'IssuerOfPatientID',
'PatientAddress',
'PatientAge',
'PatientBirthDate',
'PatientID',
'PatientName',
'PatientPosition',
'PatientSex']
&lt;/code>&lt;/pre>
&lt;p>Calling &lt;code>Dataset.dir()&lt;/code> without passing it an argument will return a list of all non-private element keywords in the dataset:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">dir&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>['AccessionNumber',
'AcquisitionDate',
'AcquisitionNumber',
'AcquisitionTime',
'AdmittingDiagnosesDescription',
'BitsAllocated',
'BitsStored',
'BodyPartExamined',
'Columns',
'ConfidentialityCode',
'ContentDate',
'ContentTime',
'ConvolutionKernel',
'DateOfLastCalibration',
'DerivationDescription',
'DeviceSerialNumber',
'DistanceSourceToDetector',
'DistanceSourceToPatient',
'FilterType',
'FocalSpots',
'FrameOfReferenceUID',
'GantryDetectorTilt',
'GeneratorPower',
'HighBit',
'IconImageSequence',
'ImageComments',
'ImageFrameOrigin',
'ImageOrientationPatient',
'ImagePositionPatient',
'ImageType',
'InstanceNumber',
'InstitutionAddress',
'InstitutionName',
'IssuerOfPatientID',
'KVP',
'LossyImageCompression',
'Manufacturer',
'ManufacturerModelName',
'ModalitiesInStudy',
'Modality',
'NumberOfFramesInOverlay',
'NumberOfStudyRelatedInstances',
'OperatorsName',
'OverlayBitPosition',
'OverlayBitsAllocated',
'OverlayColumns',
'OverlayData',
'OverlayDescription',
'OverlayOrigin',
'OverlayRows',
'OverlayType',
'PatientAddress',
'PatientAge',
'PatientBirthDate',
'PatientID',
'PatientName',
'PatientPosition',
'PatientSex',
'PhotometricInterpretation',
'PhysiciansOfRecord',
'PixelData',
'PixelRepresentation',
'PixelSpacing',
'PositionReferenceIndicator',
'ProcedureCodeSequence',
'ProtocolName',
'ReferencedImageSequence',
'ReferringPhysicianName',
'RequestAttributesSequence',
'RequestedProcedureCodeSequence',
'RequestedProcedureDescription',
'RequestingPhysician',
'RescaleIntercept',
'RescaleSlope',
'RescaleType',
'RotationDirection',
'Rows',
'SOPClassUID',
'SOPInstanceUID',
'SamplesPerPixel',
'SeriesDate',
'SeriesDescription',
'SeriesInstanceUID',
'SeriesNumber',
'SeriesTime',
'SliceThickness',
'SoftwareVersions',
'StationName',
'StudyDate',
'StudyDescription',
'StudyID',
'StudyInstanceUID',
'StudyTime',
'TableHeight',
'TimeOfLastCalibration',
'WindowCenter',
'WindowCenterWidthExplanation',
'WindowWidth']
&lt;/code>&lt;/pre>
&lt;blockquote>
&lt;p>&lt;strong>&lt;em>NOTE:&lt;/em>&lt;/strong> You can also view DICOM files in a collapsible tree using the example program &lt;a href="https://github.com/pydicom/contrib-pydicom/blob/master/plotting-visualization/dcm_qt_tree.py" target="_blank" rel="noopener">dcm_qt_tree.py&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;h2 id="image-visualization">Image visualization&lt;/h2>
&lt;p>DICOM images pixel data is stored as raw bytes in the &lt;code>DataElement&lt;/code> associated to the &lt;code>PixelData&lt;/code> tag. &lt;code>PixelData&lt;/code> is often not immediately useful as data may be stored in a variety of different ways:&lt;/p>
&lt;ul>
&lt;li>The pixel values may be signed or unsigned integers, or floats&lt;/li>
&lt;li>There may be multiple image frames&lt;/li>
&lt;li>There may be multiple planes per frame (i.e., RGB) and the order of the pixels may be different&lt;/li>
&lt;li>The image data may be encoded using one of the available compression standards (1.2.840.10008.1.2.4.50 JPEG Baseline, 1.2.840.10008.1.2.5 RLE Lossless, etc). Encoded image data will also be encapsulated and each encapsulated image frame may be broken up into one or more fragments.&lt;/li>
&lt;/ul>
&lt;p>Because of the complexity in interpreting the pixel data, pydicom provides an easy way to get it in a convenient form: &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.dataset.Dataset.html#pydicom.dataset.Dataset.pixel_array" target="_blank" rel="noopener">&lt;code>Dataset.pixel_array&lt;/code>&lt;/a>. As an example, if the pixel data is compressed then &lt;code>pixel_array&lt;/code> will directly return the uncompressed data.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">matplotlib.pyplot&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">plt&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pixel_array&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bone&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>&amp;lt;matplotlib.image.AxesImage at 0x7f5625845280&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0090-python-dicom/dicom_files/dicom_17_1_hu5cd3fcbac50ea0a3e37b2b8c02f36615_76432_a0d4e1be83f4cb0c55f87b7f4904ed80.webp 400w,
/post/0090-python-dicom/dicom_files/dicom_17_1_hu5cd3fcbac50ea0a3e37b2b8c02f36615_76432_bfde284ff4ca51548ee97668ef0a8d7e.webp 760w,
/post/0090-python-dicom/dicom_files/dicom_17_1_hu5cd3fcbac50ea0a3e37b2b8c02f36615_76432_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0090-python-dicom/dicom_files/dicom_17_1_hu5cd3fcbac50ea0a3e37b2b8c02f36615_76432_a0d4e1be83f4cb0c55f87b7f4904ed80.webp"
width="430"
height="418"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>As it is possible to see, the picture details are not well-defined so the information content is quite poor. The following additional DICOM post-processing should be &lt;strong>sequentially&lt;/strong> performed in order to enhance the image content.&lt;/p>
&lt;h3 id="1-color-palette">1. Color Palette&lt;/h3>
&lt;p>Some DICOM datasets store their output image pixel values in a lookup table (LUT), where the values in Pixel Data are the index to a corresponding LUT entry. When a dataset’s (0028,0004) Photometric Interpretation value is PALETTE COLOR then the &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.pixel_data_handlers.util.html#pydicom.pixel_data_handlers.util.apply_color_lut" target="_blank" rel="noopener">&lt;code>apply_color_lut()&lt;/code>&lt;/a> function can be used to apply a palette color LUT to the pixel data to produce an RGB image.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pydicom.pixel_data_handlers.util&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">apply_color_lut&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;(0028,0004) Photometric Interpretation: &lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mh">0x28&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mh">0x4&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">value&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">rgb&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">apply_color_lut&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">rgb&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bone&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">except&lt;/span> &lt;span class="ne">Exception&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">e&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>(0028,0004) Photometric Interpretation: MONOCHROME2
No suitable Palette Color Lookup Table Module found
&lt;/code>&lt;/pre>
&lt;p>This was expected since the &lt;em>Photometric Interpretation&lt;/em> is &lt;em>MONOCHROME2&lt;/em>, so no suitable Palette Color Lookup Table Module could found and the &lt;code>apply_color_lut&lt;/code> method fails.&lt;/p>
&lt;h3 id="2-modality-lut-or-rescale-operation">2. Modality LUT or Rescale Operation¶&lt;/h3>
&lt;p>The DICOM &lt;a href="http://dicom.nema.org/medical/dicom/current/output/chtml/part03/sect_C.11.html#sect_C.11.1" target="_blank" rel="noopener">Modality LUT&lt;/a> module converts raw pixel data values to a specific (possibly unitless) physical quantity, such as Hounsfield units for CT scan (as in this case). The &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.pixel_data_handlers.util.html#pydicom.pixel_data_handlers.util.apply_voi_lut" target="_blank" rel="noopener">&lt;code>apply_modality_lut()&lt;/code>&lt;/a> function can be used with an input array of raw values and a dataset containing a Modality LUT module to return the converted values. When a dataset requires multiple grayscale transformations, the Modality LUT transformation is always applied first.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pydicom.pixel_data_handlers.util&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">apply_modality_lut&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pixel_array&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">hu&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">apply_modality_lut&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">hu&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bone&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>&amp;lt;matplotlib.image.AxesImage at 0x7f5621d45d60&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0090-python-dicom/dicom_files/dicom_23_1_hu5cd3fcbac50ea0a3e37b2b8c02f36615_76432_7f7e419c08ca4d6a615088a8bc0c5603.webp 400w,
/post/0090-python-dicom/dicom_files/dicom_23_1_hu5cd3fcbac50ea0a3e37b2b8c02f36615_76432_ecb72cbaa6e095d8999258131f5453ec.webp 760w,
/post/0090-python-dicom/dicom_files/dicom_23_1_hu5cd3fcbac50ea0a3e37b2b8c02f36615_76432_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0090-python-dicom/dicom_files/dicom_23_1_hu5cd3fcbac50ea0a3e37b2b8c02f36615_76432_7f7e419c08ca4d6a615088a8bc0c5603.webp"
width="430"
height="418"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>The image has not visually changed, but the pixel values have been correctly transformed into Hounsfield units.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">max&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>(0, 2335)
&lt;/code>&lt;/pre>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">min&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">hu&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">max&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">hu&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>(-1024.0, 1311.0)
&lt;/code>&lt;/pre>
&lt;h3 id="3-voi-lut-or-windowing-operation">3. VOI LUT or Windowing Operation¶&lt;/h3>
&lt;p>The DICOM &lt;a href="http://dicom.nema.org/medical/dicom/current/output/chtml/part03/sect_C.11.2.html" target="_blank" rel="noopener">VOI LUT&lt;/a> module applies a VOI or windowing operation to input values. The &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.pixel_data_handlers.util.html#pydicom.pixel_data_handlers.util.apply_voi_lut" target="_blank" rel="noopener">&lt;code>apply_voi_lut()&lt;/code>&lt;/a> function can be used with an input array and a dataset containing a VOI LUT module to return values with applied VOI LUT or windowing. When a dataset contains multiple VOI or windowing views then a particular view can be returned by using the index keyword parameter. In this case the index &lt;code>0&lt;/code> will be used.&lt;/p>
&lt;p>When a dataset requires multiple grayscale transformations, then it’s assumed that the modality LUT or rescale operation has already been applied.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pydicom.pixel_data_handlers.util&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">apply_voi_lut&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">out&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">apply_voi_lut&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">hu&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">index&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">out&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bone&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>&amp;lt;matplotlib.image.AxesImage at 0x7f5621ab8c40&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0090-python-dicom/dicom_files/dicom_28_1_huf447e093701c4bcb4834419a79ca0b5d_92272_cf1702a0385e32544cc75cd0037f9df4.webp 400w,
/post/0090-python-dicom/dicom_files/dicom_28_1_huf447e093701c4bcb4834419a79ca0b5d_92272_a7c221cdea1e0f4c5712617f3d9b6522.webp 760w,
/post/0090-python-dicom/dicom_files/dicom_28_1_huf447e093701c4bcb4834419a79ca0b5d_92272_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0090-python-dicom/dicom_files/dicom_28_1_huf447e093701c4bcb4834419a79ca0b5d_92272_cf1702a0385e32544cc75cd0037f9df4.webp"
width="430"
height="418"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Got it! The sequence of pre-processing steps has deeply enhanced the details of the CT scan contained in the DICOM file. At this point, the image can be definitely visually analyzed.&lt;/p>
&lt;h2 id="image-export">Image export&lt;/h2>
&lt;p>As already discussed, DICOM files contain not only image data, but also lots of ancillary information. It has also been demonstrated the image may not be immediately usable without some processing. DICOM images are not accessible without specific viewers and the image exchange may be even more difficult since different viewers may differently process the images. A possible solution could be to convert the DICOM file into a standard exchange format, e.g., JPEG or PNG.&lt;/p>
&lt;p>The starting point is the pre-processed image &lt;code>out&lt;/code>. The first step is to convert pixel data to &lt;code>float&lt;/code> in order to avoid overflow or underflow losses during image scaling.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">new_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">astype&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">float&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Pixel data is currently expressed in Hounsfield units, but it must rescaled into the &lt;code>[0, 255]&lt;/code> interval and then converted to 8 bits unsigned integer.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">PIL&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">Image&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">scaled_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">maximum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">new_image&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">new_image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">max&lt;/span>&lt;span class="p">())&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mf">255.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">scaled_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">uint8&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">scaled_image&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">final_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">fromarray&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">scaled_image&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The image can then be easily saved in &lt;code>jpg&lt;/code> or &lt;code>png&lt;/code> format.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">final_image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;dicom.jpg&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">final_image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;dicom.png&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>As a test, it is possible to import and plot the just saved &lt;code>jpg&lt;/code> image.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">img&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">asarray&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">Image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">open&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;dicom.jpg&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">imshow&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">img&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cmap&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">plt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">cm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">bone&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>&amp;lt;matplotlib.image.AxesImage at 0x7f5621a34cd0&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="png" srcset="
/post/0090-python-dicom/dicom_files/dicom_39_1_hu8a1cc0d0a0d51869e683fa2ca2d58092_98210_9fd570e07dd83a10d9acd04b9bf9d909.webp 400w,
/post/0090-python-dicom/dicom_files/dicom_39_1_hu8a1cc0d0a0d51869e683fa2ca2d58092_98210_4f288a8f75b4a28c411e0b6c418dd9a1.webp 760w,
/post/0090-python-dicom/dicom_files/dicom_39_1_hu8a1cc0d0a0d51869e683fa2ca2d58092_98210_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://www.peco602.com/post/0090-python-dicom/dicom_files/dicom_39_1_hu8a1cc0d0a0d51869e683fa2ca2d58092_98210_9fd570e07dd83a10d9acd04b9bf9d909.webp"
width="430"
height="418"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h2 id="dicom-file-sets-and-dicomdir">DICOM File-sets and DICOMDIR&lt;/h2>
&lt;p>A File-set is a collection of DICOM files that share a common naming space. Most people have probably interacted with a File-set without being aware of it; one place they’re frequently used is on the CDs/DVDs containing DICOM data that are given to a patient after a medical procedure (such as an MR or ultrasound). The specification for File-sets is given in &lt;a href="http://dicom.nema.org/medical/dicom/current/output/chtml/part10/chapter_8.html" target="_blank" rel="noopener">Part 10 of the DICOM Standard&lt;/a>.&lt;/p>
&lt;p>Every File-set must contain a single file with the filename &lt;strong>&lt;code>DICOMDIR&lt;/code>&lt;/strong>, the location of which is dependent on the type of media used to store the File-set. For the most commonly used media (DVD, CD, USB, PC file system, etc), the DICOMDIR file will be in the root directory of the File-set. For other media types, &lt;a href="http://dicom.nema.org/medical/dicom/current/output/chtml/part12/ps3.12.html" target="_blank" rel="noopener">Part 12 of the DICOM Standard&lt;/a> specifies where the DICOMDIR must be located.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>&lt;em>NOTE:&lt;/em>&lt;/strong> Despite its name, a DICOMDIR file is not a file system directory and can be read using &lt;code>dcmread()&lt;/code> like any other DICOM dataset&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">DICOMDIR_PATH&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;/home/user/Desktop/exam/DICOMDIR&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ds&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dcmread&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">DICOMDIR_PATH&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">type&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>pydicom.dicomdir.DicomDir
&lt;/code>&lt;/pre>
&lt;p>The most important element in a DICOMDIR is the (0004,1220) &lt;em>Directory Record Sequence&lt;/em>: each item in the sequence is a directory record, and one or more records are used to briefly describe an available item, i.e., the so called SOP Instance, and its location within the File-set’s directory structure. Each record has a record type given by the (0004,1430) &lt;em>Directory Record Type&lt;/em> element, and different records are related to each other using the hierarchy given in &lt;a href="https://dicom.nema.org/medical/dicom/current/output/chtml/part03/sect_F.4.html#table_F.4-1" target="_blank" rel="noopener">Table F.4-1&lt;/a>. As examples, it is possible to go through some directory records:&lt;/p>
&lt;!-- ```python
# TO BE COMMENTED
ds.DirectoryRecordSequence[0].PatientName = 'ROSSI^MARIO'
ds.DirectoryRecordSequence[0].PatientID = '99999999'
ds.DirectoryRecordSequence[0].PatientBirthDate = '19330101'
``` -->
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DirectoryRecordSequence&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>(0004, 1400) Offset of the Next Directory Record UL: 0
(0004, 1410) Record In-use Flag US: 65535
(0004, 1420) Offset of Referenced Lower-Level Di UL: 500
(0004, 1430) Directory Record Type CS: 'PATIENT'
(0010, 0010) Patient's Name PN: 'ROSSI^MARIO'
(0010, 0020) Patient ID LO: '99999999'
(0010, 0021) Issuer of Patient ID LO: 'X1V1_MPI'
(0010, 0030) Patient's Birth Date DA: '19330101'
(0010, 0040) Patient's Sex CS: 'M'
&lt;/code>&lt;/pre>
&lt;p>This is a &lt;code>PATIENT&lt;/code> record which provides details about the patient, such as &lt;em>Patient&amp;rsquo;s Name&lt;/em> and &lt;em>Patient ID&lt;/em> (refer to &lt;a href="http://dicom.nema.org/medical/dicom/current/output/chtml/part03/sect_F.5.html#table_F.5-1" target="_blank" rel="noopener">Table F.5-1&lt;/a>).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DirectoryRecordSequence&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>(0004, 1400) Offset of the Next Directory Record UL: 0
(0004, 1410) Record In-use Flag US: 65535
(0004, 1420) Offset of Referenced Lower-Level Di UL: 956
(0004, 1430) Directory Record Type CS: 'STUDY'
(0008, 0020) Study Date DA: '20221215'
(0008, 0030) Study Time TM: '162614'
(0008, 0050) Accession Number SH: '5895682501'
(0008, 0061) Modalities in Study CS: 'CT'
(0008, 0090) Referring Physician's Name PN: 'MEDICO^REFERTANTE'
(0008, 1030) Study Description LO: 'TC CRANIO (CAPO)'
(0020, 000d) Study Instance UID UI: 1.2.840.113564.9.1.2015111110072131.20221209153953.25895682501
(0020, 0010) Study ID SH: 'CT20221215162611'
(0020, 1206) Number of Study Related Series IS: '5'
(0020, 1208) Number of Study Related Instances IS: '545'
(07a1, 0010) Private Creator LO: 'ELSCINT1'
(07a1, 1040) [Tamar Study Body Part] CS: 'ABDOMEN'
(07a3, 0010) Private Creator LO: 'ELSCINT1'
(07a3, 1069) Private tag data OB: Array of 98 elements
&lt;/code>&lt;/pre>
&lt;p>This is a &lt;code>STUDY&lt;/code> record, where details such as acquisition date, time and description are included (refer to &lt;a href="https://dicom.nema.org/medical/dicom/current/output/chtml/part03/sect_F.5.2.html" target="_blank" rel="noopener">Table F.5-2&lt;/a>).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DirectoryRecordSequence&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>(0004, 1400) Offset of the Next Directory Record UL: 6032
(0004, 1410) Record In-use Flag US: 65535
(0004, 1420) Offset of Referenced Lower-Level Di UL: 1214
(0004, 1430) Directory Record Type CS: 'SERIES'
(0008, 0021) Series Date DA: '20221215'
(0008, 0031) Series Time TM: '162644'
(0008, 0060) Modality CS: 'CT'
(0008, 103e) Series Description LO: 'Topogram 0.6 T20s'
(0018, 0015) Body Part Examined CS: 'ABDOMEN'
(0018, 1030) Protocol Name LO: 'CBM_encefalo_SEQ'
(0020, 000e) Series Instance UID UI: 1.3.12.2.1107.5.1.4.55050.30000022121508001632800000005
(0020, 0011) Series Number IS: '1'
(0020, 1209) Number of Series Related Instances IS: '1'
&lt;/code>&lt;/pre>
&lt;p>The &lt;code>SERIES&lt;/code> record adds details about the acquisition modality, i.e., &lt;code>CT&lt;/code>, and the examined body part, i.e., &lt;code>ABDOMEN&lt;/code> (refer to &lt;a href="https://dicom.nema.org/medical/dicom/current/output/chtml/part03/sect_F.5.3.html" target="_blank" rel="noopener">Table F.5-3&lt;/a>).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">DirectoryRecordSequence&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>(0004, 1400) Offset of the Next Directory Record UL: 0
(0004, 1410) Record In-use Flag US: 65535
(0004, 1420) Offset of Referenced Lower-Level Di UL: 0
(0004, 1430) Directory Record Type CS: 'IMAGE'
(0004, 1500) Referenced File ID CS: ['MD44PKO2', 'OBGUOM0I', 'I1000000']
(0004, 1510) Referenced SOP Class UID in File UI: CT Image Storage
(0004, 1511) Referenced SOP Instance UID in File UI: 1.3.12.2.1107.5.1.4.55050.30000022121506293760900002194
(0004, 1512) Referenced Transfer Syntax UID in F UI: Explicit VR Little Endian
(0008, 0008) Image Type CS: ['ORIGINAL', 'PRIMARY', 'LOCALIZER', 'CT_SOM5 TOP']
(0008, 0016) SOP Class UID UI: CT Image Storage
(0008, 0018) SOP Instance UID UI: 1.3.12.2.1107.5.1.4.55050.30000022121506293760900002194
(0008, 0023) Content Date DA: '20221215'
(0008, 0033) Content Time TM: '162704.453698'
(0008, 0060) Modality CS: 'CT'
(0018, 0010) Contrast/Bolus Agent LO: ''
(0020, 0013) Instance Number IS: '1'
(0020, 0052) Frame of Reference UID UI: 1.3.12.2.1107.5.1.4.55050.30000022121506293760900002193
(0020, 1041) Slice Location DS: '-14.5'
(0028, 0002) Samples per Pixel US: 1
(0028, 0004) Photometric Interpretation CS: 'MONOCHROME2'
(0028, 0010) Rows US: 512
(0028, 0011) Columns US: 512
(0028, 0100) Bits Allocated US: 16
(0088, 0200) Icon Image Sequence 1 item(s) ----
(0028, 0002) Samples per Pixel US: 1
(0028, 0004) Photometric Interpretation CS: 'MONOCHROME2'
(0028, 0010) Rows US: 64
(0028, 0011) Columns US: 64
(0028, 0034) Pixel Aspect Ratio IS: [1, 1]
(0028, 0100) Bits Allocated US: 8
(0028, 0101) Bits Stored US: 8
(0028, 0102) High Bit US: 7
(0028, 0103) Pixel Representation US: 0
(7fe0, 0010) Pixel Data OB: Array of 4096 elements
---------
(00e1, 0010) Private Creator LO: 'ELSCINT1'
(00e1, 1040) [Image Label] SH: ''
&lt;/code>&lt;/pre>
&lt;p>Last but not least, the &lt;code>IMAGE&lt;/code> record contains all the image data, i.e., &lt;code>Pixel Data&lt;/code>, and metadata, e.g., &lt;code>Bits Allocated&lt;/code>, &lt;code>Photometric Interpretation&lt;/code>.&lt;/p>
&lt;p>While it’s possible to access everything within a File-set using the DICOMDIR dataset, making changes to an existing File-set quickly becomes complicated due to the need to add and remove directory records, recalculate the byte offsets for existing records and manage the corresponding file system changes. A more user-friendly way to interact with one is via the &lt;a href="https://pydicom.github.io/pydicom/stable/reference/generated/pydicom.fileset.FileSet.html#pydicom.fileset.FileSet" target="_blank" rel="noopener">FileSet&lt;/a> class.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pydicom.fileset&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">FileSet&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">fs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">FileSet&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">type&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>pydicom.fileset.FileSet
&lt;/code>&lt;/pre>
&lt;p>An overview of the File-set’s contents is shown when printing:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>DICOM File-set
Root directory: /home/user/Desktop/exam
File-set ID: (no value available)
File-set UID: 1.2.840.113704.7.1.0.12118132138452.1672763590.1000003
Descriptor file ID: (no value available)
Descriptor file character set: (no value available)
Changes staged for write(): DICOMDIR update, directory structure update
Managed instances:
PATIENT: PatientID='99999999', PatientName='ROSSI^MARIO'
STUDY: StudyDate=20221215, StudyTime=162614, StudyDescription='TC CRANIO (CAPO)'
SERIES: Modality=CT, SeriesNumber=1
IMAGE: 1 SOP Instance
SERIES: Modality=CT, SeriesNumber=2
IMAGE: 66 SOP Instances
SERIES: Modality=CT, SeriesNumber=602
IMAGE: 199 SOP Instances
SERIES: Modality=CT, SeriesNumber=603
IMAGE: 143 SOP Instances
SERIES: Modality=CT, SeriesNumber=604
IMAGE: 136 SOP Instances
&lt;/code>&lt;/pre>
&lt;p>which basically provides a brief summary of the directory records previously introduced.&lt;/p>
&lt;h2 id="conclusions">Conclusions&lt;/h2>
&lt;p>This post has provided a wide overview of DICOM images in Python in particular about:&lt;/p>
&lt;ul>
&lt;li>DICOM data structure&lt;/li>
&lt;li>DICOM image visualization (and pre-processing)&lt;/li>
&lt;li>DICOM image export&lt;/li>
&lt;li>DICOM file-sets and DICOMDIR&lt;/li>
&lt;/ul>
&lt;p>As a summary, the following script summarizes all the introduced concepts since it allows to read a &lt;code>DICOMDIR&lt;/code> file (via the &lt;code>DICOMDIR_PATH&lt;/code> variable) and convert all the SOP instances to JPEG images. The exported images will be saved to a specific path based on specific metadata, i.e., &lt;code>{OUTPUT_PATH}/{patient_id}/{study_date}/{series_number}/{instance_number}.jpg&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">os&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">PIL&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">Image&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">numpy&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">np&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pydicom&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">dcmread&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pydicom.fileset&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">FileSet&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pydicom.pixel_data_handlers.util&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">apply_color_lut&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">apply_modality_lut&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">apply_voi_lut&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">DICOMDIR_PATH&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;/home/user/Desktop/exam/DICOMDIR&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">OUTPUT_PATH&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;/home/user/Desktop/exam_converted&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># DICOMDIR reading&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">ds&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dcmread&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">DICOMDIR_PATH&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">fs&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">FileSet&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Iterating over the FileSet instances&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">instance&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">fs&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Loading the corresponding SOP Instance dataset&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">ds&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">instance&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">load&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Getting instance metadata to categorize images&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">patient_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">PatientID&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">study_date&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">StudyDate&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">series_number&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">SeriesNumber&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">instance_number&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">InstanceNumber&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Getting instance pixel data&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">pixel_array&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Applying color palette (if available)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">try&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">arr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">apply_color_lut&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">except&lt;/span> &lt;span class="ne">Exception&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">e&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">pass&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Applying modality LUT&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">hu&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">apply_modality_lut&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">arr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Applying VOI LUT&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">out&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">apply_voi_lut&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">hu&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ds&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">index&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Rescaling pixel data&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">new_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">out&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">astype&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">float&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">scaled_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">maximum&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">new_image&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="n">new_image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">max&lt;/span>&lt;span class="p">())&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="mf">255.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">scaled_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">uint8&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">scaled_image&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">final_image&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">fromarray&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">scaled_image&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Exporting image in JPEG format&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">IMAGE_PATH&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">OUTPUT_PATH&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sep&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">patient_id&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sep&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">study_date&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sep&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">series_number&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">makedirs&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">IMAGE_PATH&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">exist_ok&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">True&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">OUTPUT_IMAGE&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="sa">f&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="si">{&lt;/span>&lt;span class="n">IMAGE_PATH&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">sep&lt;/span>&lt;span class="si">}{&lt;/span>&lt;span class="n">instance_number&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">.jpg&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">final_image&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">OUTPUT_IMAGE&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="references">References&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.dicomstandard.org/" target="_blank" rel="noopener">Digital Image and Communications in Medicine&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://pydicom.github.io/pydicom/stable/" target="_blank" rel="noopener">pydicom documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://medium.com/analytics-vidhya/dicom-and-deep-learning-63373e99d79a" target="_blank" rel="noopener">Extract DICOM Images Only for Deep Learning | by Nawaf Alageel | Analytics Vidhya | Medium&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mscipio.github.io/post/read_dicom_files_in_python/" target="_blank" rel="noopener">How to read DICOM files into Python | MICHELE SCIPIONI (mscipio.github.io)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://pycad.co/how-to-convert-a-dicom-image-into-jpg-or-png/" target="_blank" rel="noopener">How To Convert a DICOM Image Into JPG or PNG - PYCAD&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Maternal Health Risk Predictor</title><link>https://www.peco602.com/project/0040-maternal-health-mlops/</link><pubDate>Tue, 06 Sep 2022 00:00:00 +0000</pubDate><guid>https://www.peco602.com/project/0040-maternal-health-mlops/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>According to the World Health Organization (WHO):&lt;/p>
&lt;p>&amp;ldquo;&lt;em>Maternal health refers to the health of women during pregnancy, childbirth and the post-natal period. Each stage should be a positive experience, ensuring women and their babies reach their full potential for health and well-being. Although important progress has been made in the last two decades, about 295 000 women died during and following pregnancy and childbirth in 2017. This number is unacceptably high. The most common direct causes of maternal injury and death are excessive blood loss, infection, high blood pressure, unsafe abortion, and obstructed labour, as well as indirect causes such as anemia, malaria, and heart disease. Most maternal deaths are preventable with timely management by a skilled health professional working in a supportive environment. Ending preventable maternal death must remain at the top of the global agenda. At the same time, simply surviving pregnancy and childbirth can never be the marker of successful maternal health care. It is critical to expand efforts reducing maternal injury and disability to promote health and well-being. Every pregnancy and birth is unique. Addressing inequalities that affect health outcomes, especially sexual and reproductive health and rights and gender, is fundamental to ensuring all women have access to respectful and high-quality maternity care.&lt;/em>&amp;rdquo;&lt;/p>
&lt;p>The goal of the project is to apply what has been learned during the MLOps Zoomcamp course to build a MLOps pipeline for woman health risk prediction during pregnancy.&lt;/p>
&lt;h2 id="dataset">Dataset&lt;/h2>
&lt;p>The dataset used to feed the MLOps pipeline has been downloaded from &lt;a href="https://www.kaggle.com/datasets/pyuxbhatt/maternal-health-risk" target="_blank" rel="noopener">Kaggle&lt;/a> and contains data collected from several hospitals, community clinics and maternal health cares through an IoT-based risk monitoring system. The dataset is updated daily and is characterized by the following features:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Feature&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Age&lt;/td>
&lt;td>Age when a woman is pregnant.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>SystolicBP&lt;/td>
&lt;td>Upper value of blood pressure.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>DiastolicBP&lt;/td>
&lt;td>Lower value of blood pressure.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>BS&lt;/td>
&lt;td>Blood glucose levels in terms of molar concentration.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>HeartRate&lt;/td>
&lt;td>A normal resting heart rate.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>BodyTemp&lt;/td>
&lt;td>Average human body temperature.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Risk Level&lt;/td>
&lt;td>Predicted risk intensity level during pregnancy considering the previous attributes.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="mlops-pipeline">MLOps pipeline&lt;/h2>
&lt;h3 id="architecture">Architecture&lt;/h3>
&lt;img src="./architecture.png" width="100%"/>
&lt;h3 id="deployment">Deployment&lt;/h3>
&lt;p>The MLOps pipeline is fully dockerised and can be easily deployed via the following steps:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Clone the &lt;code>maternal-health-risk&lt;/code> repository locally:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ git clone https://github.com/Peco602/maternal-health-risk.git
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Install the pre-requisites necessary to run the pipeline:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ &lt;span class="nb">cd&lt;/span> maternal-health-risk
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ sudo apt install make
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ make prerequisites
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>It is also suggested to add the current user to the &lt;code>docker&lt;/code> group to avoid running the next steps as &lt;code>sudo&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ sudo groupadd docker
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ sudo usermod -aG docker &lt;span class="nv">$USER&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>then, logout and log back in so that the group membership is re-evaluated.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[&lt;em>Optional&lt;/em>] Configure the development evironment:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">$ make setup
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is required to perform further development and testing on the pipeline.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>[&lt;em>Optional&lt;/em>] Insert Kaggle credentials in the &lt;code>.env&lt;/code> file to allow the automatic scheduled dataset update:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Kaggle credentials&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">KAGGLE_USERNAME&lt;/span>&lt;span class="o">=&lt;/span>*****
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">KAGGLE_KEY&lt;/span>&lt;span class="o">=&lt;/span>*****
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In case the credentials are not available, the training dataset &lt;code>data/data.csv&lt;/code> must be updated manually.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Pull the Docker images:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$ make pull
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Launch the MLOps pipeline:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$ make run
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once ready, the following services will be available:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Service&lt;/th>
&lt;th>Port&lt;/th>
&lt;th>Interface&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Web Application&lt;/td>
&lt;td>80&lt;/td>
&lt;td>0.0.0.0&lt;/td>
&lt;td>Prediction web service (see picture below)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Prefect&lt;/td>
&lt;td>4200&lt;/td>
&lt;td>127.0.0.1&lt;/td>
&lt;td>Training workflow orchestration&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>MLFlow&lt;/td>
&lt;td>5000&lt;/td>
&lt;td>127.0.0.1&lt;/td>
&lt;td>Experiment tracking and model registry&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>MinIO&lt;/td>
&lt;td>9001&lt;/td>
&lt;td>127.0.0.1&lt;/td>
&lt;td>S3-equivalent bucket management&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Evidently&lt;/td>
&lt;td>8085&lt;/td>
&lt;td>127.0.0.1&lt;/td>
&lt;td>Data and target drift report generation (&lt;code>/dashboard&lt;/code> route)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Grafana&lt;/td>
&lt;td>3000&lt;/td>
&lt;td>127.0.0.1&lt;/td>
&lt;td>Data and target drift real-time dashboards&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;img src="./webservice.png" width="100%"/>
&lt;/li>
&lt;/ol>
&lt;h3 id="training">Training&lt;/h3>
&lt;p>Once the MLOps pipeline has been started, the prediction web service can already work thanks to a default pre-trained model available in the Docker image. In order to enable pipeline training workflow it is necessary to create a scheduled Prefect deployment via:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$ make deployment
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The training workflow will be then automatically executed every day. It will download the latest dataset (if the Kaggle credentials have been provided), search the best model in terms of accuracy among XGBoost, Support Vector Machine and Random Forest and finally will store it in the model registry. It is worth noting the training workflow can also be immediately executed without waiting the next schedule:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$ make train
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once the updated model is ready, it can be moved to production by restarting the pipeline:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$ make restart
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>the web service will automatically connect to the registry and get the most updated model. If the model is still not available, it will continue to use the default one.&lt;/p>
&lt;h3 id="monitoring">Monitoring&lt;/h3>
&lt;p>It is possible to generate simulated traffic via:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$ make generate-traffic
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then, the prediction service can be monitored via:&lt;/p>
&lt;ul>
&lt;li>Grafana (in real-time): &lt;code>http://127.0.0.1:3000&lt;/code>&lt;/li>
&lt;li>Evidently (for report generation): &lt;code>http://127.0.0.1:8085/dashboard&lt;/code>&lt;/li>
&lt;/ul>
&lt;h3 id="disposal">Disposal&lt;/h3>
&lt;p>The MLOps pipeline can be disposed via:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$ make kill
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>while the Docker volumes used for persistence can be removed via:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$ make clean
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="github-actions">GitHub Actions&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Continuous Integration&lt;/strong>: On every push and pull request on &lt;code>main&lt;/code> and &lt;code>dev&lt;/code> branches, the Docker images are built, tested and then pushed to DockerHub.&lt;/li>
&lt;li>&lt;strong>Continuous Deployment&lt;/strong>: On every push and pull request on &lt;code>main&lt;/code> branch, only if the Continuous Integration workflow has been successful successful, the updated pipeline is deployed to the target server and run.&lt;/li>
&lt;/ul>
&lt;h2 id="applied-technologies">Applied technologies&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Name&lt;/th>
&lt;th>Scope&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Jupyter Notebooks&lt;/td>
&lt;td>Exploratory data analysis and pipeline prototyping.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Docker&lt;/td>
&lt;td>Application containerization.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Docker-Compose&lt;/td>
&lt;td>Multi-container Docker applications definition and running.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Prefect&lt;/td>
&lt;td>Workflow orchestration.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>MLFlow&lt;/td>
&lt;td>Experiment tracking and model registry.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>PostgreSQL&lt;/td>
&lt;td>MLFLow experiment tracking database.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>MinIO&lt;/td>
&lt;td>High Performance Object Storage compatible with Amazon S3 cloud storage service.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Flask&lt;/td>
&lt;td>Web server.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Bootstrap&lt;/td>
&lt;td>Frontend toolkit.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>MongoDB&lt;/td>
&lt;td>Prediction database.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>EvidentlyAI&lt;/td>
&lt;td>ML models evaluation and monitoring.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Prometheus&lt;/td>
&lt;td>Time Series Database for ML models real-time monitoring.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Grafana&lt;/td>
&lt;td>ML models real-time monitoring dashboards.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>pytest&lt;/td>
&lt;td>Python unit testing suite.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>pylint&lt;/td>
&lt;td>Python static code analysis.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>black&lt;/td>
&lt;td>Python code formatting.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>isort&lt;/td>
&lt;td>Python import sorting.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Pre-Commit Hooks&lt;/td>
&lt;td>Simple code issue identification before submission.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>GitHub Actions&lt;/td>
&lt;td>CI/CD pipelines.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="disclaimer">Disclaimer&lt;/h2>
&lt;p>This prediction service has been developed as the final project of the MLOps Zoomcamp course from DataTalks.Club. It does not provide medical advice and it is intended for informational purposes only. It cannot be considered a substitute for professional medical advice, diagnosis or treatment. Never ignore professional medical advice in seeking treatment because of something you have read here.&lt;/p></description></item><item><title>FindWall</title><link>https://www.peco602.com/project/0030-findwall/</link><pubDate>Fri, 20 May 2022 00:00:00 +0000</pubDate><guid>https://www.peco602.com/project/0030-findwall/</guid><description>&lt;h2 id="what-does-it-do">What does it do?&lt;/h2>
&lt;p>FindWall is Python script that allows to understand if your network provider is limiting your access to the Internet by blocking any TCP/UDP port. In order to perform this check FindWall needs to connect a public VPS of your property. FindWall performs the following actions:&lt;/p>
&lt;ol>
&lt;li>Connects to the VPS via SSH&lt;/li>
&lt;li>Opens a port in listening mode&lt;/li>
&lt;li>Tries to connect to that port from the local machine&lt;/li>
&lt;li>Closes the port&lt;/li>
&lt;/ol>
&lt;h2 id="how-do-you-use-it">How do you use it?&lt;/h2>
&lt;img src="./demo.gif" width="100%"/>
&lt;p>To use FindWall you just need an account on a public VPS. The account must have root access if you want to test ports in the range &lt;code>1-1024&lt;/code>. The root account is also required to automatically install the tool &lt;code>nc&lt;/code> to open ports.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$ pip install -r requirements
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ python findwall.py --help
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">=====================================================================================
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ███████╗██╗███╗ ██╗██████╗ ██╗ ██╗ █████╗ ██╗ ██╗
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ██╔════╝██║████╗ ██║██╔══██╗██║ ██║██╔══██╗██║ ██║
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> █████╗ ██║██╔██╗ ██║██║ ██║██║ █╗ ██║███████║██║ ██║
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ██╔══╝ ██║██║╚██╗██║██║ ██║██║███╗██║██╔══██║██║ ██║
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ██║ ██║██║ ╚████║██████╔╝╚███╔███╔╝██║ ██║███████╗███████╗
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ╚═╝ ╚═╝╚═╝ ╚═══╝╚═════╝ ╚══╝╚══╝ ╚═╝ ╚═╝╚══════╝╚══════╝
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">=====================================================================================
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">usage: findwall.py [-h] --ssh-host SSH_HOST [--ssh-port SSH_PORT] --ssh-username SSH_USERNAME [--ssh-password SSH_PASSWORD] [--ask-ssh-pass] [--ssh-key SSH_KEY] --ports PORTS [--udp]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [--threads THREADS]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Check if someone is blocking you!
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">optional arguments:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -h, --help show this help message and exit
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> --ssh-host SSH_HOST Remote host
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> --ssh-port SSH_PORT Remote SSH port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> --ssh-username SSH_USERNAME
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Remote SSH username
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> --ssh-password SSH_PASSWORD
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Remote SSH password
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> --ask-ssh-pass Ask for remote SSH password
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> --ssh-key SSH_KEY Remote SSH private key
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> --ports PORTS Port range to scan (default: 1-1024)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> --udp Scan in UDP
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> --threads THREADS Number of threads (default: 1)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>As an example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$ python findwall.py --ssh-host 172.17.0.2 --ssh-port 22 --ssh-username test --ssh-password test --ports 8000-8010 --threads 3
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item></channel></rss>